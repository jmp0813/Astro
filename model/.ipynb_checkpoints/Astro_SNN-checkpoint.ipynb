{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run ../load_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 138230 samples, validate on 92154 samples\n",
      "Epoch 1/3000\n",
      "138230/138230 [==============================] - 17s 122us/sample - loss: 0.7238 - accuracy: 0.6919 - val_loss: 0.6860 - val_accuracy: 0.7143\n",
      "Epoch 2/3000\n",
      "138230/138230 [==============================] - 14s 105us/sample - loss: 0.5808 - accuracy: 0.7627 - val_loss: 0.5083 - val_accuracy: 0.7933\n",
      "Epoch 3/3000\n",
      "138230/138230 [==============================] - 15s 106us/sample - loss: 0.4717 - accuracy: 0.8147 - val_loss: 0.3720 - val_accuracy: 0.8568\n",
      "Epoch 4/3000\n",
      "138230/138230 [==============================] - 16s 119us/sample - loss: 0.3781 - accuracy: 0.8573 - val_loss: 0.3253 - val_accuracy: 0.8809\n",
      "Epoch 5/3000\n",
      "138230/138230 [==============================] - 14s 100us/sample - loss: 0.3298 - accuracy: 0.8768 - val_loss: 0.2771 - val_accuracy: 0.8961\n",
      "Epoch 6/3000\n",
      "138230/138230 [==============================] - 14s 99us/sample - loss: 0.3053 - accuracy: 0.8852 - val_loss: 0.2993 - val_accuracy: 0.8960\n",
      "Epoch 7/3000\n",
      "138230/138230 [==============================] - 15s 111us/sample - loss: 0.2877 - accuracy: 0.8905 - val_loss: 0.2653 - val_accuracy: 0.8980\n",
      "Epoch 8/3000\n",
      "138230/138230 [==============================] - 16s 114us/sample - loss: 0.2923 - accuracy: 0.8911 - val_loss: 0.2833 - val_accuracy: 0.8975\n",
      "Epoch 9/3000\n",
      "138230/138230 [==============================] - 15s 108us/sample - loss: 0.2805 - accuracy: 0.8954 - val_loss: 0.2691 - val_accuracy: 0.8981\n",
      "Epoch 10/3000\n",
      "138230/138230 [==============================] - 15s 106us/sample - loss: 0.2661 - accuracy: 0.8988 - val_loss: 0.2684 - val_accuracy: 0.8961\n",
      "Epoch 11/3000\n",
      "138230/138230 [==============================] - 14s 103us/sample - loss: 0.2544 - accuracy: 0.9013 - val_loss: 0.3228 - val_accuracy: 0.8832\n",
      "Epoch 12/3000\n",
      "138230/138230 [==============================] - 14s 104us/sample - loss: 0.2643 - accuracy: 0.8993 - val_loss: 0.2341 - val_accuracy: 0.9068\n",
      "Epoch 13/3000\n",
      "138230/138230 [==============================] - 14s 105us/sample - loss: 0.2451 - accuracy: 0.9041 - val_loss: 0.2869 - val_accuracy: 0.8915\n",
      "Epoch 14/3000\n",
      "138230/138230 [==============================] - 14s 103us/sample - loss: 0.2403 - accuracy: 0.9066 - val_loss: 0.2368 - val_accuracy: 0.9041\n",
      "Epoch 15/3000\n",
      "138230/138230 [==============================] - 14s 104us/sample - loss: 0.2515 - accuracy: 0.9029 - val_loss: 0.2196 - val_accuracy: 0.9131\n",
      "Epoch 16/3000\n",
      "138230/138230 [==============================] - 15s 106us/sample - loss: 0.2290 - accuracy: 0.9098 - val_loss: 0.4432 - val_accuracy: 0.8590\n",
      "Epoch 17/3000\n",
      "138230/138230 [==============================] - 14s 104us/sample - loss: 0.2304 - accuracy: 0.9098 - val_loss: 0.2166 - val_accuracy: 0.9125\n",
      "Epoch 18/3000\n",
      "138230/138230 [==============================] - 15s 105us/sample - loss: 0.2255 - accuracy: 0.9101 - val_loss: 0.2177 - val_accuracy: 0.9146\n",
      "Epoch 19/3000\n",
      "138230/138230 [==============================] - 14s 99us/sample - loss: 0.2233 - accuracy: 0.9113 - val_loss: 0.2212 - val_accuracy: 0.9103\n",
      "Epoch 20/3000\n",
      "138230/138230 [==============================] - 14s 100us/sample - loss: 0.2281 - accuracy: 0.9104 - val_loss: 0.2241 - val_accuracy: 0.9102\n",
      "Epoch 21/3000\n",
      "138230/138230 [==============================] - 14s 100us/sample - loss: 0.2239 - accuracy: 0.9109 - val_loss: 0.2117 - val_accuracy: 0.9161\n",
      "Epoch 22/3000\n",
      "138230/138230 [==============================] - 14s 98us/sample - loss: 0.2223 - accuracy: 0.9115 - val_loss: 0.2581 - val_accuracy: 0.9005\n",
      "Epoch 23/3000\n",
      "138230/138230 [==============================] - 14s 100us/sample - loss: 0.2252 - accuracy: 0.9111 - val_loss: 0.2015 - val_accuracy: 0.9201\n",
      "Epoch 24/3000\n",
      "138230/138230 [==============================] - 14s 99us/sample - loss: 0.2179 - accuracy: 0.9134 - val_loss: 0.2082 - val_accuracy: 0.9165\n",
      "Epoch 25/3000\n",
      "138230/138230 [==============================] - 14s 100us/sample - loss: 0.2397 - accuracy: 0.9062 - val_loss: 0.2189 - val_accuracy: 0.9128\n",
      "Epoch 26/3000\n",
      "138230/138230 [==============================] - 14s 99us/sample - loss: 0.2240 - accuracy: 0.9116 - val_loss: 0.2082 - val_accuracy: 0.9169\n",
      "Epoch 27/3000\n",
      "138230/138230 [==============================] - 14s 99us/sample - loss: 0.2234 - accuracy: 0.9129 - val_loss: 0.2098 - val_accuracy: 0.9157\n",
      "Epoch 28/3000\n",
      "138230/138230 [==============================] - 14s 99us/sample - loss: 0.2166 - accuracy: 0.9138 - val_loss: 0.2071 - val_accuracy: 0.9166\n",
      "Epoch 29/3000\n",
      "138230/138230 [==============================] - 15s 106us/sample - loss: 0.2186 - accuracy: 0.9127 - val_loss: 0.2233 - val_accuracy: 0.9130\n",
      "Epoch 30/3000\n",
      "138230/138230 [==============================] - 15s 107us/sample - loss: 0.2120 - accuracy: 0.9146 - val_loss: 0.1973 - val_accuracy: 0.9205\n",
      "Epoch 31/3000\n",
      "138230/138230 [==============================] - 16s 112us/sample - loss: 0.2131 - accuracy: 0.9147 - val_loss: 0.2072 - val_accuracy: 0.9143\n",
      "Epoch 32/3000\n",
      "138230/138230 [==============================] - 15s 107us/sample - loss: 0.2140 - accuracy: 0.9142 - val_loss: 0.2087 - val_accuracy: 0.9158\n",
      "Epoch 33/3000\n",
      "138230/138230 [==============================] - 15s 109us/sample - loss: 0.2114 - accuracy: 0.9155 - val_loss: 0.2106 - val_accuracy: 0.9145\n",
      "Epoch 34/3000\n",
      "138230/138230 [==============================] - 14s 105us/sample - loss: 0.2876 - accuracy: 0.8882 - val_loss: 0.2905 - val_accuracy: 0.8898\n",
      "Epoch 35/3000\n",
      "138230/138230 [==============================] - 15s 106us/sample - loss: 0.2417 - accuracy: 0.9063 - val_loss: 0.4003 - val_accuracy: 0.8831\n",
      "Epoch 36/3000\n",
      "138230/138230 [==============================] - 14s 104us/sample - loss: 0.2261 - accuracy: 0.9110 - val_loss: 0.2455 - val_accuracy: 0.9040\n",
      "Epoch 37/3000\n",
      "138230/138230 [==============================] - 14s 105us/sample - loss: 0.2223 - accuracy: 0.9125 - val_loss: 0.2104 - val_accuracy: 0.9182\n",
      "Epoch 38/3000\n",
      "138230/138230 [==============================] - 15s 109us/sample - loss: 0.2156 - accuracy: 0.9141 - val_loss: 0.2008 - val_accuracy: 0.9177\n",
      "Epoch 39/3000\n",
      "138230/138230 [==============================] - 15s 105us/sample - loss: 0.2203 - accuracy: 0.9137 - val_loss: 0.2038 - val_accuracy: 0.9178\n",
      "Epoch 40/3000\n",
      "138230/138230 [==============================] - 15s 105us/sample - loss: 0.2114 - accuracy: 0.9153 - val_loss: 0.2080 - val_accuracy: 0.9202\n",
      "Epoch 41/3000\n",
      "138230/138230 [==============================] - 15s 109us/sample - loss: 0.2104 - accuracy: 0.9157 - val_loss: 0.2202 - val_accuracy: 0.9118\n",
      "Epoch 42/3000\n",
      "138230/138230 [==============================] - 15s 110us/sample - loss: 0.2133 - accuracy: 0.9149 - val_loss: 0.2256 - val_accuracy: 0.9136\n",
      "Epoch 43/3000\n",
      "138230/138230 [==============================] - 15s 110us/sample - loss: 0.2110 - accuracy: 0.9160 - val_loss: 0.1927 - val_accuracy: 0.9220\n",
      "Epoch 44/3000\n",
      "138230/138230 [==============================] - 14s 104us/sample - loss: 0.2133 - accuracy: 0.9150 - val_loss: 0.2015 - val_accuracy: 0.9180\n",
      "Epoch 45/3000\n",
      "138230/138230 [==============================] - 14s 104us/sample - loss: 0.2084 - accuracy: 0.9162 - val_loss: 0.1951 - val_accuracy: 0.9216\n",
      "Epoch 46/3000\n",
      "138230/138230 [==============================] - 14s 105us/sample - loss: 0.2067 - accuracy: 0.9171 - val_loss: 0.1969 - val_accuracy: 0.9200\n",
      "Epoch 47/3000\n",
      "138230/138230 [==============================] - 14s 104us/sample - loss: 0.2098 - accuracy: 0.9158 - val_loss: 0.1969 - val_accuracy: 0.9186\n",
      "Epoch 48/3000\n",
      "138230/138230 [==============================] - 14s 105us/sample - loss: 0.2067 - accuracy: 0.9166 - val_loss: 0.1939 - val_accuracy: 0.9202\n",
      "Epoch 49/3000\n",
      "138230/138230 [==============================] - 14s 104us/sample - loss: 0.2075 - accuracy: 0.9165 - val_loss: 0.2177 - val_accuracy: 0.9112\n",
      "Epoch 50/3000\n",
      "138230/138230 [==============================] - 14s 103us/sample - loss: 0.2064 - accuracy: 0.9170 - val_loss: 0.2036 - val_accuracy: 0.9169\n",
      "Epoch 51/3000\n",
      "138230/138230 [==============================] - 14s 102us/sample - loss: 0.2095 - accuracy: 0.9168 - val_loss: 0.1959 - val_accuracy: 0.9196\n",
      "Epoch 52/3000\n",
      "138230/138230 [==============================] - 14s 103us/sample - loss: 0.2034 - accuracy: 0.9177 - val_loss: 0.1999 - val_accuracy: 0.9192\n",
      "Epoch 53/3000\n",
      "138230/138230 [==============================] - 14s 104us/sample - loss: 0.2104 - accuracy: 0.9163 - val_loss: 0.2006 - val_accuracy: 0.9195\n",
      "Epoch 54/3000\n",
      "138230/138230 [==============================] - 14s 104us/sample - loss: 0.2045 - accuracy: 0.9179 - val_loss: 0.2135 - val_accuracy: 0.9124\n",
      "Epoch 55/3000\n",
      "138230/138230 [==============================] - 14s 103us/sample - loss: 0.2330 - accuracy: 0.9109 - val_loss: 0.2870 - val_accuracy: 0.9041\n",
      "Epoch 56/3000\n",
      "138230/138230 [==============================] - 14s 105us/sample - loss: 0.2292 - accuracy: 0.9126 - val_loss: 0.1981 - val_accuracy: 0.9188\n",
      "Epoch 57/3000\n",
      "138230/138230 [==============================] - 14s 105us/sample - loss: 0.2085 - accuracy: 0.9165 - val_loss: 0.1965 - val_accuracy: 0.9192\n",
      "Epoch 58/3000\n",
      "138230/138230 [==============================] - 15s 105us/sample - loss: 0.2089 - accuracy: 0.9165 - val_loss: 0.2316 - val_accuracy: 0.9119\n",
      "Epoch 59/3000\n",
      "138230/138230 [==============================] - 15s 108us/sample - loss: 0.2036 - accuracy: 0.9179 - val_loss: 0.2270 - val_accuracy: 0.9122\n",
      "Epoch 60/3000\n",
      "137728/138230 [============================>.] - ETA: 0s - loss: 0.2111 - accuracy: 0.9171"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-79ac69c3a30e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m history = model.fit(trainFeature, trainTarget, epochs = 3000, validation_split = 0.4, shuffle = True,\n\u001b[1;32m---> 27\u001b[1;33m                     verbose = 1, batch_size = 128, callbacks = [early_stop], use_multiprocessing =True)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m           steps_name='validation_steps')\n\u001b[0m\u001b[0;32m    430\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m           raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    529\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    529\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape = trainFeature.shape[1]))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(3, activation = \"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate = 0.0005)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", min_delta = 0.0005, patience = 100, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(trainFeature, trainTarget, epochs = 3000, validation_split = 0.4, shuffle = True,\n",
    "                    verbose = 1, batch_size = 128, callbacks = [early_stop], use_multiprocessing =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>dered_u</th>\n",
       "      <th>dered_g</th>\n",
       "      <th>dered_r</th>\n",
       "      <th>dered_i</th>\n",
       "      <th>dered_z</th>\n",
       "      <th>nObserve</th>\n",
       "      <th>nDetect</th>\n",
       "      <th>airmass_u</th>\n",
       "      <th>airmass_g</th>\n",
       "      <th>airmass_r</th>\n",
       "      <th>airmass_i</th>\n",
       "      <th>airmass_z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.263956</td>\n",
       "      <td>20.336773</td>\n",
       "      <td>19.009500</td>\n",
       "      <td>17.672439</td>\n",
       "      <td>16.939607</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>23.12426</td>\n",
       "      <td>20.25779</td>\n",
       "      <td>18.95512</td>\n",
       "      <td>17.63211</td>\n",
       "      <td>16.90894</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>1.189764</td>\n",
       "      <td>1.190681</td>\n",
       "      <td>1.188979</td>\n",
       "      <td>1.189355</td>\n",
       "      <td>1.190206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.786385</td>\n",
       "      <td>15.825426</td>\n",
       "      <td>15.536318</td>\n",
       "      <td>15.393535</td>\n",
       "      <td>15.350032</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>16.60765</td>\n",
       "      <td>15.68659</td>\n",
       "      <td>15.44004</td>\n",
       "      <td>15.32173</td>\n",
       "      <td>15.29608</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.022499</td>\n",
       "      <td>1.024105</td>\n",
       "      <td>1.020983</td>\n",
       "      <td>1.021730</td>\n",
       "      <td>1.023291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.660638</td>\n",
       "      <td>21.188727</td>\n",
       "      <td>20.221158</td>\n",
       "      <td>19.894949</td>\n",
       "      <td>19.634649</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>25.35365</td>\n",
       "      <td>20.99465</td>\n",
       "      <td>20.08727</td>\n",
       "      <td>19.79465</td>\n",
       "      <td>19.55518</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.205399</td>\n",
       "      <td>1.206058</td>\n",
       "      <td>1.204874</td>\n",
       "      <td>1.205120</td>\n",
       "      <td>1.205712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.453429</td>\n",
       "      <td>20.699170</td>\n",
       "      <td>19.042368</td>\n",
       "      <td>18.324152</td>\n",
       "      <td>17.982649</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>23.77140</td>\n",
       "      <td>20.43384</td>\n",
       "      <td>18.86299</td>\n",
       "      <td>18.19028</td>\n",
       "      <td>17.87592</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1.193946</td>\n",
       "      <td>1.194285</td>\n",
       "      <td>1.193738</td>\n",
       "      <td>1.193826</td>\n",
       "      <td>1.194099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.700402</td>\n",
       "      <td>15.506766</td>\n",
       "      <td>14.978825</td>\n",
       "      <td>14.675482</td>\n",
       "      <td>14.515478</td>\n",
       "      <td>0.014955</td>\n",
       "      <td>16.51564</td>\n",
       "      <td>15.37761</td>\n",
       "      <td>14.88758</td>\n",
       "      <td>14.60550</td>\n",
       "      <td>14.45388</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.172191</td>\n",
       "      <td>1.178541</td>\n",
       "      <td>1.166002</td>\n",
       "      <td>1.169076</td>\n",
       "      <td>1.175344</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319995</th>\n",
       "      <td>18.365648</td>\n",
       "      <td>17.240883</td>\n",
       "      <td>16.773898</td>\n",
       "      <td>16.484970</td>\n",
       "      <td>16.340403</td>\n",
       "      <td>0.051988</td>\n",
       "      <td>18.13280</td>\n",
       "      <td>17.04065</td>\n",
       "      <td>16.63744</td>\n",
       "      <td>16.38606</td>\n",
       "      <td>16.28741</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.093010</td>\n",
       "      <td>1.088828</td>\n",
       "      <td>1.097310</td>\n",
       "      <td>1.095145</td>\n",
       "      <td>1.090905</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319996</th>\n",
       "      <td>18.685639</td>\n",
       "      <td>17.665802</td>\n",
       "      <td>17.190434</td>\n",
       "      <td>16.816858</td>\n",
       "      <td>16.636688</td>\n",
       "      <td>0.087261</td>\n",
       "      <td>18.52074</td>\n",
       "      <td>17.51310</td>\n",
       "      <td>17.08711</td>\n",
       "      <td>16.74363</td>\n",
       "      <td>16.60173</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.051689</td>\n",
       "      <td>1.050838</td>\n",
       "      <td>1.052640</td>\n",
       "      <td>1.052152</td>\n",
       "      <td>1.051252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319997</th>\n",
       "      <td>21.188972</td>\n",
       "      <td>18.423357</td>\n",
       "      <td>17.295610</td>\n",
       "      <td>16.901072</td>\n",
       "      <td>16.684127</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>20.98896</td>\n",
       "      <td>18.30760</td>\n",
       "      <td>17.21518</td>\n",
       "      <td>16.84030</td>\n",
       "      <td>16.63555</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>1.193259</td>\n",
       "      <td>1.194140</td>\n",
       "      <td>1.192509</td>\n",
       "      <td>1.192868</td>\n",
       "      <td>1.193683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319998</th>\n",
       "      <td>18.847187</td>\n",
       "      <td>17.318605</td>\n",
       "      <td>16.505729</td>\n",
       "      <td>16.180571</td>\n",
       "      <td>15.911624</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>16.38998</td>\n",
       "      <td>15.40578</td>\n",
       "      <td>15.18229</td>\n",
       "      <td>15.19693</td>\n",
       "      <td>15.17935</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.172458</td>\n",
       "      <td>1.172561</td>\n",
       "      <td>1.172481</td>\n",
       "      <td>1.172454</td>\n",
       "      <td>1.172493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319999</th>\n",
       "      <td>19.860438</td>\n",
       "      <td>18.819866</td>\n",
       "      <td>18.515579</td>\n",
       "      <td>18.414884</td>\n",
       "      <td>18.307998</td>\n",
       "      <td>-0.000965</td>\n",
       "      <td>19.82565</td>\n",
       "      <td>18.78191</td>\n",
       "      <td>18.49081</td>\n",
       "      <td>18.39869</td>\n",
       "      <td>18.30977</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057076</td>\n",
       "      <td>1.056240</td>\n",
       "      <td>1.057976</td>\n",
       "      <td>1.057518</td>\n",
       "      <td>1.056650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287980 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                u          g          r          i          z  redshift  \\\n",
       "0       23.263956  20.336773  19.009500  17.672439  16.939607 -0.000081   \n",
       "2       16.786385  15.825426  15.536318  15.393535  15.350032  0.000472   \n",
       "3       25.660638  21.188727  20.221158  19.894949  19.634649  0.000006   \n",
       "4       24.453429  20.699170  19.042368  18.324152  17.982649 -0.000033   \n",
       "5       16.700402  15.506766  14.978825  14.675482  14.515478  0.014955   \n",
       "...           ...        ...        ...        ...        ...       ...   \n",
       "319995  18.365648  17.240883  16.773898  16.484970  16.340403  0.051988   \n",
       "319996  18.685639  17.665802  17.190434  16.816858  16.636688  0.087261   \n",
       "319997  21.188972  18.423357  17.295610  16.901072  16.684127 -0.000010   \n",
       "319998  18.847187  17.318605  16.505729  16.180571  15.911624 -0.000045   \n",
       "319999  19.860438  18.819866  18.515579  18.414884  18.307998 -0.000965   \n",
       "\n",
       "         dered_u   dered_g   dered_r   dered_i   dered_z  nObserve  nDetect  \\\n",
       "0       23.12426  20.25779  18.95512  17.63211  16.90894        18       18   \n",
       "2       16.60765  15.68659  15.44004  15.32173  15.29608         2        2   \n",
       "3       25.35365  20.99465  20.08727  19.79465  19.55518         4        3   \n",
       "4       23.77140  20.43384  18.86299  18.19028  17.87592        13       12   \n",
       "5       16.51564  15.37761  14.88758  14.60550  14.45388         1        1   \n",
       "...          ...       ...       ...       ...       ...       ...      ...   \n",
       "319995  18.13280  17.04065  16.63744  16.38606  16.28741         2        2   \n",
       "319996  18.52074  17.51310  17.08711  16.74363  16.60173         2        2   \n",
       "319997  20.98896  18.30760  17.21518  16.84030  16.63555        31       30   \n",
       "319998  16.38998  15.40578  15.18229  15.19693  15.17935         1        1   \n",
       "319999  19.82565  18.78191  18.49081  18.39869  18.30977         1        1   \n",
       "\n",
       "        airmass_u  airmass_g  airmass_r  airmass_i  airmass_z  class  \n",
       "0        1.189764   1.190681   1.188979   1.189355   1.190206      0  \n",
       "2        1.022499   1.024105   1.020983   1.021730   1.023291      0  \n",
       "3        1.205399   1.206058   1.204874   1.205120   1.205712      0  \n",
       "4        1.193946   1.194285   1.193738   1.193826   1.194099      0  \n",
       "5        1.172191   1.178541   1.166002   1.169076   1.175344      2  \n",
       "...           ...        ...        ...        ...        ...    ...  \n",
       "319995   1.093010   1.088828   1.097310   1.095145   1.090905      2  \n",
       "319996   1.051689   1.050838   1.052640   1.052152   1.051252      1  \n",
       "319997   1.193259   1.194140   1.192509   1.192868   1.193683      0  \n",
       "319998   1.172458   1.172561   1.172481   1.172454   1.172493      0  \n",
       "319999   1.057076   1.056240   1.057976   1.057518   1.056650      0  \n",
       "\n",
       "[287980 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_model(hp) :\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Input(shape = (trainFeature.shape[1])))\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), 32, 512, 32),\n",
    "                               activation=\"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "        model.add(keras.layers.AlphaDropout(rate = hp.Choice(\"rate\", values = [0.1, 0.2, 0.3, 0.4, 0.5])))\n",
    "\n",
    "    model.add(keras.layers.Dense(3, activation = \"softmax\"))\n",
    "\n",
    "    optimizer = keras.optimizers.Nadam(hp.Choice(\"learning_rate\", values = [0.005, 0.001, 0.0005, 0.0001]))\n",
    "\n",
    "    model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\")\n",
    "    return model\n",
    "\n",
    "tuner = kt.BayesianOptimization(make_model, objective = \"val_loss\", max_trials = 21, executions_per_trial = 11, project_name = \"Astro_SNN\")\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", min_delta = 0.0001, patience = 30, mode = \"min\", restore_best_weights = True)\n",
    "tuner.search(trainFeature, trainTarget, epochs = 3000, validation_split = 0.4, shuffle = True, use_multiprocessing = True, callbacks = [early_stop], batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(testFeature)\n",
    "sum(np.argmax(result, axis = 1) == np.argmax(testTarget, axis = 1)) / len(testTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv(\"./RawData/test.csv\")\n",
    "submit = pd.read_csv(\"./RawData/sample_submission.csv\")\n",
    "result = model.predict(pred.drop(\"id\", axis = \"columns\"))\n",
    "submit[\"class\"] = np.argmax(result, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
