{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras\n",
    "from xgboost import plot_importance\n",
    "from plotly.offline import plot\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(connected = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Family\\\\Documents\\\\GitHub\\\\Astro'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./RawData/train.csv\")\n",
    "train = train.drop([\"id\"], axis = \"columns\")\n",
    "train = train.loc[train[\"z\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(n_estimators = 300)\n",
    "clf.fit(train)\n",
    "pred = clf.predict(train)\n",
    "train[\"anomaly\"] = pred\n",
    "\n",
    "train = train.loc[train[\"anomaly\"] != -1]\n",
    "train = train.drop(\"anomaly\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>dered_u</th>\n",
       "      <th>dered_g</th>\n",
       "      <th>dered_r</th>\n",
       "      <th>dered_i</th>\n",
       "      <th>dered_z</th>\n",
       "      <th>nObserve</th>\n",
       "      <th>nDetect</th>\n",
       "      <th>airmass_u</th>\n",
       "      <th>airmass_g</th>\n",
       "      <th>airmass_r</th>\n",
       "      <th>airmass_i</th>\n",
       "      <th>airmass_z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "      <td>265417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.560975</td>\n",
       "      <td>18.169334</td>\n",
       "      <td>17.522373</td>\n",
       "      <td>17.150804</td>\n",
       "      <td>16.936455</td>\n",
       "      <td>0.060422</td>\n",
       "      <td>19.380671</td>\n",
       "      <td>18.025938</td>\n",
       "      <td>17.422884</td>\n",
       "      <td>17.076885</td>\n",
       "      <td>16.881950</td>\n",
       "      <td>5.611385</td>\n",
       "      <td>5.487557</td>\n",
       "      <td>1.162278</td>\n",
       "      <td>1.162575</td>\n",
       "      <td>1.162105</td>\n",
       "      <td>1.162175</td>\n",
       "      <td>1.162410</td>\n",
       "      <td>1.214753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.430487</td>\n",
       "      <td>1.135651</td>\n",
       "      <td>1.005425</td>\n",
       "      <td>0.968910</td>\n",
       "      <td>1.006891</td>\n",
       "      <td>0.312827</td>\n",
       "      <td>1.390727</td>\n",
       "      <td>1.107456</td>\n",
       "      <td>0.989865</td>\n",
       "      <td>0.961322</td>\n",
       "      <td>1.003426</td>\n",
       "      <td>7.859775</td>\n",
       "      <td>7.645241</td>\n",
       "      <td>0.096617</td>\n",
       "      <td>0.097336</td>\n",
       "      <td>0.096090</td>\n",
       "      <td>0.096329</td>\n",
       "      <td>0.096952</td>\n",
       "      <td>0.902958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.081344</td>\n",
       "      <td>14.975357</td>\n",
       "      <td>14.043669</td>\n",
       "      <td>14.043790</td>\n",
       "      <td>11.056773</td>\n",
       "      <td>-86.618158</td>\n",
       "      <td>14.537490</td>\n",
       "      <td>14.083900</td>\n",
       "      <td>13.912000</td>\n",
       "      <td>13.982440</td>\n",
       "      <td>13.567770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000059</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>1.000179</td>\n",
       "      <td>1.000109</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.721727</td>\n",
       "      <td>17.483948</td>\n",
       "      <td>16.892467</td>\n",
       "      <td>16.540688</td>\n",
       "      <td>16.308016</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>18.575800</td>\n",
       "      <td>17.364950</td>\n",
       "      <td>16.807660</td>\n",
       "      <td>16.474240</td>\n",
       "      <td>16.256900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.086500</td>\n",
       "      <td>1.086905</td>\n",
       "      <td>1.086241</td>\n",
       "      <td>1.086425</td>\n",
       "      <td>1.086712</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.331423</td>\n",
       "      <td>18.069807</td>\n",
       "      <td>17.462466</td>\n",
       "      <td>17.089812</td>\n",
       "      <td>16.859418</td>\n",
       "      <td>0.057165</td>\n",
       "      <td>19.186390</td>\n",
       "      <td>17.956340</td>\n",
       "      <td>17.383010</td>\n",
       "      <td>17.028680</td>\n",
       "      <td>16.813200</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.173206</td>\n",
       "      <td>1.172478</td>\n",
       "      <td>1.173740</td>\n",
       "      <td>1.173450</td>\n",
       "      <td>1.172943</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.039879</td>\n",
       "      <td>18.621714</td>\n",
       "      <td>17.933373</td>\n",
       "      <td>17.585967</td>\n",
       "      <td>17.402567</td>\n",
       "      <td>0.097859</td>\n",
       "      <td>19.857050</td>\n",
       "      <td>18.480200</td>\n",
       "      <td>17.822720</td>\n",
       "      <td>17.506110</td>\n",
       "      <td>17.342940</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.210531</td>\n",
       "      <td>1.209674</td>\n",
       "      <td>1.210891</td>\n",
       "      <td>1.210634</td>\n",
       "      <td>1.209893</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>37.429989</td>\n",
       "      <td>30.025962</td>\n",
       "      <td>31.963770</td>\n",
       "      <td>28.494407</td>\n",
       "      <td>30.192485</td>\n",
       "      <td>62.323343</td>\n",
       "      <td>29.672990</td>\n",
       "      <td>29.925390</td>\n",
       "      <td>25.558920</td>\n",
       "      <td>28.227670</td>\n",
       "      <td>28.220950</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.530074</td>\n",
       "      <td>1.539729</td>\n",
       "      <td>1.520720</td>\n",
       "      <td>1.525356</td>\n",
       "      <td>1.534856</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   u              g              r              i  \\\n",
       "count  265417.000000  265417.000000  265417.000000  265417.000000   \n",
       "mean       19.560975      18.169334      17.522373      17.150804   \n",
       "std         1.430487       1.135651       1.005425       0.968910   \n",
       "min        10.081344      14.975357      14.043669      14.043790   \n",
       "25%        18.721727      17.483948      16.892467      16.540688   \n",
       "50%        19.331423      18.069807      17.462466      17.089812   \n",
       "75%        20.039879      18.621714      17.933373      17.585967   \n",
       "max        37.429989      30.025962      31.963770      28.494407   \n",
       "\n",
       "                   z       redshift        dered_u        dered_g  \\\n",
       "count  265417.000000  265417.000000  265417.000000  265417.000000   \n",
       "mean       16.936455       0.060422      19.380671      18.025938   \n",
       "std         1.006891       0.312827       1.390727       1.107456   \n",
       "min        11.056773     -86.618158      14.537490      14.083900   \n",
       "25%        16.308016       0.000091      18.575800      17.364950   \n",
       "50%        16.859418       0.057165      19.186390      17.956340   \n",
       "75%        17.402567       0.097859      19.857050      18.480200   \n",
       "max        30.192485      62.323343      29.672990      29.925390   \n",
       "\n",
       "             dered_r        dered_i        dered_z       nObserve  \\\n",
       "count  265417.000000  265417.000000  265417.000000  265417.000000   \n",
       "mean       17.422884      17.076885      16.881950       5.611385   \n",
       "std         0.989865       0.961322       1.003426       7.859775   \n",
       "min        13.912000      13.982440      13.567770       1.000000   \n",
       "25%        16.807660      16.474240      16.256900       1.000000   \n",
       "50%        17.383010      17.028680      16.813200       2.000000   \n",
       "75%        17.822720      17.506110      17.342940       4.000000   \n",
       "max        25.558920      28.227670      28.220950      43.000000   \n",
       "\n",
       "             nDetect      airmass_u      airmass_g      airmass_r  \\\n",
       "count  265417.000000  265417.000000  265417.000000  265417.000000   \n",
       "mean        5.487557       1.162278       1.162575       1.162105   \n",
       "std         7.645241       0.096617       0.097336       0.096090   \n",
       "min         1.000000       1.000059       1.000012       1.000179   \n",
       "25%         1.000000       1.086500       1.086905       1.086241   \n",
       "50%         2.000000       1.173206       1.172478       1.173740   \n",
       "75%         4.000000       1.210531       1.209674       1.210891   \n",
       "max        41.000000       1.530074       1.539729       1.520720   \n",
       "\n",
       "           airmass_i      airmass_z          class  \n",
       "count  265417.000000  265417.000000  265417.000000  \n",
       "mean        1.162175       1.162410       1.214753  \n",
       "std         0.096329       0.096952       0.902958  \n",
       "min         1.000109       1.000027       0.000000  \n",
       "25%         1.086425       1.086712       0.000000  \n",
       "50%         1.173450       1.172943       2.000000  \n",
       "75%         1.210634       1.209893       2.000000  \n",
       "max         1.525356       1.534856       2.000000  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ug'] = train['dered_u'] - train['dered_g']\n",
    "train['gr'] = train['dered_g'] - train['dered_r']\n",
    "train['ri'] = train['dered_r'] - train['dered_i']\n",
    "train['iz'] = train['dered_i'] - train['dered_z']\n",
    "\n",
    "del train['dered_u']\n",
    "del train['dered_g']\n",
    "del train['dered_r']\n",
    "del train['dered_i']\n",
    "del train[\"dered_z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'u'}>,\n",
       "        <AxesSubplot:title={'center':'g'}>,\n",
       "        <AxesSubplot:title={'center':'r'}>,\n",
       "        <AxesSubplot:title={'center':'i'}>],\n",
       "       [<AxesSubplot:title={'center':'z'}>,\n",
       "        <AxesSubplot:title={'center':'redshift'}>,\n",
       "        <AxesSubplot:title={'center':'nObserve'}>,\n",
       "        <AxesSubplot:title={'center':'nDetect'}>],\n",
       "       [<AxesSubplot:title={'center':'airmass_u'}>,\n",
       "        <AxesSubplot:title={'center':'airmass_g'}>,\n",
       "        <AxesSubplot:title={'center':'airmass_r'}>,\n",
       "        <AxesSubplot:title={'center':'airmass_i'}>],\n",
       "       [<AxesSubplot:title={'center':'airmass_z'}>,\n",
       "        <AxesSubplot:title={'center':'class'}>,\n",
       "        <AxesSubplot:title={'center':'ug'}>,\n",
       "        <AxesSubplot:title={'center':'gr'}>],\n",
       "       [<AxesSubplot:title={'center':'ri'}>,\n",
       "        <AxesSubplot:title={'center':'iz'}>, <AxesSubplot:>,\n",
       "        <AxesSubplot:>]], dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.hist(figsize = (12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86728 36017 140433\n"
     ]
    }
   ],
   "source": [
    "print(sum(train[\"class\"] == 0), sum(train[\"class\"] == 1), sum(train[\"class\"] == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(train, test_size = .2)\n",
    "\n",
    "trainTarget = keras.utils.to_categorical(train[\"class\"])\n",
    "testTarget = keras.utils.to_categorical(test[\"class\"])\n",
    "\n",
    "trainFeature = train.drop([\"class\"], axis = \"columns\")\n",
    "testFeature = test.drop([\"class\"], axis = \"columns\")\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "res = scale.fit(trainFeature)\n",
    "res = scale.transform(trainFeature)\n",
    "trainFeature = np.array(res)\n",
    "\n",
    "res = scale.transform(testFeature)\n",
    "testFeature = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 9.8935 - accuracy: 0.4949 - val_loss: 1.0866 - val_accuracy: 0.5416\n",
      "Epoch 2/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 9.7487 - accuracy: 0.5459 - val_loss: 1.0499 - val_accuracy: 0.5483\n",
      "Epoch 3/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 9.3753 - accuracy: 0.5551 - val_loss: 0.9752 - val_accuracy: 0.5818\n",
      "Epoch 4/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 8.9804 - accuracy: 0.6171 - val_loss: 0.9134 - val_accuracy: 0.6573\n",
      "Epoch 5/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 8.7296 - accuracy: 0.6652 - val_loss: 0.8998 - val_accuracy: 0.6720\n",
      "Epoch 6/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 8.5791 - accuracy: 0.6734 - val_loss: 0.8810 - val_accuracy: 0.6756\n",
      "Epoch 7/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 8.4599 - accuracy: 0.6757 - val_loss: 0.8646 - val_accuracy: 0.6745\n",
      "Epoch 8/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 8.4013 - accuracy: 0.6710 - val_loss: 0.8476 - val_accuracy: 0.6807\n",
      "Epoch 9/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 8.1872 - accuracy: 0.6815 - val_loss: 0.8191 - val_accuracy: 0.6798\n",
      "Epoch 10/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 7.9779 - accuracy: 0.6906 - val_loss: 0.7921 - val_accuracy: 0.6934\n",
      "Epoch 11/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 7.8011 - accuracy: 0.7003 - val_loss: 0.7664 - val_accuracy: 0.7030\n",
      "Epoch 12/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 7.6706 - accuracy: 0.7086 - val_loss: 0.7719 - val_accuracy: 0.7188\n",
      "Epoch 13/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 7.8245 - accuracy: 0.6962 - val_loss: 0.7629 - val_accuracy: 0.6999\n",
      "Epoch 14/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 7.5382 - accuracy: 0.7102 - val_loss: 0.7458 - val_accuracy: 0.7217\n",
      "Epoch 15/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 7.3508 - accuracy: 0.7198 - val_loss: 0.7135 - val_accuracy: 0.7203\n",
      "Epoch 16/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 7.2119 - accuracy: 0.7253 - val_loss: 0.7024 - val_accuracy: 0.7249\n",
      "Epoch 17/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 7.1068 - accuracy: 0.7298 - val_loss: 0.6898 - val_accuracy: 0.7303\n",
      "Epoch 18/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 7.0236 - accuracy: 0.7320 - val_loss: 0.6831 - val_accuracy: 0.7344\n",
      "Epoch 19/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.9461 - accuracy: 0.7340 - val_loss: 0.6808 - val_accuracy: 0.7354\n",
      "Epoch 20/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.9190 - accuracy: 0.7338 - val_loss: 0.6696 - val_accuracy: 0.7346\n",
      "Epoch 21/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 6.8323 - accuracy: 0.7346 - val_loss: 0.6744 - val_accuracy: 0.7349\n",
      "Epoch 22/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.8175 - accuracy: 0.7327 - val_loss: 0.6681 - val_accuracy: 0.7350\n",
      "Epoch 23/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 6.7814 - accuracy: 0.7324 - val_loss: 0.6828 - val_accuracy: 0.7279\n",
      "Epoch 24/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 6.7423 - accuracy: 0.7320 - val_loss: 0.6548 - val_accuracy: 0.7297\n",
      "Epoch 25/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 6.6760 - accuracy: 0.7351 - val_loss: 0.6486 - val_accuracy: 0.7374\n",
      "Epoch 26/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.6024 - accuracy: 0.7380 - val_loss: 0.6464 - val_accuracy: 0.7377\n",
      "Epoch 27/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.5824 - accuracy: 0.7370 - val_loss: 0.6422 - val_accuracy: 0.7388\n",
      "Epoch 28/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.5568 - accuracy: 0.7366 - val_loss: 0.6523 - val_accuracy: 0.7331\n",
      "Epoch 29/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.5768 - accuracy: 0.7330 - val_loss: 0.6359 - val_accuracy: 0.7376\n",
      "Epoch 30/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.4779 - accuracy: 0.7398 - val_loss: 0.6413 - val_accuracy: 0.7351\n",
      "Epoch 31/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.4935 - accuracy: 0.7359 - val_loss: 0.6245 - val_accuracy: 0.7408\n",
      "Epoch 32/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.5134 - accuracy: 0.7356 - val_loss: 0.6318 - val_accuracy: 0.7381\n",
      "Epoch 33/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.4312 - accuracy: 0.7386 - val_loss: 0.6324 - val_accuracy: 0.7379\n",
      "Epoch 34/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.3966 - accuracy: 0.7411 - val_loss: 0.6200 - val_accuracy: 0.7406\n",
      "Epoch 35/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.4539 - accuracy: 0.7347 - val_loss: 0.6203 - val_accuracy: 0.7402\n",
      "Epoch 36/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.4356 - accuracy: 0.7336 - val_loss: 0.6243 - val_accuracy: 0.7335\n",
      "Epoch 37/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.3844 - accuracy: 0.7382 - val_loss: 0.6321 - val_accuracy: 0.7363\n",
      "Epoch 38/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.3947 - accuracy: 0.7358 - val_loss: 0.6200 - val_accuracy: 0.7413\n",
      "Epoch 39/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.3222 - accuracy: 0.7425 - val_loss: 0.6182 - val_accuracy: 0.7410\n",
      "Epoch 40/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.2965 - accuracy: 0.7419 - val_loss: 0.6225 - val_accuracy: 0.7419\n",
      "Epoch 41/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.3572 - accuracy: 0.7361 - val_loss: 0.6160 - val_accuracy: 0.7398\n",
      "Epoch 42/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.3110 - accuracy: 0.7384 - val_loss: 0.6228 - val_accuracy: 0.7391\n",
      "Epoch 43/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.2860 - accuracy: 0.7403 - val_loss: 0.6171 - val_accuracy: 0.7423\n",
      "Epoch 44/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.3123 - accuracy: 0.7374 - val_loss: 0.6271 - val_accuracy: 0.7363\n",
      "Epoch 45/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.2978 - accuracy: 0.7375 - val_loss: 0.6183 - val_accuracy: 0.7405\n",
      "Epoch 46/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.2580 - accuracy: 0.7408 - val_loss: 0.6108 - val_accuracy: 0.7440\n",
      "Epoch 47/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.2435 - accuracy: 0.7420 - val_loss: 0.6151 - val_accuracy: 0.7386\n",
      "Epoch 48/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.2704 - accuracy: 0.7389 - val_loss: 0.6166 - val_accuracy: 0.7379\n",
      "Epoch 49/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.2508 - accuracy: 0.7389 - val_loss: 0.6173 - val_accuracy: 0.7400\n",
      "Epoch 50/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.1937 - accuracy: 0.7439 - val_loss: 0.6086 - val_accuracy: 0.7433\n",
      "Epoch 51/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.2097 - accuracy: 0.7425 - val_loss: 0.6117 - val_accuracy: 0.7406\n",
      "Epoch 52/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.2412 - accuracy: 0.7385 - val_loss: 0.6122 - val_accuracy: 0.7408\n",
      "Epoch 53/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1751 - accuracy: 0.7430 - val_loss: 0.6093 - val_accuracy: 0.7424\n",
      "Epoch 54/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1722 - accuracy: 0.7433 - val_loss: 0.6083 - val_accuracy: 0.7430\n",
      "Epoch 55/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1611 - accuracy: 0.7433 - val_loss: 0.6098 - val_accuracy: 0.7409\n",
      "Epoch 56/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1954 - accuracy: 0.7400 - val_loss: 0.6076 - val_accuracy: 0.7442\n",
      "Epoch 57/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1509 - accuracy: 0.7424 - val_loss: 0.6098 - val_accuracy: 0.7402\n",
      "Epoch 58/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1676 - accuracy: 0.7422 - val_loss: 0.6129 - val_accuracy: 0.7384\n",
      "Epoch 59/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1832 - accuracy: 0.7406 - val_loss: 0.6094 - val_accuracy: 0.7437\n",
      "Epoch 60/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.1135 - accuracy: 0.7450 - val_loss: 0.6052 - val_accuracy: 0.7454\n",
      "Epoch 61/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1175 - accuracy: 0.7453 - val_loss: 0.6078 - val_accuracy: 0.7445\n",
      "Epoch 62/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.0873 - accuracy: 0.7460 - val_loss: 0.6015 - val_accuracy: 0.7486\n",
      "Epoch 63/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1792 - accuracy: 0.7386 - val_loss: 0.6073 - val_accuracy: 0.7442\n",
      "Epoch 64/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 6.1323 - accuracy: 0.7410 - val_loss: 0.6095 - val_accuracy: 0.7431\n",
      "Epoch 65/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.1349 - accuracy: 0.7419 - val_loss: 0.6102 - val_accuracy: 0.7422\n",
      "Epoch 66/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.1013 - accuracy: 0.7451 - val_loss: 0.6023 - val_accuracy: 0.7482\n",
      "Epoch 67/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.0716 - accuracy: 0.7461 - val_loss: 0.6009 - val_accuracy: 0.7476\n",
      "Epoch 68/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.0643 - accuracy: 0.7470 - val_loss: 0.6018 - val_accuracy: 0.7487\n",
      "Epoch 69/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1131 - accuracy: 0.7425 - val_loss: 0.6210 - val_accuracy: 0.7326\n",
      "Epoch 70/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.1008 - accuracy: 0.7403 - val_loss: 0.6056 - val_accuracy: 0.7444\n",
      "Epoch 71/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.0573 - accuracy: 0.7464 - val_loss: 0.5977 - val_accuracy: 0.7502\n",
      "Epoch 72/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.0570 - accuracy: 0.7471 - val_loss: 0.6094 - val_accuracy: 0.7416\n",
      "Epoch 73/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.0629 - accuracy: 0.7458 - val_loss: 0.6185 - val_accuracy: 0.7339\n",
      "Epoch 74/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.0907 - accuracy: 0.7408 - val_loss: 0.6003 - val_accuracy: 0.7481\n",
      "Epoch 75/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1142 - accuracy: 0.7391 - val_loss: 0.6127 - val_accuracy: 0.7393\n",
      "Epoch 76/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.0434 - accuracy: 0.7454 - val_loss: 0.6080 - val_accuracy: 0.7419\n",
      "Epoch 77/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.0431 - accuracy: 0.7457 - val_loss: 0.6056 - val_accuracy: 0.7434\n",
      "Epoch 78/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.0339 - accuracy: 0.7456 - val_loss: 0.5943 - val_accuracy: 0.7524\n",
      "Epoch 79/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.9944 - accuracy: 0.7498 - val_loss: 0.5959 - val_accuracy: 0.7506\n",
      "Epoch 80/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.9856 - accuracy: 0.7495 - val_loss: 0.5954 - val_accuracy: 0.7531\n",
      "Epoch 81/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.9674 - accuracy: 0.7509 - val_loss: 0.5961 - val_accuracy: 0.7506\n",
      "Epoch 82/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.9981 - accuracy: 0.7489 - val_loss: 0.6056 - val_accuracy: 0.7415\n",
      "Epoch 83/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.9981 - accuracy: 0.7472 - val_loss: 0.6211 - val_accuracy: 0.7283\n",
      "Epoch 84/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.0519 - accuracy: 0.7412 - val_loss: 0.6000 - val_accuracy: 0.7460\n",
      "Epoch 85/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.9812 - accuracy: 0.7471 - val_loss: 0.6033 - val_accuracy: 0.7455\n",
      "Epoch 86/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.9688 - accuracy: 0.7506 - val_loss: 0.5900 - val_accuracy: 0.7559\n",
      "Epoch 87/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.9940 - accuracy: 0.7492 - val_loss: 0.5995 - val_accuracy: 0.7461\n",
      "Epoch 88/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.9337 - accuracy: 0.7517 - val_loss: 0.5969 - val_accuracy: 0.7478\n",
      "Epoch 89/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.9208 - accuracy: 0.7531 - val_loss: 0.5885 - val_accuracy: 0.7563\n",
      "Epoch 90/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.0675 - accuracy: 0.7421 - val_loss: 0.6046 - val_accuracy: 0.7433\n",
      "Epoch 91/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.0144 - accuracy: 0.7437 - val_loss: 0.6139 - val_accuracy: 0.7307\n",
      "Epoch 92/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1293 - accuracy: 0.7330 - val_loss: 0.6240 - val_accuracy: 0.7329\n",
      "Epoch 93/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1897 - accuracy: 0.7267 - val_loss: 0.6093 - val_accuracy: 0.7372\n",
      "Epoch 94/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.0457 - accuracy: 0.7390 - val_loss: 0.6089 - val_accuracy: 0.7357\n",
      "Epoch 95/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.0038 - accuracy: 0.7433 - val_loss: 0.6024 - val_accuracy: 0.7432\n",
      "Epoch 96/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.9446 - accuracy: 0.7498 - val_loss: 0.6124 - val_accuracy: 0.7329\n",
      "Epoch 97/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.9627 - accuracy: 0.7482 - val_loss: 0.5945 - val_accuracy: 0.7506\n",
      "Epoch 98/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8972 - accuracy: 0.7541 - val_loss: 0.5903 - val_accuracy: 0.7541\n",
      "Epoch 99/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8871 - accuracy: 0.7558 - val_loss: 0.5874 - val_accuracy: 0.7580\n",
      "Epoch 100/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8594 - accuracy: 0.7581 - val_loss: 0.5882 - val_accuracy: 0.7550\n",
      "Epoch 101/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.8865 - accuracy: 0.7549 - val_loss: 0.5842 - val_accuracy: 0.7588\n",
      "Epoch 102/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.8638 - accuracy: 0.7566 - val_loss: 0.5898 - val_accuracy: 0.7512\n",
      "Epoch 103/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.8518 - accuracy: 0.7579 - val_loss: 0.5868 - val_accuracy: 0.7543\n",
      "Epoch 104/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.9210 - accuracy: 0.7515 - val_loss: 0.6021 - val_accuracy: 0.7460\n",
      "Epoch 105/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.0586 - accuracy: 0.7392 - val_loss: 0.6264 - val_accuracy: 0.7176\n",
      "Epoch 106/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.9728 - accuracy: 0.7418 - val_loss: 0.5935 - val_accuracy: 0.7495\n",
      "Epoch 107/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.8726 - accuracy: 0.7530 - val_loss: 0.5874 - val_accuracy: 0.7560\n",
      "Epoch 108/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.8345 - accuracy: 0.7591 - val_loss: 0.5847 - val_accuracy: 0.7534\n",
      "Epoch 109/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.9997 - accuracy: 0.7440 - val_loss: 0.5899 - val_accuracy: 0.7572\n",
      "Epoch 110/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.9358 - accuracy: 0.7466 - val_loss: 0.6011 - val_accuracy: 0.7391\n",
      "Epoch 111/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8413 - accuracy: 0.7547 - val_loss: 0.5818 - val_accuracy: 0.7570\n",
      "Epoch 112/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.8241 - accuracy: 0.7601 - val_loss: 0.5860 - val_accuracy: 0.7565\n",
      "Epoch 113/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7841 - accuracy: 0.7623 - val_loss: 0.5803 - val_accuracy: 0.7597\n",
      "Epoch 114/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7982 - accuracy: 0.7614 - val_loss: 0.5754 - val_accuracy: 0.7651\n",
      "Epoch 115/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7647 - accuracy: 0.7638 - val_loss: 0.5745 - val_accuracy: 0.7639\n",
      "Epoch 116/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.7466 - accuracy: 0.7648 - val_loss: 0.5733 - val_accuracy: 0.7655\n",
      "Epoch 117/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.7515 - accuracy: 0.7656 - val_loss: 0.5714 - val_accuracy: 0.7663\n",
      "Epoch 118/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.7641 - accuracy: 0.7644 - val_loss: 0.5778 - val_accuracy: 0.7618\n",
      "Epoch 119/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.7741 - accuracy: 0.7618 - val_loss: 0.5739 - val_accuracy: 0.7651\n",
      "Epoch 120/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7425 - accuracy: 0.7632 - val_loss: 0.5689 - val_accuracy: 0.7688\n",
      "Epoch 121/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.7083 - accuracy: 0.7671 - val_loss: 0.5694 - val_accuracy: 0.7674\n",
      "Epoch 122/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.7206 - accuracy: 0.7650 - val_loss: 0.5682 - val_accuracy: 0.7687\n",
      "Epoch 123/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.7203 - accuracy: 0.7662 - val_loss: 0.5674 - val_accuracy: 0.7681\n",
      "Epoch 124/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.7034 - accuracy: 0.7669 - val_loss: 0.5842 - val_accuracy: 0.7547\n",
      "Epoch 125/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.7596 - accuracy: 0.7624 - val_loss: 0.5798 - val_accuracy: 0.7563\n",
      "Epoch 126/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.1643 - accuracy: 0.7313 - val_loss: 0.6412 - val_accuracy: 0.7034\n",
      "Epoch 127/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 6.0791 - accuracy: 0.7267 - val_loss: 0.5928 - val_accuracy: 0.7521\n",
      "Epoch 128/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8540 - accuracy: 0.7477 - val_loss: 0.5702 - val_accuracy: 0.7648\n",
      "Epoch 129/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7211 - accuracy: 0.7650 - val_loss: 0.5816 - val_accuracy: 0.7571\n",
      "Epoch 130/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.7108 - accuracy: 0.7657 - val_loss: 0.5790 - val_accuracy: 0.7587\n",
      "Epoch 131/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.7658 - accuracy: 0.7599 - val_loss: 0.5841 - val_accuracy: 0.7587\n",
      "Epoch 132/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.7256 - accuracy: 0.7603 - val_loss: 0.5801 - val_accuracy: 0.7596\n",
      "Epoch 133/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.6805 - accuracy: 0.7678 - val_loss: 0.5703 - val_accuracy: 0.7626\n",
      "Epoch 134/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.6482 - accuracy: 0.7702 - val_loss: 0.5659 - val_accuracy: 0.7668\n",
      "Epoch 135/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.6584 - accuracy: 0.7677 - val_loss: 0.5664 - val_accuracy: 0.7655\n",
      "Epoch 136/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7053 - accuracy: 0.7625 - val_loss: 0.6116 - val_accuracy: 0.7251\n",
      "Epoch 137/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8976 - accuracy: 0.7461 - val_loss: 0.5888 - val_accuracy: 0.7509\n",
      "Epoch 138/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.6860 - accuracy: 0.7601 - val_loss: 0.5608 - val_accuracy: 0.7687\n",
      "Epoch 139/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.6063 - accuracy: 0.7713 - val_loss: 0.5608 - val_accuracy: 0.7713\n",
      "Epoch 140/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.5863 - accuracy: 0.7731 - val_loss: 0.5553 - val_accuracy: 0.7740\n",
      "Epoch 141/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.6056 - accuracy: 0.7719 - val_loss: 0.5704 - val_accuracy: 0.7662\n",
      "Epoch 142/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.8781 - accuracy: 0.7521 - val_loss: 0.6088 - val_accuracy: 0.7397\n",
      "Epoch 143/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.8252 - accuracy: 0.7468 - val_loss: 0.5929 - val_accuracy: 0.7371\n",
      "Epoch 144/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.7065 - accuracy: 0.7578 - val_loss: 0.5637 - val_accuracy: 0.7648\n",
      "Epoch 145/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.6674 - accuracy: 0.7651 - val_loss: 0.5705 - val_accuracy: 0.7623\n",
      "Epoch 146/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.6503 - accuracy: 0.7645 - val_loss: 0.5751 - val_accuracy: 0.7518\n",
      "Epoch 147/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.6620 - accuracy: 0.7637 - val_loss: 0.5635 - val_accuracy: 0.7661\n",
      "Epoch 148/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.5613 - accuracy: 0.7717 - val_loss: 0.5569 - val_accuracy: 0.7696\n",
      "Epoch 149/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.5276 - accuracy: 0.7758 - val_loss: 0.5517 - val_accuracy: 0.7753\n",
      "Epoch 150/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.5610 - accuracy: 0.7730 - val_loss: 0.5519 - val_accuracy: 0.7727\n",
      "Epoch 151/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.5242 - accuracy: 0.7729 - val_loss: 0.5557 - val_accuracy: 0.7705\n",
      "Epoch 152/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.5519 - accuracy: 0.7712 - val_loss: 0.5590 - val_accuracy: 0.7617\n",
      "Epoch 153/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7331 - accuracy: 0.7550 - val_loss: 0.6089 - val_accuracy: 0.7203\n",
      "Epoch 154/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.8192 - accuracy: 0.7413 - val_loss: 0.5954 - val_accuracy: 0.7536\n",
      "Epoch 155/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.7800 - accuracy: 0.7463 - val_loss: 0.5905 - val_accuracy: 0.7365\n",
      "Epoch 156/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.6376 - accuracy: 0.7546 - val_loss: 0.5655 - val_accuracy: 0.7649\n",
      "Epoch 157/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.5664 - accuracy: 0.7627 - val_loss: 0.5731 - val_accuracy: 0.7596\n",
      "Epoch 158/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.5815 - accuracy: 0.7595 - val_loss: 0.5953 - val_accuracy: 0.7528\n",
      "Epoch 159/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.5334 - accuracy: 0.7620 - val_loss: 0.5501 - val_accuracy: 0.7726\n",
      "Epoch 160/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.5515 - accuracy: 0.7634 - val_loss: 0.5491 - val_accuracy: 0.7634\n",
      "Epoch 161/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.4905 - accuracy: 0.7649 - val_loss: 0.5448 - val_accuracy: 0.7678\n",
      "Epoch 162/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.4823 - accuracy: 0.7655 - val_loss: 0.5690 - val_accuracy: 0.7446\n",
      "Epoch 163/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.5695 - accuracy: 0.7593 - val_loss: 0.5582 - val_accuracy: 0.7574\n",
      "Epoch 164/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.4918 - accuracy: 0.7654 - val_loss: 0.5552 - val_accuracy: 0.7550\n",
      "Epoch 165/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.4031 - accuracy: 0.7694 - val_loss: 0.5363 - val_accuracy: 0.7694\n",
      "Epoch 166/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.3707 - accuracy: 0.7736 - val_loss: 0.5343 - val_accuracy: 0.7762\n",
      "Epoch 167/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.3292 - accuracy: 0.7810 - val_loss: 0.5412 - val_accuracy: 0.7787\n",
      "Epoch 168/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.3483 - accuracy: 0.7851 - val_loss: 0.5394 - val_accuracy: 0.7752\n",
      "Epoch 169/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.5975 - accuracy: 0.7703 - val_loss: 0.5619 - val_accuracy: 0.7547\n",
      "Epoch 170/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.4507 - accuracy: 0.7781 - val_loss: 0.5333 - val_accuracy: 0.7904\n",
      "Epoch 171/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.3289 - accuracy: 0.7914 - val_loss: 0.5335 - val_accuracy: 0.7909\n",
      "Epoch 172/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.3725 - accuracy: 0.7938 - val_loss: 0.5367 - val_accuracy: 0.7820\n",
      "Epoch 173/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.3579 - accuracy: 0.7929 - val_loss: 0.5405 - val_accuracy: 0.7813\n",
      "Epoch 174/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.4019 - accuracy: 0.7896 - val_loss: 0.5293 - val_accuracy: 0.7917\n",
      "Epoch 175/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 5.3784 - accuracy: 0.7928 - val_loss: 0.5283 - val_accuracy: 0.7937\n",
      "Epoch 176/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.3291 - accuracy: 0.7949 - val_loss: 0.5175 - val_accuracy: 0.8013\n",
      "Epoch 177/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.2957 - accuracy: 0.7988 - val_loss: 0.5240 - val_accuracy: 0.7978\n",
      "Epoch 178/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.2467 - accuracy: 0.8010 - val_loss: 0.5279 - val_accuracy: 0.7983\n",
      "Epoch 179/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.3083 - accuracy: 0.7981 - val_loss: 0.5259 - val_accuracy: 0.7974\n",
      "Epoch 180/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.3958 - accuracy: 0.7894 - val_loss: 0.5246 - val_accuracy: 0.7967\n",
      "Epoch 181/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.2629 - accuracy: 0.7993 - val_loss: 0.5211 - val_accuracy: 0.8000\n",
      "Epoch 182/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.2409 - accuracy: 0.8039 - val_loss: 0.5205 - val_accuracy: 0.8013\n",
      "Epoch 183/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.2610 - accuracy: 0.8011 - val_loss: 0.5535 - val_accuracy: 0.7715\n",
      "Epoch 184/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.4157 - accuracy: 0.7875 - val_loss: 0.5296 - val_accuracy: 0.7867\n",
      "Epoch 185/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.2443 - accuracy: 0.7996 - val_loss: 0.5153 - val_accuracy: 0.8003\n",
      "Epoch 186/3000\n",
      "10/10 [==============================] - ETA: 0s - loss: 5.2198 - accuracy: 0.80 - 1s 76ms/step - loss: 5.2198 - accuracy: 0.8027 - val_loss: 0.5202 - val_accuracy: 0.7963\n",
      "Epoch 187/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.2198 - accuracy: 0.8030 - val_loss: 0.5154 - val_accuracy: 0.8027\n",
      "Epoch 188/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.2864 - accuracy: 0.7986 - val_loss: 0.5357 - val_accuracy: 0.7952\n",
      "Epoch 189/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.2843 - accuracy: 0.7983 - val_loss: 0.5440 - val_accuracy: 0.7878\n",
      "Epoch 190/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.2547 - accuracy: 0.7992 - val_loss: 0.5266 - val_accuracy: 0.7975\n",
      "Epoch 191/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.1808 - accuracy: 0.8042 - val_loss: 0.5138 - val_accuracy: 0.8049\n",
      "Epoch 192/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.2086 - accuracy: 0.8036 - val_loss: 0.5163 - val_accuracy: 0.8025\n",
      "Epoch 193/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1574 - accuracy: 0.8070 - val_loss: 0.5164 - val_accuracy: 0.7995\n",
      "Epoch 194/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.2167 - accuracy: 0.8024 - val_loss: 0.5260 - val_accuracy: 0.7878\n",
      "Epoch 195/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.3483 - accuracy: 0.7915 - val_loss: 0.5370 - val_accuracy: 0.7797\n",
      "Epoch 196/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.2230 - accuracy: 0.7978 - val_loss: 0.5143 - val_accuracy: 0.7987\n",
      "Epoch 197/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.2049 - accuracy: 0.8032 - val_loss: 0.5185 - val_accuracy: 0.7997\n",
      "Epoch 198/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.2225 - accuracy: 0.8019 - val_loss: 0.5158 - val_accuracy: 0.7969\n",
      "Epoch 199/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.1807 - accuracy: 0.8034 - val_loss: 0.5075 - val_accuracy: 0.8035\n",
      "Epoch 200/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.1480 - accuracy: 0.8057 - val_loss: 0.5179 - val_accuracy: 0.7949\n",
      "Epoch 201/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.2919 - accuracy: 0.7945 - val_loss: 0.5257 - val_accuracy: 0.7884\n",
      "Epoch 202/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.1820 - accuracy: 0.8010 - val_loss: 0.5044 - val_accuracy: 0.8062\n",
      "Epoch 203/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.1944 - accuracy: 0.8016 - val_loss: 0.5051 - val_accuracy: 0.8060\n",
      "Epoch 204/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.1758 - accuracy: 0.8032 - val_loss: 0.5061 - val_accuracy: 0.8039\n",
      "Epoch 205/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.1032 - accuracy: 0.8079 - val_loss: 0.4991 - val_accuracy: 0.8099\n",
      "Epoch 206/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.0897 - accuracy: 0.8102 - val_loss: 0.5096 - val_accuracy: 0.8022\n",
      "Epoch 207/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.1423 - accuracy: 0.8068 - val_loss: 0.5077 - val_accuracy: 0.8047\n",
      "Epoch 208/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1220 - accuracy: 0.8053 - val_loss: 0.5154 - val_accuracy: 0.8026\n",
      "Epoch 209/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.0931 - accuracy: 0.8087 - val_loss: 0.5178 - val_accuracy: 0.8007\n",
      "Epoch 210/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1225 - accuracy: 0.8056 - val_loss: 0.5204 - val_accuracy: 0.8010\n",
      "Epoch 211/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.1192 - accuracy: 0.8051 - val_loss: 0.5012 - val_accuracy: 0.8099\n",
      "Epoch 212/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1072 - accuracy: 0.8071 - val_loss: 0.5099 - val_accuracy: 0.8010\n",
      "Epoch 213/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.2198 - accuracy: 0.7987 - val_loss: 0.5169 - val_accuracy: 0.8014\n",
      "Epoch 214/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.1685 - accuracy: 0.8001 - val_loss: 0.5012 - val_accuracy: 0.8081\n",
      "Epoch 215/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.0810 - accuracy: 0.8094 - val_loss: 0.5022 - val_accuracy: 0.8078\n",
      "Epoch 216/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.0671 - accuracy: 0.8095 - val_loss: 0.4946 - val_accuracy: 0.8108\n",
      "Epoch 217/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.0795 - accuracy: 0.8094 - val_loss: 0.5146 - val_accuracy: 0.8048\n",
      "Epoch 218/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.2067 - accuracy: 0.8009 - val_loss: 0.5133 - val_accuracy: 0.8002\n",
      "Epoch 219/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.1864 - accuracy: 0.8010 - val_loss: 0.5175 - val_accuracy: 0.7995\n",
      "Epoch 220/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1187 - accuracy: 0.8031 - val_loss: 0.5072 - val_accuracy: 0.8082\n",
      "Epoch 221/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.0321 - accuracy: 0.8099 - val_loss: 0.4967 - val_accuracy: 0.8116\n",
      "Epoch 222/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.9945 - accuracy: 0.8104 - val_loss: 0.4867 - val_accuracy: 0.8182\n",
      "Epoch 223/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 4.9063 - accuracy: 0.8139 - val_loss: 0.4824 - val_accuracy: 0.8193\n",
      "Epoch 224/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.8872 - accuracy: 0.8141 - val_loss: 0.4941 - val_accuracy: 0.8170\n",
      "Epoch 225/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.9471 - accuracy: 0.8126 - val_loss: 0.6095 - val_accuracy: 0.7409\n",
      "Epoch 226/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 6.3277 - accuracy: 0.7311 - val_loss: 0.6883 - val_accuracy: 0.7394\n",
      "Epoch 227/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.1107 - accuracy: 0.7464 - val_loss: 0.6367 - val_accuracy: 0.7360\n",
      "Epoch 228/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.6890 - accuracy: 0.7614 - val_loss: 0.5935 - val_accuracy: 0.7563\n",
      "Epoch 229/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.3879 - accuracy: 0.7828 - val_loss: 0.5359 - val_accuracy: 0.7918\n",
      "Epoch 230/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.2442 - accuracy: 0.7953 - val_loss: 0.5231 - val_accuracy: 0.7974\n",
      "Epoch 231/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1664 - accuracy: 0.7996 - val_loss: 0.5173 - val_accuracy: 0.7986\n",
      "Epoch 232/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.1072 - accuracy: 0.8013 - val_loss: 0.5018 - val_accuracy: 0.8061\n",
      "Epoch 233/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.0574 - accuracy: 0.8064 - val_loss: 0.5082 - val_accuracy: 0.8010\n",
      "Epoch 234/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.0078 - accuracy: 0.8088 - val_loss: 0.5087 - val_accuracy: 0.8010\n",
      "Epoch 235/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.9808 - accuracy: 0.8105 - val_loss: 0.4895 - val_accuracy: 0.8107\n",
      "Epoch 236/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.9682 - accuracy: 0.8103 - val_loss: 0.4883 - val_accuracy: 0.8127\n",
      "Epoch 237/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.9499 - accuracy: 0.8103 - val_loss: 0.4764 - val_accuracy: 0.8171\n",
      "Epoch 238/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.9025 - accuracy: 0.8099 - val_loss: 0.4661 - val_accuracy: 0.8203\n",
      "Epoch 239/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.8403 - accuracy: 0.8140 - val_loss: 0.4848 - val_accuracy: 0.8134\n",
      "Epoch 240/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.7652 - accuracy: 0.8189 - val_loss: 0.4796 - val_accuracy: 0.8097\n",
      "Epoch 241/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.6763 - accuracy: 0.8211 - val_loss: 0.4681 - val_accuracy: 0.8183\n",
      "Epoch 242/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.5964 - accuracy: 0.8259 - val_loss: 0.4535 - val_accuracy: 0.8263\n",
      "Epoch 243/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.6206 - accuracy: 0.8209 - val_loss: 0.4510 - val_accuracy: 0.8296\n",
      "Epoch 244/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.1602 - accuracy: 0.7928 - val_loss: 0.5059 - val_accuracy: 0.7897\n",
      "Epoch 245/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.1934 - accuracy: 0.7916 - val_loss: 0.5657 - val_accuracy: 0.7616\n",
      "Epoch 246/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.8121 - accuracy: 0.8079 - val_loss: 0.4687 - val_accuracy: 0.8180\n",
      "Epoch 247/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.5722 - accuracy: 0.8191 - val_loss: 0.4319 - val_accuracy: 0.8331\n",
      "Epoch 248/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.4909 - accuracy: 0.8249 - val_loss: 0.4665 - val_accuracy: 0.8111\n",
      "Epoch 249/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.5332 - accuracy: 0.8230 - val_loss: 0.5234 - val_accuracy: 0.7902\n",
      "Epoch 250/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.8342 - accuracy: 0.8020 - val_loss: 0.5210 - val_accuracy: 0.7736\n",
      "Epoch 251/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.6469 - accuracy: 0.8146 - val_loss: 0.4537 - val_accuracy: 0.8204\n",
      "Epoch 252/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.4283 - accuracy: 0.8256 - val_loss: 0.4297 - val_accuracy: 0.8347\n",
      "Epoch 253/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3465 - accuracy: 0.8313 - val_loss: 0.4413 - val_accuracy: 0.8258\n",
      "Epoch 254/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.4039 - accuracy: 0.8261 - val_loss: 0.4148 - val_accuracy: 0.8416\n",
      "Epoch 255/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.4724 - accuracy: 0.8263 - val_loss: 0.5291 - val_accuracy: 0.7672\n",
      "Epoch 256/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.9006 - accuracy: 0.8005 - val_loss: 0.5128 - val_accuracy: 0.7782\n",
      "Epoch 257/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.5428 - accuracy: 0.8193 - val_loss: 0.4466 - val_accuracy: 0.8250\n",
      "Epoch 258/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.3484 - accuracy: 0.8298 - val_loss: 0.4223 - val_accuracy: 0.8365\n",
      "Epoch 259/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3193 - accuracy: 0.8305 - val_loss: 0.4335 - val_accuracy: 0.8297\n",
      "Epoch 260/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.3490 - accuracy: 0.8297 - val_loss: 0.5494 - val_accuracy: 0.7580\n",
      "Epoch 261/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.6368 - accuracy: 0.8108 - val_loss: 0.4232 - val_accuracy: 0.8360\n",
      "Epoch 262/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.4622 - accuracy: 0.8245 - val_loss: 0.4180 - val_accuracy: 0.8423\n",
      "Epoch 263/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 4.3260 - accuracy: 0.8307 - val_loss: 0.4219 - val_accuracy: 0.8381\n",
      "Epoch 264/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 4.3495 - accuracy: 0.8298 - val_loss: 0.4185 - val_accuracy: 0.8383\n",
      "Epoch 265/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.2255 - accuracy: 0.8359 - val_loss: 0.4210 - val_accuracy: 0.8347\n",
      "Epoch 266/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.5135 - accuracy: 0.8207 - val_loss: 0.5811 - val_accuracy: 0.7472\n",
      "Epoch 267/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.4351 - accuracy: 0.8210 - val_loss: 0.4250 - val_accuracy: 0.8350\n",
      "Epoch 268/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3238 - accuracy: 0.8299 - val_loss: 0.4092 - val_accuracy: 0.8435\n",
      "Epoch 269/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.2083 - accuracy: 0.8354 - val_loss: 0.4113 - val_accuracy: 0.8407\n",
      "Epoch 270/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1841 - accuracy: 0.8362 - val_loss: 0.4015 - val_accuracy: 0.8463\n",
      "Epoch 271/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1823 - accuracy: 0.8386 - val_loss: 0.4045 - val_accuracy: 0.8451\n",
      "Epoch 272/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3141 - accuracy: 0.8303 - val_loss: 0.4732 - val_accuracy: 0.8087\n",
      "Epoch 273/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.4470 - accuracy: 0.8200 - val_loss: 0.4198 - val_accuracy: 0.8402\n",
      "Epoch 274/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.2316 - accuracy: 0.8353 - val_loss: 0.4282 - val_accuracy: 0.8301\n",
      "Epoch 275/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1373 - accuracy: 0.8388 - val_loss: 0.4327 - val_accuracy: 0.8256\n",
      "Epoch 276/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1741 - accuracy: 0.8363 - val_loss: 0.4085 - val_accuracy: 0.8414\n",
      "Epoch 277/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.1626 - accuracy: 0.8394 - val_loss: 0.5264 - val_accuracy: 0.7825\n",
      "Epoch 278/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.5442 - accuracy: 0.8142 - val_loss: 0.4087 - val_accuracy: 0.8434\n",
      "Epoch 279/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3923 - accuracy: 0.8258 - val_loss: 0.4129 - val_accuracy: 0.8432\n",
      "Epoch 280/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.2037 - accuracy: 0.8357 - val_loss: 0.4151 - val_accuracy: 0.8391\n",
      "Epoch 281/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1404 - accuracy: 0.8397 - val_loss: 0.4090 - val_accuracy: 0.8411\n",
      "Epoch 282/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.2027 - accuracy: 0.8343 - val_loss: 0.4140 - val_accuracy: 0.8414\n",
      "Epoch 283/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.2438 - accuracy: 0.8318 - val_loss: 0.4057 - val_accuracy: 0.8446\n",
      "Epoch 284/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.2090 - accuracy: 0.8381 - val_loss: 0.4587 - val_accuracy: 0.8088\n",
      "Epoch 285/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.1016 - accuracy: 0.8399 - val_loss: 0.4110 - val_accuracy: 0.8392\n",
      "Epoch 286/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1206 - accuracy: 0.8396 - val_loss: 0.4006 - val_accuracy: 0.8452\n",
      "Epoch 287/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.2276 - accuracy: 0.8314 - val_loss: 0.4127 - val_accuracy: 0.8432\n",
      "Epoch 288/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.2184 - accuracy: 0.8364 - val_loss: 0.4558 - val_accuracy: 0.8115\n",
      "Epoch 289/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.1190 - accuracy: 0.8393 - val_loss: 0.4236 - val_accuracy: 0.8311\n",
      "Epoch 290/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1184 - accuracy: 0.8379 - val_loss: 0.4014 - val_accuracy: 0.8451\n",
      "Epoch 291/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0644 - accuracy: 0.8413 - val_loss: 0.4063 - val_accuracy: 0.8414\n",
      "Epoch 292/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0505 - accuracy: 0.8435 - val_loss: 0.4038 - val_accuracy: 0.8434\n",
      "Epoch 293/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1616 - accuracy: 0.8360 - val_loss: 0.4049 - val_accuracy: 0.8428\n",
      "Epoch 294/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0893 - accuracy: 0.8398 - val_loss: 0.4019 - val_accuracy: 0.8454\n",
      "Epoch 295/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1566 - accuracy: 0.8354 - val_loss: 0.4012 - val_accuracy: 0.8456\n",
      "Epoch 296/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1435 - accuracy: 0.8406 - val_loss: 0.4474 - val_accuracy: 0.8163\n",
      "Epoch 297/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0997 - accuracy: 0.8401 - val_loss: 0.4405 - val_accuracy: 0.8221\n",
      "Epoch 298/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0666 - accuracy: 0.8413 - val_loss: 0.4073 - val_accuracy: 0.8406\n",
      "Epoch 299/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0824 - accuracy: 0.8412 - val_loss: 0.4221 - val_accuracy: 0.8307\n",
      "Epoch 300/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1717 - accuracy: 0.8358 - val_loss: 0.4004 - val_accuracy: 0.8479\n",
      "Epoch 301/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.3280 - accuracy: 0.8288 - val_loss: 0.4969 - val_accuracy: 0.7974\n",
      "Epoch 302/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 4.2010 - accuracy: 0.8344 - val_loss: 0.4387 - val_accuracy: 0.8239\n",
      "Epoch 303/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.0676 - accuracy: 0.8421 - val_loss: 0.3997 - val_accuracy: 0.8452\n",
      "Epoch 304/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.0032 - accuracy: 0.8468 - val_loss: 0.3927 - val_accuracy: 0.8490\n",
      "Epoch 305/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0002 - accuracy: 0.8465 - val_loss: 0.4444 - val_accuracy: 0.8146\n",
      "Epoch 306/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0394 - accuracy: 0.8426 - val_loss: 0.4316 - val_accuracy: 0.8245\n",
      "Epoch 307/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1763 - accuracy: 0.8366 - val_loss: 0.4850 - val_accuracy: 0.7949\n",
      "Epoch 308/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.3345 - accuracy: 0.8263 - val_loss: 0.4002 - val_accuracy: 0.8457\n",
      "Epoch 309/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1410 - accuracy: 0.8392 - val_loss: 0.4038 - val_accuracy: 0.8460\n",
      "Epoch 310/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1225 - accuracy: 0.8419 - val_loss: 0.4547 - val_accuracy: 0.8139\n",
      "Epoch 311/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0604 - accuracy: 0.8412 - val_loss: 0.3916 - val_accuracy: 0.8500\n",
      "Epoch 312/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1062 - accuracy: 0.8428 - val_loss: 0.5317 - val_accuracy: 0.7696\n",
      "Epoch 313/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.2429 - accuracy: 0.8294 - val_loss: 0.3947 - val_accuracy: 0.8479\n",
      "Epoch 314/3000\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 4.0886 - accuracy: 0.8430 - val_loss: 0.4014 - val_accuracy: 0.8453\n",
      "Epoch 315/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.1020 - accuracy: 0.8388 - val_loss: 0.3949 - val_accuracy: 0.8475\n",
      "Epoch 316/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0533 - accuracy: 0.8448 - val_loss: 0.4361 - val_accuracy: 0.8242\n",
      "Epoch 317/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.0164 - accuracy: 0.8445 - val_loss: 0.4089 - val_accuracy: 0.8392\n",
      "Epoch 318/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9912 - accuracy: 0.8468 - val_loss: 0.3975 - val_accuracy: 0.8465\n",
      "Epoch 319/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0429 - accuracy: 0.8426 - val_loss: 0.3881 - val_accuracy: 0.8521\n",
      "Epoch 320/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0099 - accuracy: 0.8466 - val_loss: 0.3930 - val_accuracy: 0.8482\n",
      "Epoch 321/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9320 - accuracy: 0.8503 - val_loss: 0.3988 - val_accuracy: 0.8429\n",
      "Epoch 322/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9340 - accuracy: 0.8482 - val_loss: 0.3894 - val_accuracy: 0.8504\n",
      "Epoch 323/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.0528 - accuracy: 0.8435 - val_loss: 0.3851 - val_accuracy: 0.8516\n",
      "Epoch 324/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0021 - accuracy: 0.8457 - val_loss: 0.3813 - val_accuracy: 0.8551\n",
      "Epoch 325/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9607 - accuracy: 0.8492 - val_loss: 0.3905 - val_accuracy: 0.8490\n",
      "Epoch 326/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1178 - accuracy: 0.8393 - val_loss: 0.4078 - val_accuracy: 0.8403\n",
      "Epoch 327/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.0284 - accuracy: 0.8450 - val_loss: 0.4160 - val_accuracy: 0.8356\n",
      "Epoch 328/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9280 - accuracy: 0.8494 - val_loss: 0.3834 - val_accuracy: 0.8547\n",
      "Epoch 329/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1411 - accuracy: 0.8389 - val_loss: 0.3972 - val_accuracy: 0.8457\n",
      "Epoch 330/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0098 - accuracy: 0.8466 - val_loss: 0.4375 - val_accuracy: 0.8227\n",
      "Epoch 331/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9748 - accuracy: 0.8465 - val_loss: 0.4066 - val_accuracy: 0.8406\n",
      "Epoch 332/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0459 - accuracy: 0.8418 - val_loss: 0.3968 - val_accuracy: 0.8482\n",
      "Epoch 333/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.9331 - accuracy: 0.8495 - val_loss: 0.3880 - val_accuracy: 0.8495\n",
      "Epoch 334/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9278 - accuracy: 0.8501 - val_loss: 0.4032 - val_accuracy: 0.8413\n",
      "Epoch 335/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9912 - accuracy: 0.8456 - val_loss: 0.3984 - val_accuracy: 0.8442\n",
      "Epoch 336/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1588 - accuracy: 0.8345 - val_loss: 0.3945 - val_accuracy: 0.8500\n",
      "Epoch 337/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0429 - accuracy: 0.8453 - val_loss: 0.4250 - val_accuracy: 0.8333\n",
      "Epoch 338/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9657 - accuracy: 0.8471 - val_loss: 0.3879 - val_accuracy: 0.8509\n",
      "Epoch 339/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.9694 - accuracy: 0.8480 - val_loss: 0.3913 - val_accuracy: 0.8492\n",
      "Epoch 340/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1095 - accuracy: 0.8400 - val_loss: 0.4169 - val_accuracy: 0.8354\n",
      "Epoch 341/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.0284 - accuracy: 0.8431 - val_loss: 0.3862 - val_accuracy: 0.8543\n",
      "Epoch 342/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9507 - accuracy: 0.8497 - val_loss: 0.4265 - val_accuracy: 0.8299\n",
      "Epoch 343/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9038 - accuracy: 0.8510 - val_loss: 0.3898 - val_accuracy: 0.8490\n",
      "Epoch 344/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9252 - accuracy: 0.8493 - val_loss: 0.3823 - val_accuracy: 0.8523\n",
      "Epoch 345/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1423 - accuracy: 0.8402 - val_loss: 0.4403 - val_accuracy: 0.8249\n",
      "Epoch 346/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9997 - accuracy: 0.8441 - val_loss: 0.3778 - val_accuracy: 0.8562\n",
      "Epoch 347/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0454 - accuracy: 0.8447 - val_loss: 0.4205 - val_accuracy: 0.8319\n",
      "Epoch 348/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0326 - accuracy: 0.8447 - val_loss: 0.4099 - val_accuracy: 0.8379\n",
      "Epoch 349/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9058 - accuracy: 0.8501 - val_loss: 0.3838 - val_accuracy: 0.8533\n",
      "Epoch 350/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9639 - accuracy: 0.8473 - val_loss: 0.3757 - val_accuracy: 0.8570\n",
      "Epoch 351/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9463 - accuracy: 0.8490 - val_loss: 0.3867 - val_accuracy: 0.8500\n",
      "Epoch 352/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9256 - accuracy: 0.8508 - val_loss: 0.4498 - val_accuracy: 0.8214\n",
      "Epoch 353/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0167 - accuracy: 0.8441 - val_loss: 0.3862 - val_accuracy: 0.8534\n",
      "Epoch 354/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9415 - accuracy: 0.8493 - val_loss: 0.3938 - val_accuracy: 0.8466\n",
      "Epoch 355/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9119 - accuracy: 0.8515 - val_loss: 0.4396 - val_accuracy: 0.8252\n",
      "Epoch 356/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9739 - accuracy: 0.8464 - val_loss: 0.3889 - val_accuracy: 0.8494\n",
      "Epoch 357/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9423 - accuracy: 0.8472 - val_loss: 0.3906 - val_accuracy: 0.8488\n",
      "Epoch 358/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0883 - accuracy: 0.8440 - val_loss: 0.4565 - val_accuracy: 0.8148\n",
      "Epoch 359/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9252 - accuracy: 0.8487 - val_loss: 0.3888 - val_accuracy: 0.8503\n",
      "Epoch 360/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8572 - accuracy: 0.8541 - val_loss: 0.3826 - val_accuracy: 0.8517\n",
      "Epoch 361/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.8643 - accuracy: 0.8534 - val_loss: 0.4091 - val_accuracy: 0.8354\n",
      "Epoch 362/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8546 - accuracy: 0.8529 - val_loss: 0.3794 - val_accuracy: 0.8540\n",
      "Epoch 363/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.8820 - accuracy: 0.8524 - val_loss: 0.3812 - val_accuracy: 0.8527\n",
      "Epoch 364/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8909 - accuracy: 0.8507 - val_loss: 0.3814 - val_accuracy: 0.8522\n",
      "Epoch 365/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.8478 - accuracy: 0.8545 - val_loss: 0.3876 - val_accuracy: 0.8495\n",
      "Epoch 366/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9113 - accuracy: 0.8508 - val_loss: 0.3891 - val_accuracy: 0.8484\n",
      "Epoch 367/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0631 - accuracy: 0.8400 - val_loss: 0.3845 - val_accuracy: 0.8524\n",
      "Epoch 368/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9129 - accuracy: 0.8517 - val_loss: 0.4211 - val_accuracy: 0.8321\n",
      "Epoch 369/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8716 - accuracy: 0.8529 - val_loss: 0.3904 - val_accuracy: 0.8482\n",
      "Epoch 370/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8722 - accuracy: 0.8521 - val_loss: 0.3947 - val_accuracy: 0.8456\n",
      "Epoch 371/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8659 - accuracy: 0.8529 - val_loss: 0.4269 - val_accuracy: 0.8298\n",
      "Epoch 372/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8986 - accuracy: 0.8508 - val_loss: 0.4341 - val_accuracy: 0.8234\n",
      "Epoch 373/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9158 - accuracy: 0.8500 - val_loss: 0.4165 - val_accuracy: 0.8339\n",
      "Epoch 374/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8735 - accuracy: 0.8522 - val_loss: 0.3804 - val_accuracy: 0.8541\n",
      "Epoch 375/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8388 - accuracy: 0.8536 - val_loss: 0.3722 - val_accuracy: 0.8578\n",
      "Epoch 376/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8970 - accuracy: 0.8515 - val_loss: 0.3733 - val_accuracy: 0.8581\n",
      "Epoch 377/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9507 - accuracy: 0.8490 - val_loss: 0.3702 - val_accuracy: 0.8585\n",
      "Epoch 378/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9482 - accuracy: 0.8507 - val_loss: 0.4139 - val_accuracy: 0.8363\n",
      "Epoch 379/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9211 - accuracy: 0.8504 - val_loss: 0.3905 - val_accuracy: 0.8497\n",
      "Epoch 380/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1896 - accuracy: 0.8365 - val_loss: 0.5107 - val_accuracy: 0.7852\n",
      "Epoch 381/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.1320 - accuracy: 0.8371 - val_loss: 0.4067 - val_accuracy: 0.8447\n",
      "Epoch 382/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9440 - accuracy: 0.8494 - val_loss: 0.3849 - val_accuracy: 0.8537\n",
      "Epoch 383/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.8819 - accuracy: 0.8519 - val_loss: 0.3685 - val_accuracy: 0.8594\n",
      "Epoch 384/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8257 - accuracy: 0.8560 - val_loss: 0.3797 - val_accuracy: 0.8534\n",
      "Epoch 385/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8281 - accuracy: 0.8550 - val_loss: 0.3809 - val_accuracy: 0.8537\n",
      "Epoch 386/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9237 - accuracy: 0.8482 - val_loss: 0.3783 - val_accuracy: 0.8564\n",
      "Epoch 387/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8973 - accuracy: 0.8529 - val_loss: 0.4363 - val_accuracy: 0.8238\n",
      "Epoch 388/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9321 - accuracy: 0.8488 - val_loss: 0.3955 - val_accuracy: 0.8451\n",
      "Epoch 389/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8142 - accuracy: 0.8547 - val_loss: 0.3907 - val_accuracy: 0.8480\n",
      "Epoch 390/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8047 - accuracy: 0.8568 - val_loss: 0.4381 - val_accuracy: 0.8255\n",
      "Epoch 391/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8370 - accuracy: 0.8537 - val_loss: 0.3774 - val_accuracy: 0.8553\n",
      "Epoch 392/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8808 - accuracy: 0.8512 - val_loss: 0.3657 - val_accuracy: 0.8609\n",
      "Epoch 393/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9603 - accuracy: 0.8494 - val_loss: 0.4454 - val_accuracy: 0.8225\n",
      "Epoch 394/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.2125 - accuracy: 0.8328 - val_loss: 0.3765 - val_accuracy: 0.8566\n",
      "Epoch 395/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0580 - accuracy: 0.8459 - val_loss: 0.3793 - val_accuracy: 0.8554\n",
      "Epoch 396/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8997 - accuracy: 0.8512 - val_loss: 0.3733 - val_accuracy: 0.8584\n",
      "Epoch 397/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8457 - accuracy: 0.8539 - val_loss: 0.3723 - val_accuracy: 0.8573\n",
      "Epoch 398/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8281 - accuracy: 0.8561 - val_loss: 0.3899 - val_accuracy: 0.8475\n",
      "Epoch 399/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8526 - accuracy: 0.8535 - val_loss: 0.4103 - val_accuracy: 0.8349\n",
      "Epoch 400/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8144 - accuracy: 0.8549 - val_loss: 0.3807 - val_accuracy: 0.8529\n",
      "Epoch 401/3000\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.8452 - accuracy: 0.85 - 1s 75ms/step - loss: 3.8452 - accuracy: 0.8542 - val_loss: 0.3793 - val_accuracy: 0.8538\n",
      "Epoch 402/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.8327 - accuracy: 0.8535 - val_loss: 0.3696 - val_accuracy: 0.8596\n",
      "Epoch 403/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 3.7747 - accuracy: 0.8585 - val_loss: 0.4166 - val_accuracy: 0.8325\n",
      "Epoch 404/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8502 - accuracy: 0.8535 - val_loss: 0.4216 - val_accuracy: 0.8313\n",
      "Epoch 405/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8703 - accuracy: 0.8518 - val_loss: 0.3840 - val_accuracy: 0.8509\n",
      "Epoch 406/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7981 - accuracy: 0.8560 - val_loss: 0.3655 - val_accuracy: 0.8612\n",
      "Epoch 407/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7688 - accuracy: 0.8588 - val_loss: 0.3746 - val_accuracy: 0.8565\n",
      "Epoch 408/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7752 - accuracy: 0.8576 - val_loss: 0.3760 - val_accuracy: 0.8554\n",
      "Epoch 409/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8125 - accuracy: 0.8560 - val_loss: 0.3881 - val_accuracy: 0.8491\n",
      "Epoch 410/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8056 - accuracy: 0.8548 - val_loss: 0.3625 - val_accuracy: 0.8622\n",
      "Epoch 411/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8408 - accuracy: 0.8535 - val_loss: 0.3637 - val_accuracy: 0.8619\n",
      "Epoch 412/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8958 - accuracy: 0.8527 - val_loss: 0.4497 - val_accuracy: 0.8180\n",
      "Epoch 413/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9720 - accuracy: 0.8451 - val_loss: 0.3695 - val_accuracy: 0.8594\n",
      "Epoch 414/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7811 - accuracy: 0.8580 - val_loss: 0.3828 - val_accuracy: 0.8520\n",
      "Epoch 415/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7568 - accuracy: 0.8576 - val_loss: 0.3677 - val_accuracy: 0.8594\n",
      "Epoch 416/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8569 - accuracy: 0.8516 - val_loss: 0.3743 - val_accuracy: 0.8557\n",
      "Epoch 417/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.2139 - accuracy: 0.8375 - val_loss: 0.3916 - val_accuracy: 0.8498\n",
      "Epoch 418/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0526 - accuracy: 0.8429 - val_loss: 0.3704 - val_accuracy: 0.8595\n",
      "Epoch 419/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9075 - accuracy: 0.8520 - val_loss: 0.4062 - val_accuracy: 0.8410\n",
      "Epoch 420/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8459 - accuracy: 0.8530 - val_loss: 0.3667 - val_accuracy: 0.8605\n",
      "Epoch 421/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.8000 - accuracy: 0.8575 - val_loss: 0.3965 - val_accuracy: 0.8455\n",
      "Epoch 422/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7766 - accuracy: 0.8577 - val_loss: 0.3768 - val_accuracy: 0.8541\n",
      "Epoch 423/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7553 - accuracy: 0.8580 - val_loss: 0.3638 - val_accuracy: 0.8617\n",
      "Epoch 424/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7555 - accuracy: 0.8586 - val_loss: 0.3665 - val_accuracy: 0.8603\n",
      "Epoch 425/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7591 - accuracy: 0.8585 - val_loss: 0.3626 - val_accuracy: 0.8618\n",
      "Epoch 426/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7492 - accuracy: 0.8591 - val_loss: 0.3690 - val_accuracy: 0.8590\n",
      "Epoch 427/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7660 - accuracy: 0.8577 - val_loss: 0.3646 - val_accuracy: 0.8610\n",
      "Epoch 428/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8379 - accuracy: 0.8554 - val_loss: 0.4465 - val_accuracy: 0.8178\n",
      "Epoch 429/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9484 - accuracy: 0.8467 - val_loss: 0.3724 - val_accuracy: 0.8577\n",
      "Epoch 430/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7604 - accuracy: 0.8593 - val_loss: 0.3796 - val_accuracy: 0.8537\n",
      "Epoch 431/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7931 - accuracy: 0.8561 - val_loss: 0.3819 - val_accuracy: 0.8526\n",
      "Epoch 432/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7886 - accuracy: 0.8564 - val_loss: 0.3900 - val_accuracy: 0.8478\n",
      "Epoch 433/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8611 - accuracy: 0.8521 - val_loss: 0.4003 - val_accuracy: 0.8445\n",
      "Epoch 434/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8949 - accuracy: 0.8524 - val_loss: 0.4313 - val_accuracy: 0.8273\n",
      "Epoch 435/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7851 - accuracy: 0.8562 - val_loss: 0.3949 - val_accuracy: 0.8451\n",
      "Epoch 436/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7733 - accuracy: 0.8577 - val_loss: 0.4251 - val_accuracy: 0.8309\n",
      "Epoch 437/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8723 - accuracy: 0.8510 - val_loss: 0.3688 - val_accuracy: 0.8594\n",
      "Epoch 438/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8570 - accuracy: 0.8520 - val_loss: 0.3650 - val_accuracy: 0.8609\n",
      "Epoch 439/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8739 - accuracy: 0.8535 - val_loss: 0.4018 - val_accuracy: 0.8416\n",
      "Epoch 440/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7910 - accuracy: 0.8555 - val_loss: 0.3790 - val_accuracy: 0.8543\n",
      "Epoch 441/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8449 - accuracy: 0.8546 - val_loss: 0.4163 - val_accuracy: 0.8355\n",
      "Epoch 442/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7477 - accuracy: 0.8587 - val_loss: 0.3810 - val_accuracy: 0.8523\n",
      "Epoch 443/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7073 - accuracy: 0.8596 - val_loss: 0.3593 - val_accuracy: 0.8638\n",
      "Epoch 444/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7420 - accuracy: 0.8595 - val_loss: 0.3909 - val_accuracy: 0.8460\n",
      "Epoch 445/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7203 - accuracy: 0.8599 - val_loss: 0.4033 - val_accuracy: 0.8391\n",
      "Epoch 446/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7425 - accuracy: 0.8589 - val_loss: 0.4196 - val_accuracy: 0.8312\n",
      "Epoch 447/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9180 - accuracy: 0.8479 - val_loss: 0.3741 - val_accuracy: 0.8561\n",
      "Epoch 448/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1742 - accuracy: 0.8376 - val_loss: 0.4161 - val_accuracy: 0.8372\n",
      "Epoch 449/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8616 - accuracy: 0.8530 - val_loss: 0.4282 - val_accuracy: 0.8312\n",
      "Epoch 450/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7963 - accuracy: 0.8567 - val_loss: 0.3674 - val_accuracy: 0.8606\n",
      "Epoch 451/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7434 - accuracy: 0.8589 - val_loss: 0.3675 - val_accuracy: 0.8593\n",
      "Epoch 452/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7085 - accuracy: 0.8612 - val_loss: 0.3774 - val_accuracy: 0.8534\n",
      "Epoch 453/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7465 - accuracy: 0.8581 - val_loss: 0.3595 - val_accuracy: 0.8636\n",
      "Epoch 454/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7245 - accuracy: 0.8606 - val_loss: 0.3669 - val_accuracy: 0.8599\n",
      "Epoch 455/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7052 - accuracy: 0.8615 - val_loss: 0.3848 - val_accuracy: 0.8494\n",
      "Epoch 456/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6854 - accuracy: 0.8611 - val_loss: 0.3658 - val_accuracy: 0.8601\n",
      "Epoch 457/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7690 - accuracy: 0.8568 - val_loss: 0.3615 - val_accuracy: 0.8619\n",
      "Epoch 458/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7173 - accuracy: 0.8610 - val_loss: 0.3965 - val_accuracy: 0.8426\n",
      "Epoch 459/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7295 - accuracy: 0.8589 - val_loss: 0.3591 - val_accuracy: 0.8634\n",
      "Epoch 460/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7246 - accuracy: 0.8596 - val_loss: 0.3597 - val_accuracy: 0.8634\n",
      "Epoch 461/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8295 - accuracy: 0.8550 - val_loss: 0.3890 - val_accuracy: 0.8485\n",
      "Epoch 462/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7865 - accuracy: 0.8559 - val_loss: 0.3653 - val_accuracy: 0.8606\n",
      "Epoch 463/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7922 - accuracy: 0.8564 - val_loss: 0.3664 - val_accuracy: 0.8605\n",
      "Epoch 464/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7176 - accuracy: 0.8614 - val_loss: 0.3674 - val_accuracy: 0.8597\n",
      "Epoch 465/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7027 - accuracy: 0.8611 - val_loss: 0.3768 - val_accuracy: 0.8537\n",
      "Epoch 466/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6805 - accuracy: 0.8620 - val_loss: 0.3652 - val_accuracy: 0.8609\n",
      "Epoch 467/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6877 - accuracy: 0.8623 - val_loss: 0.3924 - val_accuracy: 0.8451\n",
      "Epoch 468/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7950 - accuracy: 0.8563 - val_loss: 0.3972 - val_accuracy: 0.8430\n",
      "Epoch 469/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6839 - accuracy: 0.8621 - val_loss: 0.3715 - val_accuracy: 0.8566\n",
      "Epoch 470/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7887 - accuracy: 0.8569 - val_loss: 0.4234 - val_accuracy: 0.8313\n",
      "Epoch 471/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8758 - accuracy: 0.8511 - val_loss: 0.3670 - val_accuracy: 0.8612\n",
      "Epoch 472/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1625 - accuracy: 0.8385 - val_loss: 0.5244 - val_accuracy: 0.7877\n",
      "Epoch 473/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0464 - accuracy: 0.8423 - val_loss: 0.4213 - val_accuracy: 0.8357\n",
      "Epoch 474/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8903 - accuracy: 0.8508 - val_loss: 0.3963 - val_accuracy: 0.8451\n",
      "Epoch 475/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7960 - accuracy: 0.8566 - val_loss: 0.3905 - val_accuracy: 0.8468\n",
      "Epoch 476/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6936 - accuracy: 0.8612 - val_loss: 0.3671 - val_accuracy: 0.8583\n",
      "Epoch 477/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7002 - accuracy: 0.8607 - val_loss: 0.3599 - val_accuracy: 0.8627\n",
      "Epoch 478/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6703 - accuracy: 0.8631 - val_loss: 0.3810 - val_accuracy: 0.8509\n",
      "Epoch 479/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6579 - accuracy: 0.8634 - val_loss: 0.3954 - val_accuracy: 0.8427\n",
      "Epoch 480/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7504 - accuracy: 0.8575 - val_loss: 0.3721 - val_accuracy: 0.8561\n",
      "Epoch 481/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7211 - accuracy: 0.8607 - val_loss: 0.4352 - val_accuracy: 0.8280\n",
      "Epoch 482/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9404 - accuracy: 0.8457 - val_loss: 0.3733 - val_accuracy: 0.8570\n",
      "Epoch 483/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.9930 - accuracy: 0.8475 - val_loss: 0.3722 - val_accuracy: 0.8595\n",
      "Epoch 484/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7921 - accuracy: 0.8579 - val_loss: 0.3795 - val_accuracy: 0.8534\n",
      "Epoch 485/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7400 - accuracy: 0.8584 - val_loss: 0.3615 - val_accuracy: 0.8625\n",
      "Epoch 486/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6851 - accuracy: 0.8629 - val_loss: 0.3931 - val_accuracy: 0.8454\n",
      "Epoch 487/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7261 - accuracy: 0.8594 - val_loss: 0.3989 - val_accuracy: 0.8439\n",
      "Epoch 488/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7960 - accuracy: 0.8549 - val_loss: 0.3624 - val_accuracy: 0.8620\n",
      "Epoch 489/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7797 - accuracy: 0.8560 - val_loss: 0.3619 - val_accuracy: 0.8613\n",
      "Epoch 490/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6649 - accuracy: 0.8640 - val_loss: 0.4029 - val_accuracy: 0.8410\n",
      "Epoch 491/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7255 - accuracy: 0.8593 - val_loss: 0.3754 - val_accuracy: 0.8542\n",
      "Epoch 492/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6569 - accuracy: 0.8632 - val_loss: 0.3729 - val_accuracy: 0.8558\n",
      "Epoch 493/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6658 - accuracy: 0.8627 - val_loss: 0.3764 - val_accuracy: 0.8526\n",
      "Epoch 494/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6590 - accuracy: 0.8626 - val_loss: 0.3610 - val_accuracy: 0.8611\n",
      "Epoch 495/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8796 - accuracy: 0.8497 - val_loss: 0.4000 - val_accuracy: 0.8426\n",
      "Epoch 496/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 4.0546 - accuracy: 0.8425 - val_loss: 0.3744 - val_accuracy: 0.8584\n",
      "Epoch 497/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8117 - accuracy: 0.8573 - val_loss: 0.3774 - val_accuracy: 0.8549\n",
      "Epoch 498/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6686 - accuracy: 0.8629 - val_loss: 0.3541 - val_accuracy: 0.8655\n",
      "Epoch 499/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6541 - accuracy: 0.8644 - val_loss: 0.3734 - val_accuracy: 0.8550\n",
      "Epoch 500/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6710 - accuracy: 0.8618 - val_loss: 0.3923 - val_accuracy: 0.8451\n",
      "Epoch 501/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7499 - accuracy: 0.8585 - val_loss: 0.4320 - val_accuracy: 0.8232\n",
      "Epoch 502/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7107 - accuracy: 0.8583 - val_loss: 0.3622 - val_accuracy: 0.8620\n",
      "Epoch 503/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6626 - accuracy: 0.8637 - val_loss: 0.3562 - val_accuracy: 0.8644\n",
      "Epoch 504/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6629 - accuracy: 0.8631 - val_loss: 0.3619 - val_accuracy: 0.8609\n",
      "Epoch 505/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6856 - accuracy: 0.8627 - val_loss: 0.4025 - val_accuracy: 0.8392\n",
      "Epoch 506/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8756 - accuracy: 0.8510 - val_loss: 0.3696 - val_accuracy: 0.8576\n",
      "Epoch 507/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0964 - accuracy: 0.8407 - val_loss: 0.3728 - val_accuracy: 0.8586\n",
      "Epoch 508/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8295 - accuracy: 0.8551 - val_loss: 0.3996 - val_accuracy: 0.8424\n",
      "Epoch 509/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6907 - accuracy: 0.8614 - val_loss: 0.3636 - val_accuracy: 0.8611\n",
      "Epoch 510/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6278 - accuracy: 0.8646 - val_loss: 0.3557 - val_accuracy: 0.8648\n",
      "Epoch 511/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6369 - accuracy: 0.8641 - val_loss: 0.3616 - val_accuracy: 0.8612\n",
      "Epoch 512/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6264 - accuracy: 0.8650 - val_loss: 0.3734 - val_accuracy: 0.8542\n",
      "Epoch 513/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7079 - accuracy: 0.8602 - val_loss: 0.3676 - val_accuracy: 0.8580\n",
      "Epoch 514/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7947 - accuracy: 0.8534 - val_loss: 0.3741 - val_accuracy: 0.8557\n",
      "Epoch 515/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8695 - accuracy: 0.8534 - val_loss: 0.3791 - val_accuracy: 0.8552\n",
      "Epoch 516/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8524 - accuracy: 0.8531 - val_loss: 0.4639 - val_accuracy: 0.8115\n",
      "Epoch 517/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9134 - accuracy: 0.8489 - val_loss: 0.3584 - val_accuracy: 0.8641\n",
      "Epoch 518/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7713 - accuracy: 0.8592 - val_loss: 0.3640 - val_accuracy: 0.8620\n",
      "Epoch 519/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7519 - accuracy: 0.8584 - val_loss: 0.4342 - val_accuracy: 0.8241\n",
      "Epoch 520/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9281 - accuracy: 0.8472 - val_loss: 0.3604 - val_accuracy: 0.8627\n",
      "Epoch 521/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 3.7967 - accuracy: 0.8576 - val_loss: 0.3645 - val_accuracy: 0.8617\n",
      "Epoch 522/3000\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 3.7309 - accuracy: 0.8597 - val_loss: 0.3644 - val_accuracy: 0.8597\n",
      "Epoch 523/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 3.7685 - accuracy: 0.8576 - val_loss: 0.4405 - val_accuracy: 0.8240\n",
      "Epoch 524/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 3.7657 - accuracy: 0.8572 - val_loss: 0.3714 - val_accuracy: 0.8573\n",
      "Epoch 525/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.6249 - accuracy: 0.8651 - val_loss: 0.3672 - val_accuracy: 0.8585\n",
      "Epoch 526/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.6468 - accuracy: 0.8633 - val_loss: 0.3592 - val_accuracy: 0.8620\n",
      "Epoch 527/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6558 - accuracy: 0.8621 - val_loss: 0.3619 - val_accuracy: 0.8609\n",
      "Epoch 528/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6136 - accuracy: 0.8651 - val_loss: 0.3529 - val_accuracy: 0.8653\n",
      "Epoch 529/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6050 - accuracy: 0.8656 - val_loss: 0.3923 - val_accuracy: 0.8450\n",
      "Epoch 530/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7063 - accuracy: 0.8600 - val_loss: 0.3809 - val_accuracy: 0.8518\n",
      "Epoch 531/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6567 - accuracy: 0.8613 - val_loss: 0.3497 - val_accuracy: 0.8678\n",
      "Epoch 532/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6186 - accuracy: 0.8650 - val_loss: 0.3619 - val_accuracy: 0.8597\n",
      "Epoch 533/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5951 - accuracy: 0.8659 - val_loss: 0.3495 - val_accuracy: 0.8669\n",
      "Epoch 534/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6261 - accuracy: 0.8641 - val_loss: 0.3503 - val_accuracy: 0.8677\n",
      "Epoch 535/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6068 - accuracy: 0.8655 - val_loss: 0.3556 - val_accuracy: 0.8632\n",
      "Epoch 536/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5919 - accuracy: 0.8666 - val_loss: 0.3795 - val_accuracy: 0.8509\n",
      "Epoch 537/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6201 - accuracy: 0.8643 - val_loss: 0.3669 - val_accuracy: 0.8580\n",
      "Epoch 538/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5900 - accuracy: 0.8661 - val_loss: 0.3738 - val_accuracy: 0.8542\n",
      "Epoch 539/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5993 - accuracy: 0.8655 - val_loss: 0.3566 - val_accuracy: 0.8632\n",
      "Epoch 540/3000\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 3.6220 - accuracy: 0.8641 - val_loss: 0.3608 - val_accuracy: 0.8612\n",
      "Epoch 541/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9993 - accuracy: 0.8438 - val_loss: 0.3861 - val_accuracy: 0.8523\n",
      "Epoch 542/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8783 - accuracy: 0.8537 - val_loss: 0.3600 - val_accuracy: 0.8640\n",
      "Epoch 543/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.8046 - accuracy: 0.8562 - val_loss: 0.4301 - val_accuracy: 0.8277\n",
      "Epoch 544/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7731 - accuracy: 0.8564 - val_loss: 0.3596 - val_accuracy: 0.8638\n",
      "Epoch 545/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6703 - accuracy: 0.8636 - val_loss: 0.3736 - val_accuracy: 0.8549\n",
      "Epoch 546/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6400 - accuracy: 0.8625 - val_loss: 0.3499 - val_accuracy: 0.8674\n",
      "Epoch 547/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6272 - accuracy: 0.8655 - val_loss: 0.3895 - val_accuracy: 0.8472\n",
      "Epoch 548/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6012 - accuracy: 0.8657 - val_loss: 0.3804 - val_accuracy: 0.8512\n",
      "Epoch 549/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6285 - accuracy: 0.8645 - val_loss: 0.3932 - val_accuracy: 0.8439\n",
      "Epoch 550/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6549 - accuracy: 0.8627 - val_loss: 0.3776 - val_accuracy: 0.8529\n",
      "Epoch 551/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6120 - accuracy: 0.8650 - val_loss: 0.3694 - val_accuracy: 0.8566\n",
      "Epoch 552/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5687 - accuracy: 0.8665 - val_loss: 0.3516 - val_accuracy: 0.8658\n",
      "Epoch 553/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5705 - accuracy: 0.8681 - val_loss: 0.3768 - val_accuracy: 0.8532\n",
      "Epoch 554/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6690 - accuracy: 0.8606 - val_loss: 0.3517 - val_accuracy: 0.8662\n",
      "Epoch 555/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6620 - accuracy: 0.8633 - val_loss: 0.3768 - val_accuracy: 0.8533\n",
      "Epoch 556/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6619 - accuracy: 0.8619 - val_loss: 0.3639 - val_accuracy: 0.8600\n",
      "Epoch 557/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6082 - accuracy: 0.8659 - val_loss: 0.3622 - val_accuracy: 0.8607\n",
      "Epoch 558/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6413 - accuracy: 0.8632 - val_loss: 0.3581 - val_accuracy: 0.8625\n",
      "Epoch 559/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7511 - accuracy: 0.8577 - val_loss: 0.3616 - val_accuracy: 0.8627\n",
      "Epoch 560/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5997 - accuracy: 0.8676 - val_loss: 0.3675 - val_accuracy: 0.8581\n",
      "Epoch 561/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6212 - accuracy: 0.8635 - val_loss: 0.3553 - val_accuracy: 0.8641\n",
      "Epoch 562/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7386 - accuracy: 0.8592 - val_loss: 0.3768 - val_accuracy: 0.8539\n",
      "Epoch 563/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.5944 - accuracy: 0.8661 - val_loss: 0.3763 - val_accuracy: 0.8536\n",
      "Epoch 564/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5954 - accuracy: 0.8653 - val_loss: 0.3609 - val_accuracy: 0.8603\n",
      "Epoch 565/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8206 - accuracy: 0.8543 - val_loss: 0.3905 - val_accuracy: 0.8464\n",
      "Epoch 566/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.9566 - accuracy: 0.8479 - val_loss: 0.5049 - val_accuracy: 0.7944\n",
      "Epoch 567/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8981 - accuracy: 0.8501 - val_loss: 0.4126 - val_accuracy: 0.8365\n",
      "Epoch 568/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6706 - accuracy: 0.8625 - val_loss: 0.3605 - val_accuracy: 0.8627\n",
      "Epoch 569/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6114 - accuracy: 0.8656 - val_loss: 0.3589 - val_accuracy: 0.8611\n",
      "Epoch 570/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5537 - accuracy: 0.8682 - val_loss: 0.3673 - val_accuracy: 0.8561\n",
      "Epoch 571/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6191 - accuracy: 0.8651 - val_loss: 0.3966 - val_accuracy: 0.8414\n",
      "Epoch 572/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5855 - accuracy: 0.8652 - val_loss: 0.3565 - val_accuracy: 0.8623\n",
      "Epoch 573/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5679 - accuracy: 0.8665 - val_loss: 0.3456 - val_accuracy: 0.8691\n",
      "Epoch 574/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6187 - accuracy: 0.8641 - val_loss: 0.3459 - val_accuracy: 0.8689\n",
      "Epoch 575/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5481 - accuracy: 0.8688 - val_loss: 0.3502 - val_accuracy: 0.8664\n",
      "Epoch 576/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6393 - accuracy: 0.8643 - val_loss: 0.3680 - val_accuracy: 0.8583\n",
      "Epoch 577/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7106 - accuracy: 0.8583 - val_loss: 0.3683 - val_accuracy: 0.8574\n",
      "Epoch 578/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6845 - accuracy: 0.8625 - val_loss: 0.3645 - val_accuracy: 0.8599\n",
      "Epoch 579/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5596 - accuracy: 0.8681 - val_loss: 0.3632 - val_accuracy: 0.8588\n",
      "Epoch 580/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6052 - accuracy: 0.8646 - val_loss: 0.3549 - val_accuracy: 0.8638\n",
      "Epoch 581/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6226 - accuracy: 0.8642 - val_loss: 0.3576 - val_accuracy: 0.8629\n",
      "Epoch 582/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7343 - accuracy: 0.8575 - val_loss: 0.3786 - val_accuracy: 0.8534\n",
      "Epoch 583/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6535 - accuracy: 0.8613 - val_loss: 0.3493 - val_accuracy: 0.8664\n",
      "Epoch 584/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7194 - accuracy: 0.8598 - val_loss: 0.3485 - val_accuracy: 0.8680\n",
      "Epoch 585/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7440 - accuracy: 0.8586 - val_loss: 0.3685 - val_accuracy: 0.8576\n",
      "Epoch 586/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6401 - accuracy: 0.8628 - val_loss: 0.3588 - val_accuracy: 0.8619\n",
      "Epoch 587/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5556 - accuracy: 0.8684 - val_loss: 0.3535 - val_accuracy: 0.8645\n",
      "Epoch 588/3000\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.5402 - accuracy: 0.86 - 1s 72ms/step - loss: 3.5402 - accuracy: 0.8682 - val_loss: 0.3674 - val_accuracy: 0.8562\n",
      "Epoch 589/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6055 - accuracy: 0.8652 - val_loss: 0.4150 - val_accuracy: 0.8329\n",
      "Epoch 590/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5798 - accuracy: 0.8648 - val_loss: 0.3539 - val_accuracy: 0.8637\n",
      "Epoch 591/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5357 - accuracy: 0.8687 - val_loss: 0.3510 - val_accuracy: 0.8652\n",
      "Epoch 592/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5118 - accuracy: 0.8698 - val_loss: 0.3493 - val_accuracy: 0.8654\n",
      "Epoch 593/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6754 - accuracy: 0.8604 - val_loss: 0.3428 - val_accuracy: 0.8702\n",
      "Epoch 594/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7320 - accuracy: 0.8591 - val_loss: 0.4130 - val_accuracy: 0.8366\n",
      "Epoch 595/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7793 - accuracy: 0.8543 - val_loss: 0.3545 - val_accuracy: 0.8646\n",
      "Epoch 596/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5912 - accuracy: 0.8653 - val_loss: 0.3482 - val_accuracy: 0.8676\n",
      "Epoch 597/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5756 - accuracy: 0.8659 - val_loss: 0.3459 - val_accuracy: 0.8681\n",
      "Epoch 598/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5591 - accuracy: 0.8675 - val_loss: 0.3519 - val_accuracy: 0.8659\n",
      "Epoch 599/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6641 - accuracy: 0.8605 - val_loss: 0.3820 - val_accuracy: 0.8511\n",
      "Epoch 600/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7367 - accuracy: 0.8604 - val_loss: 0.3718 - val_accuracy: 0.8553\n",
      "Epoch 601/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5311 - accuracy: 0.8690 - val_loss: 0.3750 - val_accuracy: 0.8517\n",
      "Epoch 602/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5363 - accuracy: 0.8678 - val_loss: 0.3543 - val_accuracy: 0.8629\n",
      "Epoch 603/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5369 - accuracy: 0.8676 - val_loss: 0.3433 - val_accuracy: 0.8699\n",
      "Epoch 604/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5298 - accuracy: 0.8699 - val_loss: 0.3455 - val_accuracy: 0.8679\n",
      "Epoch 605/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6842 - accuracy: 0.8602 - val_loss: 0.3431 - val_accuracy: 0.8707\n",
      "Epoch 606/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5883 - accuracy: 0.8665 - val_loss: 0.3463 - val_accuracy: 0.8689\n",
      "Epoch 607/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5804 - accuracy: 0.8661 - val_loss: 0.3491 - val_accuracy: 0.8667\n",
      "Epoch 608/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6608 - accuracy: 0.8624 - val_loss: 0.3434 - val_accuracy: 0.8706\n",
      "Epoch 609/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6252 - accuracy: 0.8655 - val_loss: 0.4432 - val_accuracy: 0.8199\n",
      "Epoch 610/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0473 - accuracy: 0.8406 - val_loss: 0.3676 - val_accuracy: 0.8613\n",
      "Epoch 611/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8593 - accuracy: 0.8549 - val_loss: 0.3775 - val_accuracy: 0.8554\n",
      "Epoch 612/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6056 - accuracy: 0.8666 - val_loss: 0.3437 - val_accuracy: 0.8696\n",
      "Epoch 613/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5364 - accuracy: 0.8687 - val_loss: 0.3435 - val_accuracy: 0.8693\n",
      "Epoch 614/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5296 - accuracy: 0.8693 - val_loss: 0.3730 - val_accuracy: 0.8547\n",
      "Epoch 615/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5214 - accuracy: 0.8688 - val_loss: 0.3569 - val_accuracy: 0.8625\n",
      "Epoch 616/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5879 - accuracy: 0.8651 - val_loss: 0.3599 - val_accuracy: 0.8604\n",
      "Epoch 617/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5548 - accuracy: 0.8678 - val_loss: 0.4049 - val_accuracy: 0.8381\n",
      "Epoch 618/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6983 - accuracy: 0.8596 - val_loss: 0.3786 - val_accuracy: 0.8530\n",
      "Epoch 619/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6169 - accuracy: 0.8631 - val_loss: 0.3441 - val_accuracy: 0.8699\n",
      "Epoch 620/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5360 - accuracy: 0.8687 - val_loss: 0.3608 - val_accuracy: 0.8607\n",
      "Epoch 621/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5158 - accuracy: 0.8688 - val_loss: 0.3492 - val_accuracy: 0.8658\n",
      "Epoch 622/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5155 - accuracy: 0.8685 - val_loss: 0.3455 - val_accuracy: 0.8681\n",
      "Epoch 623/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5320 - accuracy: 0.8682 - val_loss: 0.3365 - val_accuracy: 0.8730\n",
      "Epoch 624/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4830 - accuracy: 0.8711 - val_loss: 0.3400 - val_accuracy: 0.8712\n",
      "Epoch 625/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5632 - accuracy: 0.8663 - val_loss: 0.3564 - val_accuracy: 0.8624\n",
      "Epoch 626/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6762 - accuracy: 0.8619 - val_loss: 0.3892 - val_accuracy: 0.8476\n",
      "Epoch 627/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5335 - accuracy: 0.8681 - val_loss: 0.3760 - val_accuracy: 0.8543\n",
      "Epoch 628/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6400 - accuracy: 0.8623 - val_loss: 0.3429 - val_accuracy: 0.8704\n",
      "Epoch 629/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8827 - accuracy: 0.8515 - val_loss: 0.5585 - val_accuracy: 0.7768\n",
      "Epoch 630/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.1012 - accuracy: 0.8403 - val_loss: 0.4165 - val_accuracy: 0.8439\n",
      "Epoch 631/3000\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.6933 - accuracy: 0.86 - 1s 76ms/step - loss: 3.6933 - accuracy: 0.8622 - val_loss: 0.3799 - val_accuracy: 0.8541\n",
      "Epoch 632/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5699 - accuracy: 0.8673 - val_loss: 0.3396 - val_accuracy: 0.8719\n",
      "Epoch 633/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5103 - accuracy: 0.8702 - val_loss: 0.3470 - val_accuracy: 0.8669\n",
      "Epoch 634/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5276 - accuracy: 0.8682 - val_loss: 0.3521 - val_accuracy: 0.8636\n",
      "Epoch 635/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4739 - accuracy: 0.8708 - val_loss: 0.3441 - val_accuracy: 0.8682\n",
      "Epoch 636/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5054 - accuracy: 0.8690 - val_loss: 0.3381 - val_accuracy: 0.8718\n",
      "Epoch 637/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4848 - accuracy: 0.8711 - val_loss: 0.3503 - val_accuracy: 0.8654\n",
      "Epoch 638/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4959 - accuracy: 0.8695 - val_loss: 0.3568 - val_accuracy: 0.8618\n",
      "Epoch 639/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6276 - accuracy: 0.8630 - val_loss: 0.3933 - val_accuracy: 0.8437\n",
      "Epoch 640/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6036 - accuracy: 0.8641 - val_loss: 0.3449 - val_accuracy: 0.8700\n",
      "Epoch 641/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7202 - accuracy: 0.8576 - val_loss: 0.3392 - val_accuracy: 0.8730\n",
      "Epoch 642/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6137 - accuracy: 0.8659 - val_loss: 0.3673 - val_accuracy: 0.8582\n",
      "Epoch 643/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6089 - accuracy: 0.8637 - val_loss: 0.3604 - val_accuracy: 0.8605\n",
      "Epoch 644/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5213 - accuracy: 0.8692 - val_loss: 0.3948 - val_accuracy: 0.8422\n",
      "Epoch 645/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5195 - accuracy: 0.8685 - val_loss: 0.3509 - val_accuracy: 0.8651\n",
      "Epoch 646/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4984 - accuracy: 0.8680 - val_loss: 0.3386 - val_accuracy: 0.8713\n",
      "Epoch 647/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.4930 - accuracy: 0.8703 - val_loss: 0.3485 - val_accuracy: 0.8662\n",
      "Epoch 648/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5242 - accuracy: 0.8682 - val_loss: 0.3377 - val_accuracy: 0.8721\n",
      "Epoch 649/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5591 - accuracy: 0.8673 - val_loss: 0.4093 - val_accuracy: 0.8372\n",
      "Epoch 650/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7675 - accuracy: 0.8553 - val_loss: 0.3798 - val_accuracy: 0.8531\n",
      "Epoch 651/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8384 - accuracy: 0.8520 - val_loss: 0.4567 - val_accuracy: 0.8157\n",
      "Epoch 652/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6713 - accuracy: 0.8599 - val_loss: 0.3370 - val_accuracy: 0.8743\n",
      "Epoch 653/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6689 - accuracy: 0.8627 - val_loss: 0.3512 - val_accuracy: 0.8653\n",
      "Epoch 654/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6499 - accuracy: 0.8624 - val_loss: 0.4146 - val_accuracy: 0.8351\n",
      "Epoch 655/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6753 - accuracy: 0.8591 - val_loss: 0.3548 - val_accuracy: 0.8650\n",
      "Epoch 656/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6773 - accuracy: 0.8616 - val_loss: 0.3452 - val_accuracy: 0.8685\n",
      "Epoch 657/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6920 - accuracy: 0.8592 - val_loss: 0.4389 - val_accuracy: 0.8225\n",
      "Epoch 658/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6467 - accuracy: 0.8606 - val_loss: 0.3382 - val_accuracy: 0.8725\n",
      "Epoch 659/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5895 - accuracy: 0.8662 - val_loss: 0.3415 - val_accuracy: 0.8707\n",
      "Epoch 660/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6505 - accuracy: 0.8616 - val_loss: 0.4367 - val_accuracy: 0.8245\n",
      "Epoch 661/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6260 - accuracy: 0.8621 - val_loss: 0.3423 - val_accuracy: 0.8699\n",
      "Epoch 662/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5064 - accuracy: 0.8703 - val_loss: 0.3497 - val_accuracy: 0.8650\n",
      "Epoch 663/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4649 - accuracy: 0.8708 - val_loss: 0.3390 - val_accuracy: 0.8699\n",
      "Epoch 664/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4962 - accuracy: 0.8700 - val_loss: 0.3639 - val_accuracy: 0.8567\n",
      "Epoch 665/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4558 - accuracy: 0.8715 - val_loss: 0.3608 - val_accuracy: 0.8603\n",
      "Epoch 666/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5944 - accuracy: 0.8631 - val_loss: 0.3465 - val_accuracy: 0.8683\n",
      "Epoch 667/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5414 - accuracy: 0.8681 - val_loss: 0.3509 - val_accuracy: 0.8660\n",
      "Epoch 668/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5083 - accuracy: 0.8680 - val_loss: 0.3356 - val_accuracy: 0.8731\n",
      "Epoch 669/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4443 - accuracy: 0.8718 - val_loss: 0.3478 - val_accuracy: 0.8664\n",
      "Epoch 670/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4311 - accuracy: 0.8727 - val_loss: 0.3646 - val_accuracy: 0.8577\n",
      "Epoch 671/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4682 - accuracy: 0.8699 - val_loss: 0.3421 - val_accuracy: 0.8690\n",
      "Epoch 672/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4319 - accuracy: 0.8734 - val_loss: 0.3404 - val_accuracy: 0.8693\n",
      "Epoch 673/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4800 - accuracy: 0.8700 - val_loss: 0.3487 - val_accuracy: 0.8647\n",
      "Epoch 674/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4185 - accuracy: 0.8731 - val_loss: 0.3385 - val_accuracy: 0.8707\n",
      "Epoch 675/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4480 - accuracy: 0.8724 - val_loss: 0.3493 - val_accuracy: 0.8647\n",
      "Epoch 676/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4208 - accuracy: 0.8733 - val_loss: 0.3494 - val_accuracy: 0.8644\n",
      "Epoch 677/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4857 - accuracy: 0.8693 - val_loss: 0.3647 - val_accuracy: 0.8561\n",
      "Epoch 678/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4942 - accuracy: 0.8685 - val_loss: 0.4084 - val_accuracy: 0.8363\n",
      "Epoch 679/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6563 - accuracy: 0.8593 - val_loss: 0.3591 - val_accuracy: 0.8624\n",
      "Epoch 680/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6456 - accuracy: 0.8625 - val_loss: 0.3665 - val_accuracy: 0.8592\n",
      "Epoch 681/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4632 - accuracy: 0.8722 - val_loss: 0.3617 - val_accuracy: 0.8585\n",
      "Epoch 682/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4599 - accuracy: 0.8708 - val_loss: 0.3608 - val_accuracy: 0.8593\n",
      "Epoch 683/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4838 - accuracy: 0.8706 - val_loss: 0.4251 - val_accuracy: 0.8244\n",
      "Epoch 684/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6689 - accuracy: 0.8592 - val_loss: 0.3754 - val_accuracy: 0.8526\n",
      "Epoch 685/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4586 - accuracy: 0.8708 - val_loss: 0.3381 - val_accuracy: 0.8717\n",
      "Epoch 686/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4112 - accuracy: 0.8744 - val_loss: 0.3388 - val_accuracy: 0.8694\n",
      "Epoch 687/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.4324 - accuracy: 0.8723 - val_loss: 0.3685 - val_accuracy: 0.8543\n",
      "Epoch 688/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5910 - accuracy: 0.8653 - val_loss: 0.4507 - val_accuracy: 0.8091\n",
      "Epoch 689/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8412 - accuracy: 0.8497 - val_loss: 0.3515 - val_accuracy: 0.8676\n",
      "Epoch 690/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7245 - accuracy: 0.8600 - val_loss: 0.3392 - val_accuracy: 0.8726\n",
      "Epoch 691/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6896 - accuracy: 0.8601 - val_loss: 0.3786 - val_accuracy: 0.8534\n",
      "Epoch 692/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5323 - accuracy: 0.8682 - val_loss: 0.3674 - val_accuracy: 0.8568\n",
      "Epoch 693/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4850 - accuracy: 0.8705 - val_loss: 0.3524 - val_accuracy: 0.8631\n",
      "Epoch 694/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4378 - accuracy: 0.8720 - val_loss: 0.3433 - val_accuracy: 0.8677\n",
      "Epoch 695/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6336 - accuracy: 0.8601 - val_loss: 0.3849 - val_accuracy: 0.8484\n",
      "Epoch 696/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9537 - accuracy: 0.8468 - val_loss: 0.3541 - val_accuracy: 0.8663\n",
      "Epoch 697/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5981 - accuracy: 0.8672 - val_loss: 0.3350 - val_accuracy: 0.8742\n",
      "Epoch 698/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4332 - accuracy: 0.8737 - val_loss: 0.3575 - val_accuracy: 0.8609\n",
      "Epoch 699/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4158 - accuracy: 0.8738 - val_loss: 0.3577 - val_accuracy: 0.8593\n",
      "Epoch 700/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4133 - accuracy: 0.8724 - val_loss: 0.3436 - val_accuracy: 0.8678\n",
      "Epoch 701/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3788 - accuracy: 0.8744 - val_loss: 0.3327 - val_accuracy: 0.8731\n",
      "Epoch 702/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3909 - accuracy: 0.8740 - val_loss: 0.3318 - val_accuracy: 0.8735\n",
      "Epoch 703/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3781 - accuracy: 0.8748 - val_loss: 0.3330 - val_accuracy: 0.8725\n",
      "Epoch 704/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4195 - accuracy: 0.8729 - val_loss: 0.3374 - val_accuracy: 0.8707\n",
      "Epoch 705/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4233 - accuracy: 0.8722 - val_loss: 0.3306 - val_accuracy: 0.8748\n",
      "Epoch 706/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4265 - accuracy: 0.8730 - val_loss: 0.3270 - val_accuracy: 0.8767\n",
      "Epoch 707/3000\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.4044 - accuracy: 0.87 - 1s 74ms/step - loss: 3.4044 - accuracy: 0.8744 - val_loss: 0.3548 - val_accuracy: 0.8604\n",
      "Epoch 708/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4223 - accuracy: 0.8730 - val_loss: 0.3781 - val_accuracy: 0.8502\n",
      "Epoch 709/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5464 - accuracy: 0.8665 - val_loss: 0.4086 - val_accuracy: 0.8359\n",
      "Epoch 710/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5944 - accuracy: 0.8634 - val_loss: 0.3500 - val_accuracy: 0.8666\n",
      "Epoch 711/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5169 - accuracy: 0.8671 - val_loss: 0.3337 - val_accuracy: 0.8737\n",
      "Epoch 712/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5047 - accuracy: 0.8699 - val_loss: 0.3330 - val_accuracy: 0.8735\n",
      "Epoch 713/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4136 - accuracy: 0.8731 - val_loss: 0.3707 - val_accuracy: 0.8533\n",
      "Epoch 714/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4416 - accuracy: 0.8700 - val_loss: 0.3310 - val_accuracy: 0.8745\n",
      "Epoch 715/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3928 - accuracy: 0.8744 - val_loss: 0.3328 - val_accuracy: 0.8737\n",
      "Epoch 716/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3519 - accuracy: 0.8762 - val_loss: 0.3333 - val_accuracy: 0.8715\n",
      "Epoch 717/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4143 - accuracy: 0.8726 - val_loss: 0.3554 - val_accuracy: 0.8619\n",
      "Epoch 718/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4244 - accuracy: 0.8715 - val_loss: 0.3428 - val_accuracy: 0.8695\n",
      "Epoch 719/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4427 - accuracy: 0.8711 - val_loss: 0.3656 - val_accuracy: 0.8577\n",
      "Epoch 720/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3934 - accuracy: 0.8745 - val_loss: 0.3360 - val_accuracy: 0.8715\n",
      "Epoch 721/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4867 - accuracy: 0.8695 - val_loss: 0.3753 - val_accuracy: 0.8550\n",
      "Epoch 722/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3928 - accuracy: 0.8741 - val_loss: 0.3761 - val_accuracy: 0.8511\n",
      "Epoch 723/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5639 - accuracy: 0.8646 - val_loss: 0.3660 - val_accuracy: 0.8555\n",
      "Epoch 724/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5220 - accuracy: 0.8685 - val_loss: 0.4011 - val_accuracy: 0.8393\n",
      "Epoch 725/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7715 - accuracy: 0.8546 - val_loss: 0.3435 - val_accuracy: 0.8698\n",
      "Epoch 726/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8045 - accuracy: 0.8538 - val_loss: 0.3843 - val_accuracy: 0.8520\n",
      "Epoch 727/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4813 - accuracy: 0.8696 - val_loss: 0.3312 - val_accuracy: 0.8757\n",
      "Epoch 728/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3894 - accuracy: 0.8755 - val_loss: 0.3633 - val_accuracy: 0.8572\n",
      "Epoch 729/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3827 - accuracy: 0.8736 - val_loss: 0.3275 - val_accuracy: 0.8759\n",
      "Epoch 730/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3419 - accuracy: 0.8763 - val_loss: 0.3331 - val_accuracy: 0.8723\n",
      "Epoch 731/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3378 - accuracy: 0.8768 - val_loss: 0.3471 - val_accuracy: 0.8644\n",
      "Epoch 732/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3754 - accuracy: 0.8735 - val_loss: 0.3275 - val_accuracy: 0.8750\n",
      "Epoch 733/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3746 - accuracy: 0.8749 - val_loss: 0.3545 - val_accuracy: 0.8617\n",
      "Epoch 734/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5880 - accuracy: 0.8637 - val_loss: 0.3414 - val_accuracy: 0.8701\n",
      "Epoch 735/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0343 - accuracy: 0.8408 - val_loss: 0.3554 - val_accuracy: 0.8654\n",
      "Epoch 736/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7817 - accuracy: 0.8557 - val_loss: 0.3437 - val_accuracy: 0.8701\n",
      "Epoch 737/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4986 - accuracy: 0.8708 - val_loss: 0.3423 - val_accuracy: 0.8689\n",
      "Epoch 738/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4253 - accuracy: 0.8721 - val_loss: 0.3395 - val_accuracy: 0.8694\n",
      "Epoch 739/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4360 - accuracy: 0.8713 - val_loss: 0.3326 - val_accuracy: 0.8741\n",
      "Epoch 740/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3791 - accuracy: 0.8759 - val_loss: 0.3443 - val_accuracy: 0.8666\n",
      "Epoch 741/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3327 - accuracy: 0.8769 - val_loss: 0.3468 - val_accuracy: 0.8642\n",
      "Epoch 742/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4575 - accuracy: 0.8705 - val_loss: 0.3875 - val_accuracy: 0.8432\n",
      "Epoch 743/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5354 - accuracy: 0.8661 - val_loss: 0.3581 - val_accuracy: 0.8627\n",
      "Epoch 744/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3666 - accuracy: 0.8749 - val_loss: 0.3347 - val_accuracy: 0.8723\n",
      "Epoch 745/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3569 - accuracy: 0.8753 - val_loss: 0.3497 - val_accuracy: 0.8630\n",
      "Epoch 746/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3662 - accuracy: 0.8732 - val_loss: 0.3236 - val_accuracy: 0.8773\n",
      "Epoch 747/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3431 - accuracy: 0.8774 - val_loss: 0.3523 - val_accuracy: 0.8633\n",
      "Epoch 748/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4374 - accuracy: 0.8701 - val_loss: 0.3350 - val_accuracy: 0.8724\n",
      "Epoch 749/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4253 - accuracy: 0.8726 - val_loss: 0.3234 - val_accuracy: 0.8784\n",
      "Epoch 750/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5557 - accuracy: 0.8659 - val_loss: 0.3381 - val_accuracy: 0.8706\n",
      "Epoch 751/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4303 - accuracy: 0.8729 - val_loss: 0.3433 - val_accuracy: 0.8671\n",
      "Epoch 752/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4030 - accuracy: 0.8736 - val_loss: 0.3536 - val_accuracy: 0.8620\n",
      "Epoch 753/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4469 - accuracy: 0.8708 - val_loss: 0.3819 - val_accuracy: 0.8476\n",
      "Epoch 754/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4527 - accuracy: 0.8703 - val_loss: 0.3636 - val_accuracy: 0.8581\n",
      "Epoch 755/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.4341 - accuracy: 0.8713 - val_loss: 0.3533 - val_accuracy: 0.8634\n",
      "Epoch 756/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6341 - accuracy: 0.8587 - val_loss: 0.3669 - val_accuracy: 0.8579\n",
      "Epoch 757/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0838 - accuracy: 0.8407 - val_loss: 0.3572 - val_accuracy: 0.8654\n",
      "Epoch 758/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6764 - accuracy: 0.8644 - val_loss: 0.3701 - val_accuracy: 0.8583\n",
      "Epoch 759/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4431 - accuracy: 0.8726 - val_loss: 0.3276 - val_accuracy: 0.8764\n",
      "Epoch 760/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3534 - accuracy: 0.8765 - val_loss: 0.3437 - val_accuracy: 0.8668\n",
      "Epoch 761/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3302 - accuracy: 0.8759 - val_loss: 0.3563 - val_accuracy: 0.8612\n",
      "Epoch 762/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3520 - accuracy: 0.8753 - val_loss: 0.3276 - val_accuracy: 0.8749\n",
      "Epoch 763/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3613 - accuracy: 0.8753 - val_loss: 0.3595 - val_accuracy: 0.8568\n",
      "Epoch 764/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4533 - accuracy: 0.8701 - val_loss: 0.3959 - val_accuracy: 0.8388\n",
      "Epoch 765/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6037 - accuracy: 0.8627 - val_loss: 0.3531 - val_accuracy: 0.8627\n",
      "Epoch 766/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.9015 - accuracy: 0.8502 - val_loss: 0.4725 - val_accuracy: 0.8028\n",
      "Epoch 767/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8244 - accuracy: 0.8500 - val_loss: 0.3415 - val_accuracy: 0.8731\n",
      "Epoch 768/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5095 - accuracy: 0.8708 - val_loss: 0.3294 - val_accuracy: 0.8762\n",
      "Epoch 769/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3963 - accuracy: 0.8742 - val_loss: 0.3573 - val_accuracy: 0.8599\n",
      "Epoch 770/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4131 - accuracy: 0.8722 - val_loss: 0.3484 - val_accuracy: 0.8645\n",
      "Epoch 771/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4811 - accuracy: 0.8684 - val_loss: 0.3640 - val_accuracy: 0.8568\n",
      "Epoch 772/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4364 - accuracy: 0.8712 - val_loss: 0.3275 - val_accuracy: 0.8765\n",
      "Epoch 773/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3971 - accuracy: 0.8745 - val_loss: 0.3553 - val_accuracy: 0.8618\n",
      "Epoch 774/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3103 - accuracy: 0.8771 - val_loss: 0.3323 - val_accuracy: 0.8722\n",
      "Epoch 775/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3289 - accuracy: 0.8764 - val_loss: 0.3350 - val_accuracy: 0.8724\n",
      "Epoch 776/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3555 - accuracy: 0.8750 - val_loss: 0.3564 - val_accuracy: 0.8608\n",
      "Epoch 777/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3324 - accuracy: 0.8749 - val_loss: 0.3197 - val_accuracy: 0.8797\n",
      "Epoch 778/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3936 - accuracy: 0.8739 - val_loss: 0.3354 - val_accuracy: 0.8722\n",
      "Epoch 779/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4295 - accuracy: 0.8720 - val_loss: 0.3329 - val_accuracy: 0.8721\n",
      "Epoch 780/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5019 - accuracy: 0.8670 - val_loss: 0.3328 - val_accuracy: 0.8731\n",
      "Epoch 781/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4146 - accuracy: 0.8729 - val_loss: 0.3234 - val_accuracy: 0.8785\n",
      "Epoch 782/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3273 - accuracy: 0.8772 - val_loss: 0.3650 - val_accuracy: 0.8568\n",
      "Epoch 783/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3466 - accuracy: 0.8753 - val_loss: 0.3844 - val_accuracy: 0.8464\n",
      "Epoch 784/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5359 - accuracy: 0.8666 - val_loss: 0.3672 - val_accuracy: 0.8560\n",
      "Epoch 785/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3415 - accuracy: 0.8749 - val_loss: 0.3253 - val_accuracy: 0.8764\n",
      "Epoch 786/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3223 - accuracy: 0.8758 - val_loss: 0.3251 - val_accuracy: 0.8766\n",
      "Epoch 787/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3836 - accuracy: 0.8731 - val_loss: 0.3344 - val_accuracy: 0.8723\n",
      "Epoch 788/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4160 - accuracy: 0.8727 - val_loss: 0.3265 - val_accuracy: 0.8763\n",
      "Epoch 789/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3393 - accuracy: 0.8777 - val_loss: 0.3315 - val_accuracy: 0.8729\n",
      "Epoch 790/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2989 - accuracy: 0.8779 - val_loss: 0.3465 - val_accuracy: 0.8649\n",
      "Epoch 791/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4291 - accuracy: 0.8701 - val_loss: 0.3171 - val_accuracy: 0.8810\n",
      "Epoch 792/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5116 - accuracy: 0.8675 - val_loss: 0.3869 - val_accuracy: 0.8486\n",
      "Epoch 793/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4398 - accuracy: 0.8708 - val_loss: 0.3220 - val_accuracy: 0.8794\n",
      "Epoch 794/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4553 - accuracy: 0.8703 - val_loss: 0.3412 - val_accuracy: 0.8676\n",
      "Epoch 795/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3336 - accuracy: 0.8768 - val_loss: 0.3602 - val_accuracy: 0.8591\n",
      "Epoch 796/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3014 - accuracy: 0.8773 - val_loss: 0.3226 - val_accuracy: 0.8776\n",
      "Epoch 797/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3075 - accuracy: 0.8777 - val_loss: 0.3592 - val_accuracy: 0.8586\n",
      "Epoch 798/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3616 - accuracy: 0.8724 - val_loss: 0.3228 - val_accuracy: 0.8778\n",
      "Epoch 799/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4206 - accuracy: 0.8722 - val_loss: 0.3241 - val_accuracy: 0.8787\n",
      "Epoch 800/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4820 - accuracy: 0.8704 - val_loss: 0.3597 - val_accuracy: 0.8618\n",
      "Epoch 801/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3566 - accuracy: 0.8748 - val_loss: 0.3176 - val_accuracy: 0.8804\n",
      "Epoch 802/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2957 - accuracy: 0.8783 - val_loss: 0.3217 - val_accuracy: 0.8771\n",
      "Epoch 803/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3551 - accuracy: 0.8750 - val_loss: 0.3362 - val_accuracy: 0.8704\n",
      "Epoch 804/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4832 - accuracy: 0.8676 - val_loss: 0.3280 - val_accuracy: 0.8765\n",
      "Epoch 805/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5389 - accuracy: 0.8663 - val_loss: 0.3763 - val_accuracy: 0.8555\n",
      "Epoch 806/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5703 - accuracy: 0.8631 - val_loss: 0.3517 - val_accuracy: 0.8641\n",
      "Epoch 807/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7333 - accuracy: 0.8566 - val_loss: 0.3252 - val_accuracy: 0.8775\n",
      "Epoch 808/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5119 - accuracy: 0.8685 - val_loss: 0.3329 - val_accuracy: 0.8739\n",
      "Epoch 809/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4612 - accuracy: 0.8711 - val_loss: 0.4260 - val_accuracy: 0.8266\n",
      "Epoch 810/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4143 - accuracy: 0.8702 - val_loss: 0.3180 - val_accuracy: 0.8799\n",
      "Epoch 811/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2873 - accuracy: 0.8794 - val_loss: 0.3578 - val_accuracy: 0.8610\n",
      "Epoch 812/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2873 - accuracy: 0.8782 - val_loss: 0.3427 - val_accuracy: 0.8654\n",
      "Epoch 813/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2660 - accuracy: 0.8789 - val_loss: 0.3504 - val_accuracy: 0.8627\n",
      "Epoch 814/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3312 - accuracy: 0.8749 - val_loss: 0.3184 - val_accuracy: 0.8799\n",
      "Epoch 815/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3459 - accuracy: 0.8753 - val_loss: 0.3233 - val_accuracy: 0.8785\n",
      "Epoch 816/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2981 - accuracy: 0.8791 - val_loss: 0.3228 - val_accuracy: 0.8769\n",
      "Epoch 817/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4022 - accuracy: 0.8718 - val_loss: 0.3468 - val_accuracy: 0.8667\n",
      "Epoch 818/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4056 - accuracy: 0.8744 - val_loss: 0.3294 - val_accuracy: 0.8753\n",
      "Epoch 819/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2559 - accuracy: 0.8801 - val_loss: 0.3305 - val_accuracy: 0.8729\n",
      "Epoch 820/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3047 - accuracy: 0.8768 - val_loss: 0.3930 - val_accuracy: 0.8425\n",
      "Epoch 821/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5208 - accuracy: 0.8659 - val_loss: 0.3721 - val_accuracy: 0.8548\n",
      "Epoch 822/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3460 - accuracy: 0.8752 - val_loss: 0.3251 - val_accuracy: 0.8767\n",
      "Epoch 823/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2869 - accuracy: 0.8790 - val_loss: 0.3202 - val_accuracy: 0.8780\n",
      "Epoch 824/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4783 - accuracy: 0.8672 - val_loss: 0.3854 - val_accuracy: 0.8494\n",
      "Epoch 825/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.9830 - accuracy: 0.8443 - val_loss: 0.3691 - val_accuracy: 0.8635\n",
      "Epoch 826/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6310 - accuracy: 0.8650 - val_loss: 0.3376 - val_accuracy: 0.8734\n",
      "Epoch 827/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3953 - accuracy: 0.8742 - val_loss: 0.3606 - val_accuracy: 0.8568\n",
      "Epoch 828/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3606 - accuracy: 0.8745 - val_loss: 0.3453 - val_accuracy: 0.8649\n",
      "Epoch 829/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3082 - accuracy: 0.8765 - val_loss: 0.3168 - val_accuracy: 0.8799\n",
      "Epoch 830/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2559 - accuracy: 0.8793 - val_loss: 0.3279 - val_accuracy: 0.8758\n",
      "Epoch 831/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5276 - accuracy: 0.8661 - val_loss: 0.3919 - val_accuracy: 0.8435\n",
      "Epoch 832/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 3.8308 - accuracy: 0.8510 - val_loss: 0.3455 - val_accuracy: 0.8704\n",
      "Epoch 833/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 3.5868 - accuracy: 0.8661 - val_loss: 0.3564 - val_accuracy: 0.8647\n",
      "Epoch 834/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3716 - accuracy: 0.8755 - val_loss: 0.3209 - val_accuracy: 0.8787\n",
      "Epoch 835/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.3213 - accuracy: 0.8773 - val_loss: 0.3445 - val_accuracy: 0.8650\n",
      "Epoch 836/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.2407 - accuracy: 0.8792 - val_loss: 0.3249 - val_accuracy: 0.8753\n",
      "Epoch 837/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2732 - accuracy: 0.8794 - val_loss: 0.3240 - val_accuracy: 0.8761\n",
      "Epoch 838/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3240 - accuracy: 0.8761 - val_loss: 0.3164 - val_accuracy: 0.8804\n",
      "Epoch 839/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2880 - accuracy: 0.8779 - val_loss: 0.3340 - val_accuracy: 0.8709\n",
      "Epoch 840/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3911 - accuracy: 0.8722 - val_loss: 0.3577 - val_accuracy: 0.8601\n",
      "Epoch 841/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8576 - accuracy: 0.8492 - val_loss: 0.3758 - val_accuracy: 0.8565\n",
      "Epoch 842/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6658 - accuracy: 0.8620 - val_loss: 0.4413 - val_accuracy: 0.8185\n",
      "Epoch 843/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5048 - accuracy: 0.8660 - val_loss: 0.3770 - val_accuracy: 0.8491\n",
      "Epoch 844/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4903 - accuracy: 0.8661 - val_loss: 0.3251 - val_accuracy: 0.8767\n",
      "Epoch 845/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4783 - accuracy: 0.8706 - val_loss: 0.3185 - val_accuracy: 0.8808\n",
      "Epoch 846/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2995 - accuracy: 0.8792 - val_loss: 0.3614 - val_accuracy: 0.8585\n",
      "Epoch 847/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3422 - accuracy: 0.8739 - val_loss: 0.3166 - val_accuracy: 0.8808\n",
      "Epoch 848/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2853 - accuracy: 0.8797 - val_loss: 0.3550 - val_accuracy: 0.8588\n",
      "Epoch 849/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3579 - accuracy: 0.8735 - val_loss: 0.3208 - val_accuracy: 0.8782\n",
      "Epoch 850/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3975 - accuracy: 0.8722 - val_loss: 0.3429 - val_accuracy: 0.8684\n",
      "Epoch 851/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3142 - accuracy: 0.8758 - val_loss: 0.3160 - val_accuracy: 0.8804\n",
      "Epoch 852/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2362 - accuracy: 0.8812 - val_loss: 0.3167 - val_accuracy: 0.8795\n",
      "Epoch 853/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2435 - accuracy: 0.8800 - val_loss: 0.3174 - val_accuracy: 0.8790\n",
      "Epoch 854/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2263 - accuracy: 0.8801 - val_loss: 0.3228 - val_accuracy: 0.8761\n",
      "Epoch 855/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3147 - accuracy: 0.8767 - val_loss: 0.3586 - val_accuracy: 0.8587\n",
      "Epoch 856/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3972 - accuracy: 0.8725 - val_loss: 0.3707 - val_accuracy: 0.8520\n",
      "Epoch 857/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4006 - accuracy: 0.8708 - val_loss: 0.3300 - val_accuracy: 0.8752\n",
      "Epoch 858/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5250 - accuracy: 0.8673 - val_loss: 0.3296 - val_accuracy: 0.8762\n",
      "Epoch 859/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6400 - accuracy: 0.8608 - val_loss: 0.3472 - val_accuracy: 0.8687\n",
      "Epoch 860/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3406 - accuracy: 0.8769 - val_loss: 0.3603 - val_accuracy: 0.8604\n",
      "Epoch 861/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3501 - accuracy: 0.8738 - val_loss: 0.3459 - val_accuracy: 0.8664\n",
      "Epoch 862/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8258 - accuracy: 0.8514 - val_loss: 0.3495 - val_accuracy: 0.8674\n",
      "Epoch 863/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5996 - accuracy: 0.8650 - val_loss: 0.3258 - val_accuracy: 0.8778\n",
      "Epoch 864/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3321 - accuracy: 0.8780 - val_loss: 0.3235 - val_accuracy: 0.8777\n",
      "Epoch 865/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2593 - accuracy: 0.8804 - val_loss: 0.3285 - val_accuracy: 0.8722\n",
      "Epoch 866/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2110 - accuracy: 0.8803 - val_loss: 0.3279 - val_accuracy: 0.8731\n",
      "Epoch 867/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2215 - accuracy: 0.8810 - val_loss: 0.3369 - val_accuracy: 0.8674\n",
      "Epoch 868/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.2962 - accuracy: 0.8767 - val_loss: 0.3420 - val_accuracy: 0.8657\n",
      "Epoch 869/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.3242 - accuracy: 0.8744 - val_loss: 0.3174 - val_accuracy: 0.8799\n",
      "Epoch 870/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2120 - accuracy: 0.8813 - val_loss: 0.3122 - val_accuracy: 0.8822\n",
      "Epoch 871/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2102 - accuracy: 0.8820 - val_loss: 0.3582 - val_accuracy: 0.8573\n",
      "Epoch 872/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.9896 - accuracy: 0.8415 - val_loss: 0.4069 - val_accuracy: 0.8466\n",
      "Epoch 873/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1870 - accuracy: 0.8368 - val_loss: 0.4343 - val_accuracy: 0.8378\n",
      "Epoch 874/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6711 - accuracy: 0.8646 - val_loss: 0.4016 - val_accuracy: 0.8418\n",
      "Epoch 875/3000\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 3.3944 - accuracy: 0.8733 - val_loss: 0.3451 - val_accuracy: 0.8664\n",
      "Epoch 876/3000\n",
      "10/10 [==============================] - 1s 80ms/step - loss: 3.2837 - accuracy: 0.8778 - val_loss: 0.3290 - val_accuracy: 0.8726\n",
      "Epoch 877/3000\n",
      "10/10 [==============================] - 1s 80ms/step - loss: 3.2469 - accuracy: 0.8795 - val_loss: 0.3160 - val_accuracy: 0.8793\n",
      "Epoch 878/3000\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 3.2848 - accuracy: 0.8778 - val_loss: 0.3545 - val_accuracy: 0.8598\n",
      "Epoch 879/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2633 - accuracy: 0.8785 - val_loss: 0.3210 - val_accuracy: 0.8770\n",
      "Epoch 880/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2367 - accuracy: 0.8794 - val_loss: 0.3134 - val_accuracy: 0.8811\n",
      "Epoch 881/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2084 - accuracy: 0.8816 - val_loss: 0.3249 - val_accuracy: 0.8746\n",
      "Epoch 882/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2215 - accuracy: 0.8806 - val_loss: 0.3157 - val_accuracy: 0.8795\n",
      "Epoch 883/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2380 - accuracy: 0.8808 - val_loss: 0.3483 - val_accuracy: 0.8625\n",
      "Epoch 884/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2853 - accuracy: 0.8771 - val_loss: 0.3404 - val_accuracy: 0.8682\n",
      "Epoch 885/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2096 - accuracy: 0.8825 - val_loss: 0.3402 - val_accuracy: 0.8682\n",
      "Epoch 886/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2308 - accuracy: 0.8797 - val_loss: 0.3131 - val_accuracy: 0.8809\n",
      "Epoch 887/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.2104 - accuracy: 0.8814 - val_loss: 0.3616 - val_accuracy: 0.8572\n",
      "Epoch 888/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2317 - accuracy: 0.8789 - val_loss: 0.3108 - val_accuracy: 0.8822\n",
      "Epoch 889/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3618 - accuracy: 0.8743 - val_loss: 0.3262 - val_accuracy: 0.8738\n",
      "Epoch 890/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 3.3462 - accuracy: 0.8741 - val_loss: 0.3103 - val_accuracy: 0.8840\n",
      "Epoch 891/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.2609 - accuracy: 0.8798 - val_loss: 0.3620 - val_accuracy: 0.8592\n",
      "Epoch 892/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3012 - accuracy: 0.8779 - val_loss: 0.3596 - val_accuracy: 0.8591\n",
      "Epoch 893/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2615 - accuracy: 0.8794 - val_loss: 0.3600 - val_accuracy: 0.8582\n",
      "Epoch 894/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2925 - accuracy: 0.8776 - val_loss: 0.3513 - val_accuracy: 0.8630\n",
      "Epoch 895/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3009 - accuracy: 0.8770 - val_loss: 0.3501 - val_accuracy: 0.8636\n",
      "Epoch 896/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2486 - accuracy: 0.8791 - val_loss: 0.3288 - val_accuracy: 0.8739\n",
      "Epoch 897/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3330 - accuracy: 0.8743 - val_loss: 0.3150 - val_accuracy: 0.8805\n",
      "Epoch 898/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6132 - accuracy: 0.8640 - val_loss: 0.3494 - val_accuracy: 0.8688\n",
      "Epoch 899/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9676 - accuracy: 0.8457 - val_loss: 0.3376 - val_accuracy: 0.8746\n",
      "Epoch 900/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5908 - accuracy: 0.8657 - val_loss: 0.3315 - val_accuracy: 0.8752\n",
      "Epoch 901/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3665 - accuracy: 0.8750 - val_loss: 0.3124 - val_accuracy: 0.8826\n",
      "Epoch 902/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2499 - accuracy: 0.8805 - val_loss: 0.3364 - val_accuracy: 0.8694\n",
      "Epoch 903/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2297 - accuracy: 0.8798 - val_loss: 0.3184 - val_accuracy: 0.8780\n",
      "Epoch 904/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2177 - accuracy: 0.8804 - val_loss: 0.3156 - val_accuracy: 0.8804\n",
      "Epoch 905/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2272 - accuracy: 0.8789 - val_loss: 0.3170 - val_accuracy: 0.8798\n",
      "Epoch 906/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.2886 - accuracy: 0.8768 - val_loss: 0.3435 - val_accuracy: 0.8676\n",
      "Epoch 907/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8318 - accuracy: 0.8522 - val_loss: 0.3421 - val_accuracy: 0.8727\n",
      "Epoch 908/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5941 - accuracy: 0.8636 - val_loss: 0.3272 - val_accuracy: 0.8783\n",
      "Epoch 909/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3507 - accuracy: 0.8768 - val_loss: 0.3141 - val_accuracy: 0.8819\n",
      "Epoch 910/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2400 - accuracy: 0.8810 - val_loss: 0.3360 - val_accuracy: 0.8690\n",
      "Epoch 911/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2086 - accuracy: 0.8805 - val_loss: 0.3101 - val_accuracy: 0.8827\n",
      "Epoch 912/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2643 - accuracy: 0.8784 - val_loss: 0.3115 - val_accuracy: 0.8828\n",
      "Epoch 913/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2559 - accuracy: 0.8794 - val_loss: 0.3229 - val_accuracy: 0.8765\n",
      "Epoch 914/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1927 - accuracy: 0.8825 - val_loss: 0.3295 - val_accuracy: 0.8735\n",
      "Epoch 915/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1782 - accuracy: 0.8823 - val_loss: 0.3645 - val_accuracy: 0.8556\n",
      "Epoch 916/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2342 - accuracy: 0.8791 - val_loss: 0.3292 - val_accuracy: 0.8720\n",
      "Epoch 917/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3469 - accuracy: 0.8753 - val_loss: 0.3595 - val_accuracy: 0.8586\n",
      "Epoch 918/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3351 - accuracy: 0.8747 - val_loss: 0.3141 - val_accuracy: 0.8821\n",
      "Epoch 919/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2546 - accuracy: 0.8800 - val_loss: 0.3213 - val_accuracy: 0.8781\n",
      "Epoch 920/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1751 - accuracy: 0.8826 - val_loss: 0.3099 - val_accuracy: 0.8818\n",
      "Epoch 921/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2697 - accuracy: 0.8779 - val_loss: 0.3293 - val_accuracy: 0.8723\n",
      "Epoch 922/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1925 - accuracy: 0.8813 - val_loss: 0.3180 - val_accuracy: 0.8787\n",
      "Epoch 923/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1793 - accuracy: 0.8829 - val_loss: 0.3402 - val_accuracy: 0.8685\n",
      "Epoch 924/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3472 - accuracy: 0.8734 - val_loss: 0.3032 - val_accuracy: 0.8869\n",
      "Epoch 925/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2046 - accuracy: 0.8824 - val_loss: 0.3179 - val_accuracy: 0.8790\n",
      "Epoch 926/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5345 - accuracy: 0.8659 - val_loss: 0.4801 - val_accuracy: 0.8035\n",
      "Epoch 927/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7368 - accuracy: 0.8572 - val_loss: 0.3677 - val_accuracy: 0.8593\n",
      "Epoch 928/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4415 - accuracy: 0.8705 - val_loss: 0.3388 - val_accuracy: 0.8704\n",
      "Epoch 929/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6145 - accuracy: 0.8609 - val_loss: 0.3271 - val_accuracy: 0.8776\n",
      "Epoch 930/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4223 - accuracy: 0.8717 - val_loss: 0.3089 - val_accuracy: 0.8849\n",
      "Epoch 931/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4186 - accuracy: 0.8718 - val_loss: 0.3245 - val_accuracy: 0.8769\n",
      "Epoch 932/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2789 - accuracy: 0.8782 - val_loss: 0.3600 - val_accuracy: 0.8575\n",
      "Epoch 933/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2580 - accuracy: 0.8775 - val_loss: 0.3224 - val_accuracy: 0.8773\n",
      "Epoch 934/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2310 - accuracy: 0.8804 - val_loss: 0.3110 - val_accuracy: 0.8820\n",
      "Epoch 935/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1844 - accuracy: 0.8823 - val_loss: 0.3298 - val_accuracy: 0.8728\n",
      "Epoch 936/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2343 - accuracy: 0.8791 - val_loss: 0.3567 - val_accuracy: 0.8585\n",
      "Epoch 937/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2552 - accuracy: 0.8779 - val_loss: 0.3329 - val_accuracy: 0.8710\n",
      "Epoch 938/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1995 - accuracy: 0.8813 - val_loss: 0.3088 - val_accuracy: 0.8835\n",
      "Epoch 939/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2739 - accuracy: 0.8761 - val_loss: 0.3507 - val_accuracy: 0.8654\n",
      "Epoch 940/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8822 - accuracy: 0.8482 - val_loss: 0.3801 - val_accuracy: 0.8596\n",
      "Epoch 941/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6925 - accuracy: 0.8619 - val_loss: 0.3245 - val_accuracy: 0.8764\n",
      "Epoch 942/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4240 - accuracy: 0.8723 - val_loss: 0.3167 - val_accuracy: 0.8801\n",
      "Epoch 943/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2757 - accuracy: 0.8791 - val_loss: 0.3196 - val_accuracy: 0.8779\n",
      "Epoch 944/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2305 - accuracy: 0.8794 - val_loss: 0.3203 - val_accuracy: 0.8769\n",
      "Epoch 945/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1957 - accuracy: 0.8819 - val_loss: 0.3225 - val_accuracy: 0.8763\n",
      "Epoch 946/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2223 - accuracy: 0.8786 - val_loss: 0.3057 - val_accuracy: 0.8851\n",
      "Epoch 947/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2353 - accuracy: 0.8811 - val_loss: 0.3572 - val_accuracy: 0.8594\n",
      "Epoch 948/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1748 - accuracy: 0.8821 - val_loss: 0.3154 - val_accuracy: 0.8792\n",
      "Epoch 949/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1367 - accuracy: 0.8840 - val_loss: 0.3024 - val_accuracy: 0.8862\n",
      "Epoch 950/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.2173 - accuracy: 0.8815 - val_loss: 0.3687 - val_accuracy: 0.8538\n",
      "Epoch 951/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1959 - accuracy: 0.8807 - val_loss: 0.3146 - val_accuracy: 0.8805\n",
      "Epoch 952/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4394 - accuracy: 0.8700 - val_loss: 0.4590 - val_accuracy: 0.8135\n",
      "Epoch 953/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9131 - accuracy: 0.8484 - val_loss: 0.4478 - val_accuracy: 0.8207\n",
      "Epoch 954/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4124 - accuracy: 0.8722 - val_loss: 0.3365 - val_accuracy: 0.8710\n",
      "Epoch 955/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3530 - accuracy: 0.8755 - val_loss: 0.4412 - val_accuracy: 0.8165\n",
      "Epoch 956/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4459 - accuracy: 0.8689 - val_loss: 0.3750 - val_accuracy: 0.8526\n",
      "Epoch 957/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3858 - accuracy: 0.8719 - val_loss: 0.3129 - val_accuracy: 0.8822\n",
      "Epoch 958/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2483 - accuracy: 0.8801 - val_loss: 0.3108 - val_accuracy: 0.8828\n",
      "Epoch 959/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2952 - accuracy: 0.8782 - val_loss: 0.3299 - val_accuracy: 0.8732\n",
      "Epoch 960/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4489 - accuracy: 0.8699 - val_loss: 0.4460 - val_accuracy: 0.8174\n",
      "Epoch 961/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3545 - accuracy: 0.8743 - val_loss: 0.3604 - val_accuracy: 0.8608\n",
      "Epoch 962/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2752 - accuracy: 0.8776 - val_loss: 0.3136 - val_accuracy: 0.8807\n",
      "Epoch 963/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2476 - accuracy: 0.8798 - val_loss: 0.3189 - val_accuracy: 0.8777\n",
      "Epoch 964/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3437 - accuracy: 0.8750 - val_loss: 0.4069 - val_accuracy: 0.8353\n",
      "Epoch 965/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6646 - accuracy: 0.8572 - val_loss: 0.3778 - val_accuracy: 0.8527\n",
      "Epoch 966/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4143 - accuracy: 0.8723 - val_loss: 0.3563 - val_accuracy: 0.8612\n",
      "Epoch 967/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2188 - accuracy: 0.8812 - val_loss: 0.3091 - val_accuracy: 0.8836\n",
      "Epoch 968/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1385 - accuracy: 0.8848 - val_loss: 0.3168 - val_accuracy: 0.8781\n",
      "Epoch 969/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1653 - accuracy: 0.8823 - val_loss: 0.3265 - val_accuracy: 0.8731\n",
      "Epoch 970/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1235 - accuracy: 0.8847 - val_loss: 0.3167 - val_accuracy: 0.8775\n",
      "Epoch 971/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1571 - accuracy: 0.8836 - val_loss: 0.3436 - val_accuracy: 0.8650\n",
      "Epoch 972/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1872 - accuracy: 0.8807 - val_loss: 0.3278 - val_accuracy: 0.8755\n",
      "Epoch 973/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1401 - accuracy: 0.8842 - val_loss: 0.3214 - val_accuracy: 0.8759\n",
      "Epoch 974/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1413 - accuracy: 0.8846 - val_loss: 0.3296 - val_accuracy: 0.8708\n",
      "Epoch 975/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2635 - accuracy: 0.8781 - val_loss: 0.3972 - val_accuracy: 0.8373\n",
      "Epoch 976/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.9551 - accuracy: 0.8440 - val_loss: 0.4229 - val_accuracy: 0.8301\n",
      "Epoch 977/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5746 - accuracy: 0.8673 - val_loss: 0.3644 - val_accuracy: 0.8616\n",
      "Epoch 978/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2666 - accuracy: 0.8803 - val_loss: 0.3283 - val_accuracy: 0.8736\n",
      "Epoch 979/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1659 - accuracy: 0.8830 - val_loss: 0.3078 - val_accuracy: 0.8826\n",
      "Epoch 980/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2570 - accuracy: 0.8781 - val_loss: 0.3152 - val_accuracy: 0.8799\n",
      "Epoch 981/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1908 - accuracy: 0.8834 - val_loss: 0.3352 - val_accuracy: 0.8682\n",
      "Epoch 982/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2073 - accuracy: 0.8791 - val_loss: 0.3098 - val_accuracy: 0.8819\n",
      "Epoch 983/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2406 - accuracy: 0.8784 - val_loss: 0.3034 - val_accuracy: 0.8866\n",
      "Epoch 984/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1823 - accuracy: 0.8840 - val_loss: 0.3330 - val_accuracy: 0.8705\n",
      "Epoch 985/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1862 - accuracy: 0.8828 - val_loss: 0.3368 - val_accuracy: 0.8694\n",
      "Epoch 986/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1081 - accuracy: 0.8850 - val_loss: 0.3120 - val_accuracy: 0.8811\n",
      "Epoch 987/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1011 - accuracy: 0.8853 - val_loss: 0.3063 - val_accuracy: 0.8833\n",
      "Epoch 988/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0888 - accuracy: 0.8861 - val_loss: 0.3148 - val_accuracy: 0.8787\n",
      "Epoch 989/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3121 - accuracy: 0.8754 - val_loss: 0.3778 - val_accuracy: 0.8499\n",
      "Epoch 990/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.0821 - accuracy: 0.8391 - val_loss: 0.5801 - val_accuracy: 0.7856\n",
      "Epoch 991/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9841 - accuracy: 0.8491 - val_loss: 0.3829 - val_accuracy: 0.8540\n",
      "Epoch 992/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.4469 - accuracy: 0.8719 - val_loss: 0.3261 - val_accuracy: 0.8752\n",
      "Epoch 993/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2820 - accuracy: 0.8781 - val_loss: 0.3305 - val_accuracy: 0.8720\n",
      "Epoch 994/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1979 - accuracy: 0.8821 - val_loss: 0.3176 - val_accuracy: 0.8772\n",
      "Epoch 995/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1472 - accuracy: 0.8825 - val_loss: 0.3037 - val_accuracy: 0.8851\n",
      "Epoch 996/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1654 - accuracy: 0.8832 - val_loss: 0.3124 - val_accuracy: 0.8800\n",
      "Epoch 997/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1544 - accuracy: 0.8832 - val_loss: 0.3098 - val_accuracy: 0.8817\n",
      "Epoch 998/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2309 - accuracy: 0.8792 - val_loss: 0.3354 - val_accuracy: 0.8693\n",
      "Epoch 999/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2312 - accuracy: 0.8805 - val_loss: 0.3239 - val_accuracy: 0.8753\n",
      "Epoch 1000/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4171 - accuracy: 0.8712 - val_loss: 0.4786 - val_accuracy: 0.8042\n",
      "Epoch 1001/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7252 - accuracy: 0.8565 - val_loss: 0.4301 - val_accuracy: 0.8272\n",
      "Epoch 1002/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3845 - accuracy: 0.8726 - val_loss: 0.3636 - val_accuracy: 0.8586\n",
      "Epoch 1003/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1864 - accuracy: 0.8824 - val_loss: 0.3087 - val_accuracy: 0.8829\n",
      "Epoch 1004/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1142 - accuracy: 0.8853 - val_loss: 0.3015 - val_accuracy: 0.8860\n",
      "Epoch 1005/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1323 - accuracy: 0.8851 - val_loss: 0.3440 - val_accuracy: 0.8626\n",
      "Epoch 1006/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1911 - accuracy: 0.8807 - val_loss: 0.3039 - val_accuracy: 0.8861\n",
      "Epoch 1007/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1424 - accuracy: 0.8847 - val_loss: 0.3334 - val_accuracy: 0.8702\n",
      "Epoch 1008/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1475 - accuracy: 0.8836 - val_loss: 0.3526 - val_accuracy: 0.8596\n",
      "Epoch 1009/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1831 - accuracy: 0.8817 - val_loss: 0.3807 - val_accuracy: 0.8453\n",
      "Epoch 1010/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.2051 - accuracy: 0.8795 - val_loss: 0.3206 - val_accuracy: 0.8780\n",
      "Epoch 1011/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.3740 - accuracy: 0.8705 - val_loss: 0.3435 - val_accuracy: 0.8680\n",
      "Epoch 1012/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8295 - accuracy: 0.8498 - val_loss: 0.3140 - val_accuracy: 0.8820\n",
      "Epoch 1013/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5159 - accuracy: 0.8702 - val_loss: 0.3204 - val_accuracy: 0.8807\n",
      "Epoch 1014/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3332 - accuracy: 0.8764 - val_loss: 0.3115 - val_accuracy: 0.8836\n",
      "Epoch 1015/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2992 - accuracy: 0.8776 - val_loss: 0.3032 - val_accuracy: 0.8854\n",
      "Epoch 1016/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1468 - accuracy: 0.8840 - val_loss: 0.3231 - val_accuracy: 0.8772\n",
      "Epoch 1017/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1671 - accuracy: 0.8834 - val_loss: 0.3418 - val_accuracy: 0.8639\n",
      "Epoch 1018/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1341 - accuracy: 0.8841 - val_loss: 0.3423 - val_accuracy: 0.8641\n",
      "Epoch 1019/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0945 - accuracy: 0.8855 - val_loss: 0.3034 - val_accuracy: 0.8852\n",
      "Epoch 1020/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0868 - accuracy: 0.8859 - val_loss: 0.3052 - val_accuracy: 0.8835\n",
      "Epoch 1021/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1216 - accuracy: 0.8852 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "Epoch 1022/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2434 - accuracy: 0.8783 - val_loss: 0.3317 - val_accuracy: 0.8712\n",
      "Epoch 1023/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1542 - accuracy: 0.8839 - val_loss: 0.3233 - val_accuracy: 0.8771\n",
      "Epoch 1024/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0931 - accuracy: 0.8859 - val_loss: 0.3027 - val_accuracy: 0.8857\n",
      "Epoch 1025/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2326 - accuracy: 0.8804 - val_loss: 0.3906 - val_accuracy: 0.8408\n",
      "Epoch 1026/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7525 - accuracy: 0.8544 - val_loss: 0.3714 - val_accuracy: 0.8528\n",
      "Epoch 1027/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4946 - accuracy: 0.8696 - val_loss: 0.3570 - val_accuracy: 0.8654\n",
      "Epoch 1028/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3843 - accuracy: 0.8729 - val_loss: 0.3114 - val_accuracy: 0.8834\n",
      "Epoch 1029/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3108 - accuracy: 0.8775 - val_loss: 0.3109 - val_accuracy: 0.8820\n",
      "Epoch 1030/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1699 - accuracy: 0.8842 - val_loss: 0.3334 - val_accuracy: 0.8708\n",
      "Epoch 1031/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1669 - accuracy: 0.8821 - val_loss: 0.3108 - val_accuracy: 0.8812\n",
      "Epoch 1032/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0925 - accuracy: 0.8868 - val_loss: 0.3042 - val_accuracy: 0.8844\n",
      "Epoch 1033/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0939 - accuracy: 0.8864 - val_loss: 0.3079 - val_accuracy: 0.8825\n",
      "Epoch 1034/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1818 - accuracy: 0.8806 - val_loss: 0.3077 - val_accuracy: 0.8828\n",
      "Epoch 1035/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0951 - accuracy: 0.8866 - val_loss: 0.3297 - val_accuracy: 0.8707\n",
      "Epoch 1036/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0976 - accuracy: 0.8851 - val_loss: 0.3015 - val_accuracy: 0.8859\n",
      "Epoch 1037/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1650 - accuracy: 0.8826 - val_loss: 0.3074 - val_accuracy: 0.8841\n",
      "Epoch 1038/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1746 - accuracy: 0.8829 - val_loss: 0.3026 - val_accuracy: 0.8864\n",
      "Epoch 1039/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1223 - accuracy: 0.8854 - val_loss: 0.3249 - val_accuracy: 0.8744\n",
      "Epoch 1040/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0725 - accuracy: 0.8855 - val_loss: 0.3249 - val_accuracy: 0.8759\n",
      "Epoch 1041/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0133 - accuracy: 0.8433 - val_loss: 0.4460 - val_accuracy: 0.8210\n",
      "Epoch 1042/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4998 - accuracy: 0.8698 - val_loss: 0.3579 - val_accuracy: 0.8658\n",
      "Epoch 1043/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2425 - accuracy: 0.8790 - val_loss: 0.3093 - val_accuracy: 0.8829\n",
      "Epoch 1044/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1502 - accuracy: 0.8847 - val_loss: 0.3434 - val_accuracy: 0.8626\n",
      "Epoch 1045/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2403 - accuracy: 0.8788 - val_loss: 0.3681 - val_accuracy: 0.8523\n",
      "Epoch 1046/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7409 - accuracy: 0.8530 - val_loss: 0.3901 - val_accuracy: 0.8410\n",
      "Epoch 1047/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5662 - accuracy: 0.8657 - val_loss: 0.3511 - val_accuracy: 0.8682\n",
      "Epoch 1048/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2960 - accuracy: 0.8781 - val_loss: 0.3167 - val_accuracy: 0.8798\n",
      "Epoch 1049/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1928 - accuracy: 0.8821 - val_loss: 0.3206 - val_accuracy: 0.8749\n",
      "Epoch 1050/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1322 - accuracy: 0.8829 - val_loss: 0.3007 - val_accuracy: 0.8860\n",
      "Epoch 1051/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1528 - accuracy: 0.8834 - val_loss: 0.3062 - val_accuracy: 0.8843\n",
      "Epoch 1052/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0899 - accuracy: 0.8862 - val_loss: 0.3224 - val_accuracy: 0.8757\n",
      "Epoch 1053/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0596 - accuracy: 0.8874 - val_loss: 0.3063 - val_accuracy: 0.8830\n",
      "Epoch 1054/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1093 - accuracy: 0.8847 - val_loss: 0.3257 - val_accuracy: 0.8739\n",
      "Epoch 1055/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1321 - accuracy: 0.8835 - val_loss: 0.3013 - val_accuracy: 0.8863\n",
      "Epoch 1056/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1371 - accuracy: 0.8834 - val_loss: 0.3013 - val_accuracy: 0.8866\n",
      "Epoch 1057/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1751 - accuracy: 0.8825 - val_loss: 0.3175 - val_accuracy: 0.8786\n",
      "Epoch 1058/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2158 - accuracy: 0.8796 - val_loss: 0.3019 - val_accuracy: 0.8871\n",
      "Epoch 1059/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1136 - accuracy: 0.8859 - val_loss: 0.3100 - val_accuracy: 0.8817\n",
      "Epoch 1060/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1167 - accuracy: 0.8847 - val_loss: 0.3370 - val_accuracy: 0.8669\n",
      "Epoch 1061/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2119 - accuracy: 0.8801 - val_loss: 0.3891 - val_accuracy: 0.8407\n",
      "Epoch 1062/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3815 - accuracy: 0.8715 - val_loss: 0.3090 - val_accuracy: 0.8837\n",
      "Epoch 1063/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1617 - accuracy: 0.8830 - val_loss: 0.3091 - val_accuracy: 0.8824\n",
      "Epoch 1064/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.1796 - accuracy: 0.8828 - val_loss: 0.3112 - val_accuracy: 0.8808\n",
      "Epoch 1065/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1296 - accuracy: 0.8842 - val_loss: 0.3855 - val_accuracy: 0.8416\n",
      "Epoch 1066/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4425 - accuracy: 0.8679 - val_loss: 0.3099 - val_accuracy: 0.8840\n",
      "Epoch 1067/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3188 - accuracy: 0.8768 - val_loss: 0.3892 - val_accuracy: 0.8459\n",
      "Epoch 1068/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6346 - accuracy: 0.8593 - val_loss: 0.3330 - val_accuracy: 0.8716\n",
      "Epoch 1069/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4766 - accuracy: 0.8700 - val_loss: 0.3737 - val_accuracy: 0.8532\n",
      "Epoch 1070/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3139 - accuracy: 0.8769 - val_loss: 0.3379 - val_accuracy: 0.8699\n",
      "Epoch 1071/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1251 - accuracy: 0.8842 - val_loss: 0.2993 - val_accuracy: 0.8860\n",
      "Epoch 1072/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0736 - accuracy: 0.8864 - val_loss: 0.2997 - val_accuracy: 0.8860\n",
      "Epoch 1073/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0966 - accuracy: 0.8851 - val_loss: 0.3025 - val_accuracy: 0.8861\n",
      "Epoch 1074/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.2012 - accuracy: 0.8807 - val_loss: 0.3030 - val_accuracy: 0.8864\n",
      "Epoch 1075/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1746 - accuracy: 0.8835 - val_loss: 0.3329 - val_accuracy: 0.8709\n",
      "Epoch 1076/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2234 - accuracy: 0.8795 - val_loss: 0.3143 - val_accuracy: 0.8804\n",
      "Epoch 1077/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 4.3853 - accuracy: 0.8225 - val_loss: 0.3842 - val_accuracy: 0.8583\n",
      "Epoch 1078/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.9800 - accuracy: 0.8486 - val_loss: 0.3652 - val_accuracy: 0.8649\n",
      "Epoch 1079/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4697 - accuracy: 0.8735 - val_loss: 0.3380 - val_accuracy: 0.8699\n",
      "Epoch 1080/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2463 - accuracy: 0.8811 - val_loss: 0.3376 - val_accuracy: 0.8690\n",
      "Epoch 1081/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1692 - accuracy: 0.8830 - val_loss: 0.3096 - val_accuracy: 0.8805\n",
      "Epoch 1082/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1005 - accuracy: 0.8855 - val_loss: 0.3168 - val_accuracy: 0.8771\n",
      "Epoch 1083/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1014 - accuracy: 0.8848 - val_loss: 0.3041 - val_accuracy: 0.8840\n",
      "Epoch 1084/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0866 - accuracy: 0.8863 - val_loss: 0.3538 - val_accuracy: 0.8570\n",
      "Epoch 1085/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1266 - accuracy: 0.8832 - val_loss: 0.3262 - val_accuracy: 0.8726\n",
      "Epoch 1086/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0517 - accuracy: 0.8872 - val_loss: 0.3082 - val_accuracy: 0.8814\n",
      "Epoch 1087/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0994 - accuracy: 0.8844 - val_loss: 0.3261 - val_accuracy: 0.8742\n",
      "Epoch 1088/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2042 - accuracy: 0.8819 - val_loss: 0.3395 - val_accuracy: 0.8665\n",
      "Epoch 1089/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2628 - accuracy: 0.8778 - val_loss: 0.3190 - val_accuracy: 0.8793\n",
      "Epoch 1090/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1841 - accuracy: 0.8817 - val_loss: 0.3288 - val_accuracy: 0.8745\n",
      "Epoch 1091/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1659 - accuracy: 0.8834 - val_loss: 0.3463 - val_accuracy: 0.8642\n",
      "Epoch 1092/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1261 - accuracy: 0.8836 - val_loss: 0.3253 - val_accuracy: 0.8737\n",
      "Epoch 1093/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1304 - accuracy: 0.8833 - val_loss: 0.3077 - val_accuracy: 0.8828\n",
      "Epoch 1094/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0987 - accuracy: 0.8862 - val_loss: 0.3406 - val_accuracy: 0.8661\n",
      "Epoch 1095/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.2451 - accuracy: 0.8778 - val_loss: 0.3223 - val_accuracy: 0.8768\n",
      "Epoch 1096/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1518 - accuracy: 0.8832 - val_loss: 0.3019 - val_accuracy: 0.8862\n",
      "Epoch 1097/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0662 - accuracy: 0.8874 - val_loss: 0.3037 - val_accuracy: 0.8854\n",
      "Epoch 1098/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1424 - accuracy: 0.8834 - val_loss: 0.2996 - val_accuracy: 0.8868\n",
      "Epoch 1099/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0633 - accuracy: 0.8881 - val_loss: 0.3043 - val_accuracy: 0.8847\n",
      "Epoch 1100/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0970 - accuracy: 0.8850 - val_loss: 0.3252 - val_accuracy: 0.8732\n",
      "Epoch 1101/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0630 - accuracy: 0.8868 - val_loss: 0.2965 - val_accuracy: 0.8883\n",
      "Epoch 1102/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1648 - accuracy: 0.8823 - val_loss: 0.3653 - val_accuracy: 0.8559\n",
      "Epoch 1103/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3249 - accuracy: 0.8753 - val_loss: 0.3457 - val_accuracy: 0.8653\n",
      "Epoch 1104/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7234 - accuracy: 0.8548 - val_loss: 0.3263 - val_accuracy: 0.8773\n",
      "Epoch 1105/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3195 - accuracy: 0.8766 - val_loss: 0.3271 - val_accuracy: 0.8765\n",
      "Epoch 1106/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1559 - accuracy: 0.8837 - val_loss: 0.3335 - val_accuracy: 0.8696\n",
      "Epoch 1107/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0986 - accuracy: 0.8859 - val_loss: 0.3258 - val_accuracy: 0.8725\n",
      "Epoch 1108/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0423 - accuracy: 0.8878 - val_loss: 0.3152 - val_accuracy: 0.8791\n",
      "Epoch 1109/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1022 - accuracy: 0.8847 - val_loss: 0.3253 - val_accuracy: 0.8742\n",
      "Epoch 1110/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1624 - accuracy: 0.8829 - val_loss: 0.3472 - val_accuracy: 0.8649\n",
      "Epoch 1111/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0736 - accuracy: 0.8871 - val_loss: 0.3607 - val_accuracy: 0.8555\n",
      "Epoch 1112/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6875 - accuracy: 0.8554 - val_loss: 0.3413 - val_accuracy: 0.8743\n",
      "Epoch 1113/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5492 - accuracy: 0.8660 - val_loss: 0.3135 - val_accuracy: 0.8838\n",
      "Epoch 1114/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2014 - accuracy: 0.8834 - val_loss: 0.3168 - val_accuracy: 0.8787\n",
      "Epoch 1115/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1087 - accuracy: 0.8847 - val_loss: 0.3133 - val_accuracy: 0.8792\n",
      "Epoch 1116/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0552 - accuracy: 0.8881 - val_loss: 0.3247 - val_accuracy: 0.8734\n",
      "Epoch 1117/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0543 - accuracy: 0.8866 - val_loss: 0.3441 - val_accuracy: 0.8635\n",
      "Epoch 1118/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0754 - accuracy: 0.8860 - val_loss: 0.3242 - val_accuracy: 0.8748\n",
      "Epoch 1119/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0334 - accuracy: 0.8878 - val_loss: 0.3323 - val_accuracy: 0.8688\n",
      "Epoch 1120/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1333 - accuracy: 0.8825 - val_loss: 0.2968 - val_accuracy: 0.8881\n",
      "Epoch 1121/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1065 - accuracy: 0.8840 - val_loss: 0.2948 - val_accuracy: 0.8898\n",
      "Epoch 1122/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2935 - accuracy: 0.8770 - val_loss: 0.3234 - val_accuracy: 0.8786\n",
      "Epoch 1123/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0900 - accuracy: 0.8863 - val_loss: 0.3308 - val_accuracy: 0.8695\n",
      "Epoch 1124/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0310 - accuracy: 0.8885 - val_loss: 0.3051 - val_accuracy: 0.8836\n",
      "Epoch 1125/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3395 - accuracy: 0.8734 - val_loss: 0.3187 - val_accuracy: 0.8814\n",
      "Epoch 1126/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5063 - accuracy: 0.8676 - val_loss: 0.3011 - val_accuracy: 0.8892\n",
      "Epoch 1127/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4178 - accuracy: 0.8715 - val_loss: 0.3114 - val_accuracy: 0.8836\n",
      "Epoch 1128/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3305 - accuracy: 0.8766 - val_loss: 0.4536 - val_accuracy: 0.8106\n",
      "Epoch 1129/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2854 - accuracy: 0.8771 - val_loss: 0.3455 - val_accuracy: 0.8660\n",
      "Epoch 1130/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2139 - accuracy: 0.8784 - val_loss: 0.3305 - val_accuracy: 0.8717\n",
      "Epoch 1131/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5590 - accuracy: 0.8640 - val_loss: 0.3291 - val_accuracy: 0.8776\n",
      "Epoch 1132/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3205 - accuracy: 0.8772 - val_loss: 0.3045 - val_accuracy: 0.8849\n",
      "Epoch 1133/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1221 - accuracy: 0.8854 - val_loss: 0.3196 - val_accuracy: 0.8770\n",
      "Epoch 1134/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0446 - accuracy: 0.8876 - val_loss: 0.3013 - val_accuracy: 0.8853\n",
      "Epoch 1135/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1938 - accuracy: 0.8791 - val_loss: 0.3017 - val_accuracy: 0.8866\n",
      "Epoch 1136/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1401 - accuracy: 0.8854 - val_loss: 0.3424 - val_accuracy: 0.8665\n",
      "Epoch 1137/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0384 - accuracy: 0.8879 - val_loss: 0.3120 - val_accuracy: 0.8810\n",
      "Epoch 1138/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0278 - accuracy: 0.8875 - val_loss: 0.3083 - val_accuracy: 0.8824\n",
      "Epoch 1139/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2424 - accuracy: 0.8786 - val_loss: 0.3342 - val_accuracy: 0.8696\n",
      "Epoch 1140/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1394 - accuracy: 0.8825 - val_loss: 0.3248 - val_accuracy: 0.8771\n",
      "Epoch 1141/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0226 - accuracy: 0.8889 - val_loss: 0.2980 - val_accuracy: 0.8865\n",
      "Epoch 1142/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9874 - accuracy: 0.8904 - val_loss: 0.3176 - val_accuracy: 0.8759\n",
      "Epoch 1143/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3325 - accuracy: 0.8732 - val_loss: 0.4509 - val_accuracy: 0.8174\n",
      "Epoch 1144/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.2130 - accuracy: 0.8322 - val_loss: 0.4100 - val_accuracy: 0.8405\n",
      "Epoch 1145/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8050 - accuracy: 0.8533 - val_loss: 0.3596 - val_accuracy: 0.8625\n",
      "Epoch 1146/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4145 - accuracy: 0.8722 - val_loss: 0.3252 - val_accuracy: 0.8766\n",
      "Epoch 1147/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.1488 - accuracy: 0.8844 - val_loss: 0.3072 - val_accuracy: 0.8829\n",
      "Epoch 1148/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1198 - accuracy: 0.8843 - val_loss: 0.3176 - val_accuracy: 0.8778\n",
      "Epoch 1149/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1233 - accuracy: 0.8824 - val_loss: 0.3310 - val_accuracy: 0.8713\n",
      "Epoch 1150/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6250 - accuracy: 0.8596 - val_loss: 0.3412 - val_accuracy: 0.8731\n",
      "Epoch 1151/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3973 - accuracy: 0.8737 - val_loss: 0.3030 - val_accuracy: 0.8876\n",
      "Epoch 1152/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1530 - accuracy: 0.8848 - val_loss: 0.3100 - val_accuracy: 0.8825\n",
      "Epoch 1153/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3481 - accuracy: 0.8741 - val_loss: 0.3088 - val_accuracy: 0.8843\n",
      "Epoch 1154/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3498 - accuracy: 0.8723 - val_loss: 0.3070 - val_accuracy: 0.8858\n",
      "Epoch 1155/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1636 - accuracy: 0.8837 - val_loss: 0.2967 - val_accuracy: 0.8885\n",
      "Epoch 1156/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1371 - accuracy: 0.8849 - val_loss: 0.3108 - val_accuracy: 0.8801\n",
      "Epoch 1157/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7663 - accuracy: 0.8548 - val_loss: 0.4316 - val_accuracy: 0.8213\n",
      "Epoch 1158/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8613 - accuracy: 0.8452 - val_loss: 0.3580 - val_accuracy: 0.8655\n",
      "Epoch 1159/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4149 - accuracy: 0.8743 - val_loss: 0.3490 - val_accuracy: 0.8647\n",
      "Epoch 1160/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2603 - accuracy: 0.8788 - val_loss: 0.3530 - val_accuracy: 0.8599\n",
      "Epoch 1161/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1362 - accuracy: 0.8818 - val_loss: 0.3135 - val_accuracy: 0.8791\n",
      "Epoch 1162/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0915 - accuracy: 0.8853 - val_loss: 0.2967 - val_accuracy: 0.8876\n",
      "Epoch 1163/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0745 - accuracy: 0.8869 - val_loss: 0.3248 - val_accuracy: 0.8730\n",
      "Epoch 1164/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0337 - accuracy: 0.8875 - val_loss: 0.3094 - val_accuracy: 0.8810\n",
      "Epoch 1165/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0073 - accuracy: 0.8894 - val_loss: 0.3170 - val_accuracy: 0.8760\n",
      "Epoch 1166/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0453 - accuracy: 0.8870 - val_loss: 0.3089 - val_accuracy: 0.8817\n",
      "Epoch 1167/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1539 - accuracy: 0.8826 - val_loss: 0.3343 - val_accuracy: 0.8685\n",
      "Epoch 1168/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1051 - accuracy: 0.8830 - val_loss: 0.2974 - val_accuracy: 0.8887\n",
      "Epoch 1169/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1099 - accuracy: 0.8857 - val_loss: 0.3068 - val_accuracy: 0.8837\n",
      "Epoch 1170/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0182 - accuracy: 0.8897 - val_loss: 0.2986 - val_accuracy: 0.8863\n",
      "Epoch 1171/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0249 - accuracy: 0.8880 - val_loss: 0.3154 - val_accuracy: 0.8777\n",
      "Epoch 1172/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0032 - accuracy: 0.8887 - val_loss: 0.3173 - val_accuracy: 0.8771\n",
      "Epoch 1173/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1519 - accuracy: 0.8825 - val_loss: 0.3062 - val_accuracy: 0.8835\n",
      "Epoch 1174/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0628 - accuracy: 0.8871 - val_loss: 0.3121 - val_accuracy: 0.8810\n",
      "Epoch 1175/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1138 - accuracy: 0.8832 - val_loss: 0.2999 - val_accuracy: 0.8877\n",
      "Epoch 1176/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4906 - accuracy: 0.8678 - val_loss: 0.3204 - val_accuracy: 0.8809\n",
      "Epoch 1177/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6062 - accuracy: 0.8609 - val_loss: 0.3237 - val_accuracy: 0.8806\n",
      "Epoch 1178/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2786 - accuracy: 0.8781 - val_loss: 0.2963 - val_accuracy: 0.8890\n",
      "Epoch 1179/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1151 - accuracy: 0.8868 - val_loss: 0.2992 - val_accuracy: 0.8863\n",
      "Epoch 1180/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0193 - accuracy: 0.8894 - val_loss: 0.3000 - val_accuracy: 0.8861\n",
      "Epoch 1181/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0073 - accuracy: 0.8889 - val_loss: 0.2957 - val_accuracy: 0.8874\n",
      "Epoch 1182/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0216 - accuracy: 0.8893 - val_loss: 0.3441 - val_accuracy: 0.8636\n",
      "Epoch 1183/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0675 - accuracy: 0.8860 - val_loss: 0.3522 - val_accuracy: 0.8596\n",
      "Epoch 1184/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0574 - accuracy: 0.8860 - val_loss: 0.3110 - val_accuracy: 0.8810\n",
      "Epoch 1185/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0645 - accuracy: 0.8865 - val_loss: 0.3480 - val_accuracy: 0.8596\n",
      "Epoch 1186/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0623 - accuracy: 0.8862 - val_loss: 0.3080 - val_accuracy: 0.8830\n",
      "Epoch 1187/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0034 - accuracy: 0.8894 - val_loss: 0.2955 - val_accuracy: 0.8879\n",
      "Epoch 1188/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0089 - accuracy: 0.8885 - val_loss: 0.2936 - val_accuracy: 0.8889\n",
      "Epoch 1189/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1260 - accuracy: 0.8841 - val_loss: 0.2942 - val_accuracy: 0.8892\n",
      "Epoch 1190/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1215 - accuracy: 0.8829 - val_loss: 0.3316 - val_accuracy: 0.8712\n",
      "Epoch 1191/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2206 - accuracy: 0.8806 - val_loss: 0.4087 - val_accuracy: 0.8322\n",
      "Epoch 1192/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7487 - accuracy: 0.8540 - val_loss: 0.4573 - val_accuracy: 0.8149\n",
      "Epoch 1193/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3784 - accuracy: 0.8717 - val_loss: 0.3673 - val_accuracy: 0.8558\n",
      "Epoch 1194/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1326 - accuracy: 0.8834 - val_loss: 0.3028 - val_accuracy: 0.8851\n",
      "Epoch 1195/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1615 - accuracy: 0.8829 - val_loss: 0.3209 - val_accuracy: 0.8759\n",
      "Epoch 1196/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6380 - accuracy: 0.8577 - val_loss: 0.3334 - val_accuracy: 0.8732\n",
      "Epoch 1197/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3204 - accuracy: 0.8768 - val_loss: 0.3404 - val_accuracy: 0.8705\n",
      "Epoch 1198/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1035 - accuracy: 0.8845 - val_loss: 0.3042 - val_accuracy: 0.8846\n",
      "Epoch 1199/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0500 - accuracy: 0.8878 - val_loss: 0.3226 - val_accuracy: 0.8730\n",
      "Epoch 1200/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0514 - accuracy: 0.8866 - val_loss: 0.3172 - val_accuracy: 0.8762\n",
      "Epoch 1201/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0060 - accuracy: 0.8883 - val_loss: 0.2904 - val_accuracy: 0.8905\n",
      "Epoch 1202/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1778 - accuracy: 0.8793 - val_loss: 0.3242 - val_accuracy: 0.8755\n",
      "Epoch 1203/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7563 - accuracy: 0.8545 - val_loss: 0.4740 - val_accuracy: 0.8107\n",
      "Epoch 1204/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1102 - accuracy: 0.8377 - val_loss: 0.3664 - val_accuracy: 0.8670\n",
      "Epoch 1205/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4287 - accuracy: 0.8734 - val_loss: 0.3552 - val_accuracy: 0.8606\n",
      "Epoch 1206/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2148 - accuracy: 0.8806 - val_loss: 0.3142 - val_accuracy: 0.8795\n",
      "Epoch 1207/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0701 - accuracy: 0.8868 - val_loss: 0.3141 - val_accuracy: 0.8784\n",
      "Epoch 1208/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0145 - accuracy: 0.8894 - val_loss: 0.3010 - val_accuracy: 0.8849\n",
      "Epoch 1209/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0840 - accuracy: 0.8841 - val_loss: 0.2993 - val_accuracy: 0.8865\n",
      "Epoch 1210/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1529 - accuracy: 0.8834 - val_loss: 0.3137 - val_accuracy: 0.8793\n",
      "Epoch 1211/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1298 - accuracy: 0.8836 - val_loss: 0.4225 - val_accuracy: 0.8232\n",
      "Epoch 1212/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.7019 - accuracy: 0.8570 - val_loss: 0.3982 - val_accuracy: 0.8409\n",
      "Epoch 1213/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3951 - accuracy: 0.8710 - val_loss: 0.3128 - val_accuracy: 0.8833\n",
      "Epoch 1214/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1940 - accuracy: 0.8814 - val_loss: 0.3092 - val_accuracy: 0.8828\n",
      "Epoch 1215/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1613 - accuracy: 0.8818 - val_loss: 0.4173 - val_accuracy: 0.8265\n",
      "Epoch 1216/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4320 - accuracy: 0.8673 - val_loss: 0.3704 - val_accuracy: 0.8523\n",
      "Epoch 1217/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1873 - accuracy: 0.8821 - val_loss: 0.3465 - val_accuracy: 0.8650\n",
      "Epoch 1218/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1429 - accuracy: 0.8832 - val_loss: 0.3023 - val_accuracy: 0.8866\n",
      "Epoch 1219/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1844 - accuracy: 0.8825 - val_loss: 0.2960 - val_accuracy: 0.8887\n",
      "Epoch 1220/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0447 - accuracy: 0.8882 - val_loss: 0.3448 - val_accuracy: 0.8638\n",
      "Epoch 1221/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0667 - accuracy: 0.8854 - val_loss: 0.3042 - val_accuracy: 0.8847\n",
      "Epoch 1222/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3823 - accuracy: 0.8711 - val_loss: 0.3106 - val_accuracy: 0.8842\n",
      "Epoch 1223/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2926 - accuracy: 0.8753 - val_loss: 0.3052 - val_accuracy: 0.8851\n",
      "Epoch 1224/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1092 - accuracy: 0.8867 - val_loss: 0.2998 - val_accuracy: 0.8871\n",
      "Epoch 1225/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1759 - accuracy: 0.8824 - val_loss: 0.4259 - val_accuracy: 0.8216\n",
      "Epoch 1226/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3706 - accuracy: 0.8710 - val_loss: 0.4016 - val_accuracy: 0.8375\n",
      "Epoch 1227/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2011 - accuracy: 0.8801 - val_loss: 0.3308 - val_accuracy: 0.8739\n",
      "Epoch 1228/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0203 - accuracy: 0.8898 - val_loss: 0.3025 - val_accuracy: 0.8843\n",
      "Epoch 1229/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9871 - accuracy: 0.8898 - val_loss: 0.2928 - val_accuracy: 0.8886\n",
      "Epoch 1230/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0787 - accuracy: 0.8845 - val_loss: 0.2920 - val_accuracy: 0.8901\n",
      "Epoch 1231/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0306 - accuracy: 0.8886 - val_loss: 0.3123 - val_accuracy: 0.8800\n",
      "Epoch 1232/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9897 - accuracy: 0.8903 - val_loss: 0.3128 - val_accuracy: 0.8792\n",
      "Epoch 1233/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0625 - accuracy: 0.8854 - val_loss: 0.2996 - val_accuracy: 0.8863\n",
      "Epoch 1234/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1291 - accuracy: 0.8829 - val_loss: 0.3732 - val_accuracy: 0.8502\n",
      "Epoch 1235/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6459 - accuracy: 0.8581 - val_loss: 0.4381 - val_accuracy: 0.8219\n",
      "Epoch 1236/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4112 - accuracy: 0.8719 - val_loss: 0.3721 - val_accuracy: 0.8530\n",
      "Epoch 1237/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1657 - accuracy: 0.8821 - val_loss: 0.3634 - val_accuracy: 0.8574\n",
      "Epoch 1238/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2401 - accuracy: 0.8770 - val_loss: 0.3058 - val_accuracy: 0.8838\n",
      "Epoch 1239/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2712 - accuracy: 0.8773 - val_loss: 0.3055 - val_accuracy: 0.8855\n",
      "Epoch 1240/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1572 - accuracy: 0.8833 - val_loss: 0.2947 - val_accuracy: 0.8892\n",
      "Epoch 1241/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0242 - accuracy: 0.8889 - val_loss: 0.2947 - val_accuracy: 0.8885\n",
      "Epoch 1242/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1222 - accuracy: 0.8840 - val_loss: 0.3797 - val_accuracy: 0.8458\n",
      "Epoch 1243/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4439 - accuracy: 0.8669 - val_loss: 0.4144 - val_accuracy: 0.8297\n",
      "Epoch 1244/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2295 - accuracy: 0.8796 - val_loss: 0.3623 - val_accuracy: 0.8587\n",
      "Epoch 1245/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0556 - accuracy: 0.8871 - val_loss: 0.3460 - val_accuracy: 0.8645\n",
      "Epoch 1246/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2886 - accuracy: 0.8733 - val_loss: 0.3550 - val_accuracy: 0.8631\n",
      "Epoch 1247/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4804 - accuracy: 0.8702 - val_loss: 0.3718 - val_accuracy: 0.8546\n",
      "Epoch 1248/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1826 - accuracy: 0.8821 - val_loss: 0.3535 - val_accuracy: 0.8637\n",
      "Epoch 1249/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0975 - accuracy: 0.8856 - val_loss: 0.3312 - val_accuracy: 0.8695\n",
      "Epoch 1250/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0257 - accuracy: 0.8871 - val_loss: 0.2917 - val_accuracy: 0.8898\n",
      "Epoch 1251/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9967 - accuracy: 0.8905 - val_loss: 0.3163 - val_accuracy: 0.8769\n",
      "Epoch 1252/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9919 - accuracy: 0.8893 - val_loss: 0.2944 - val_accuracy: 0.8885\n",
      "Epoch 1253/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9779 - accuracy: 0.8895 - val_loss: 0.2949 - val_accuracy: 0.8880\n",
      "Epoch 1254/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9928 - accuracy: 0.8889 - val_loss: 0.2961 - val_accuracy: 0.8872\n",
      "Epoch 1255/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 2.9960 - accuracy: 0.8899 - val_loss: 0.2937 - val_accuracy: 0.8888\n",
      "Epoch 1256/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9676 - accuracy: 0.8914 - val_loss: 0.2974 - val_accuracy: 0.8871\n",
      "Epoch 1257/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 2.9416 - accuracy: 0.8917 - val_loss: 0.3122 - val_accuracy: 0.8793\n",
      "Epoch 1258/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0570 - accuracy: 0.8858 - val_loss: 0.3502 - val_accuracy: 0.8591\n",
      "Epoch 1259/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1857 - accuracy: 0.8792 - val_loss: 0.3233 - val_accuracy: 0.8757\n",
      "Epoch 1260/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5373 - accuracy: 0.8634 - val_loss: 0.3478 - val_accuracy: 0.8668\n",
      "Epoch 1261/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3921 - accuracy: 0.8726 - val_loss: 0.3226 - val_accuracy: 0.8788\n",
      "Epoch 1262/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1077 - accuracy: 0.8851 - val_loss: 0.3122 - val_accuracy: 0.8806\n",
      "Epoch 1263/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0136 - accuracy: 0.8898 - val_loss: 0.3113 - val_accuracy: 0.8794\n",
      "Epoch 1264/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9618 - accuracy: 0.8906 - val_loss: 0.3034 - val_accuracy: 0.8835\n",
      "Epoch 1265/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9529 - accuracy: 0.8908 - val_loss: 0.2966 - val_accuracy: 0.8871\n",
      "Epoch 1266/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9826 - accuracy: 0.8904 - val_loss: 0.3174 - val_accuracy: 0.8763\n",
      "Epoch 1267/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0045 - accuracy: 0.8884 - val_loss: 0.2928 - val_accuracy: 0.8889\n",
      "Epoch 1268/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9516 - accuracy: 0.8914 - val_loss: 0.3009 - val_accuracy: 0.8860\n",
      "Epoch 1269/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0696 - accuracy: 0.8851 - val_loss: 0.3057 - val_accuracy: 0.8830\n",
      "Epoch 1270/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2069 - accuracy: 0.8813 - val_loss: 0.3111 - val_accuracy: 0.8821\n",
      "Epoch 1271/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5000 - accuracy: 0.8648 - val_loss: 0.3461 - val_accuracy: 0.8654\n",
      "Epoch 1272/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1805 - accuracy: 0.8815 - val_loss: 0.3684 - val_accuracy: 0.8543\n",
      "Epoch 1273/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1899 - accuracy: 0.8781 - val_loss: 0.3324 - val_accuracy: 0.8707\n",
      "Epoch 1274/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5381 - accuracy: 0.8637 - val_loss: 0.3036 - val_accuracy: 0.8869\n",
      "Epoch 1275/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1892 - accuracy: 0.8842 - val_loss: 0.3514 - val_accuracy: 0.8617\n",
      "Epoch 1276/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1896 - accuracy: 0.8797 - val_loss: 0.3027 - val_accuracy: 0.8852\n",
      "Epoch 1277/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0228 - accuracy: 0.8892 - val_loss: 0.2932 - val_accuracy: 0.8889\n",
      "Epoch 1278/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0025 - accuracy: 0.8902 - val_loss: 0.3107 - val_accuracy: 0.8808\n",
      "Epoch 1279/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9379 - accuracy: 0.8915 - val_loss: 0.2957 - val_accuracy: 0.8880\n",
      "Epoch 1280/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9295 - accuracy: 0.8923 - val_loss: 0.3282 - val_accuracy: 0.8701\n",
      "Epoch 1281/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9741 - accuracy: 0.8888 - val_loss: 0.2907 - val_accuracy: 0.8902\n",
      "Epoch 1282/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.0402 - accuracy: 0.8866 - val_loss: 0.3003 - val_accuracy: 0.8857\n",
      "Epoch 1283/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0017 - accuracy: 0.8889 - val_loss: 0.3220 - val_accuracy: 0.8753\n",
      "Epoch 1284/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0082 - accuracy: 0.8878 - val_loss: 0.2941 - val_accuracy: 0.8883\n",
      "Epoch 1285/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0303 - accuracy: 0.8871 - val_loss: 0.2926 - val_accuracy: 0.8901\n",
      "Epoch 1286/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9806 - accuracy: 0.8905 - val_loss: 0.3115 - val_accuracy: 0.8807\n",
      "Epoch 1287/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0327 - accuracy: 0.8874 - val_loss: 0.3003 - val_accuracy: 0.8861\n",
      "Epoch 1288/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9422 - accuracy: 0.8922 - val_loss: 0.2951 - val_accuracy: 0.8878\n",
      "Epoch 1289/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9836 - accuracy: 0.8881 - val_loss: 0.3602 - val_accuracy: 0.8587\n",
      "Epoch 1290/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4831 - accuracy: 0.8684 - val_loss: 0.5403 - val_accuracy: 0.7741\n",
      "Epoch 1291/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7012 - accuracy: 0.8546 - val_loss: 0.3357 - val_accuracy: 0.8770\n",
      "Epoch 1292/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2372 - accuracy: 0.8795 - val_loss: 0.3189 - val_accuracy: 0.8783\n",
      "Epoch 1293/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0357 - accuracy: 0.8881 - val_loss: 0.3097 - val_accuracy: 0.8808\n",
      "Epoch 1294/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9855 - accuracy: 0.8896 - val_loss: 0.2984 - val_accuracy: 0.8860\n",
      "Epoch 1295/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9741 - accuracy: 0.8892 - val_loss: 0.2864 - val_accuracy: 0.8923\n",
      "Epoch 1296/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9746 - accuracy: 0.8915 - val_loss: 0.3027 - val_accuracy: 0.8830\n",
      "Epoch 1297/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9434 - accuracy: 0.8912 - val_loss: 0.2944 - val_accuracy: 0.8876\n",
      "Epoch 1298/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9219 - accuracy: 0.8918 - val_loss: 0.3044 - val_accuracy: 0.8848\n",
      "Epoch 1299/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7577 - accuracy: 0.8550 - val_loss: 0.4088 - val_accuracy: 0.8328\n",
      "Epoch 1300/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5927 - accuracy: 0.8607 - val_loss: 0.3338 - val_accuracy: 0.8742\n",
      "Epoch 1301/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3330 - accuracy: 0.8736 - val_loss: 0.3670 - val_accuracy: 0.8550\n",
      "Epoch 1302/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0902 - accuracy: 0.8853 - val_loss: 0.3064 - val_accuracy: 0.8832\n",
      "Epoch 1303/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9755 - accuracy: 0.8910 - val_loss: 0.3027 - val_accuracy: 0.8833\n",
      "Epoch 1304/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9633 - accuracy: 0.8912 - val_loss: 0.3250 - val_accuracy: 0.8707\n",
      "Epoch 1305/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9525 - accuracy: 0.8902 - val_loss: 0.2990 - val_accuracy: 0.8856\n",
      "Epoch 1306/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0772 - accuracy: 0.8841 - val_loss: 0.2931 - val_accuracy: 0.8898\n",
      "Epoch 1307/3000\n",
      "10/10 [==============================] - 1s 80ms/step - loss: 3.0526 - accuracy: 0.8867 - val_loss: 0.3123 - val_accuracy: 0.8795\n",
      "Epoch 1308/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 3.1372 - accuracy: 0.8824 - val_loss: 0.3213 - val_accuracy: 0.8761\n",
      "Epoch 1309/3000\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 3.0497 - accuracy: 0.8860 - val_loss: 0.2879 - val_accuracy: 0.8922\n",
      "Epoch 1310/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 3.0212 - accuracy: 0.8885 - val_loss: 0.2931 - val_accuracy: 0.8895\n",
      "Epoch 1311/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9587 - accuracy: 0.8921 - val_loss: 0.3088 - val_accuracy: 0.8812\n",
      "Epoch 1312/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9643 - accuracy: 0.8896 - val_loss: 0.3161 - val_accuracy: 0.8776\n",
      "Epoch 1313/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0409 - accuracy: 0.8861 - val_loss: 0.2884 - val_accuracy: 0.8917\n",
      "Epoch 1314/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9989 - accuracy: 0.8904 - val_loss: 0.2909 - val_accuracy: 0.8898\n",
      "Epoch 1315/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0217 - accuracy: 0.8879 - val_loss: 0.2900 - val_accuracy: 0.8915\n",
      "Epoch 1316/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0577 - accuracy: 0.8872 - val_loss: 0.3429 - val_accuracy: 0.8662\n",
      "Epoch 1317/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0827 - accuracy: 0.8850 - val_loss: 0.3086 - val_accuracy: 0.8834\n",
      "Epoch 1318/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9823 - accuracy: 0.8895 - val_loss: 0.3090 - val_accuracy: 0.8820\n",
      "Epoch 1319/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9540 - accuracy: 0.8904 - val_loss: 0.3172 - val_accuracy: 0.8764\n",
      "Epoch 1320/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9652 - accuracy: 0.8893 - val_loss: 0.2872 - val_accuracy: 0.8919\n",
      "Epoch 1321/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9534 - accuracy: 0.8907 - val_loss: 0.2905 - val_accuracy: 0.8902\n",
      "Epoch 1322/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0404 - accuracy: 0.8869 - val_loss: 0.3006 - val_accuracy: 0.8868\n",
      "Epoch 1323/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9860 - accuracy: 0.8903 - val_loss: 0.3007 - val_accuracy: 0.8864\n",
      "Epoch 1324/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1775 - accuracy: 0.8801 - val_loss: 0.2923 - val_accuracy: 0.8901\n",
      "Epoch 1325/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.4853 - accuracy: 0.8650 - val_loss: 0.3156 - val_accuracy: 0.8833\n",
      "Epoch 1326/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3463 - accuracy: 0.8739 - val_loss: 0.3030 - val_accuracy: 0.8872\n",
      "Epoch 1327/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2573 - accuracy: 0.8765 - val_loss: 0.3018 - val_accuracy: 0.8877\n",
      "Epoch 1328/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1225 - accuracy: 0.8840 - val_loss: 0.3248 - val_accuracy: 0.8760\n",
      "Epoch 1329/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0199 - accuracy: 0.8865 - val_loss: 0.3076 - val_accuracy: 0.8828\n",
      "Epoch 1330/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5324 - accuracy: 0.8627 - val_loss: 0.3530 - val_accuracy: 0.8693\n",
      "Epoch 1331/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3973 - accuracy: 0.8710 - val_loss: 0.3106 - val_accuracy: 0.8843\n",
      "Epoch 1332/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0923 - accuracy: 0.8866 - val_loss: 0.3113 - val_accuracy: 0.8810\n",
      "Epoch 1333/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9906 - accuracy: 0.8898 - val_loss: 0.2863 - val_accuracy: 0.8918\n",
      "Epoch 1334/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0559 - accuracy: 0.8843 - val_loss: 0.2903 - val_accuracy: 0.8911\n",
      "Epoch 1335/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9790 - accuracy: 0.8913 - val_loss: 0.2875 - val_accuracy: 0.8920\n",
      "Epoch 1336/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9221 - accuracy: 0.8932 - val_loss: 0.2870 - val_accuracy: 0.8913\n",
      "Epoch 1337/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 2.9159 - accuracy: 0.8931 - val_loss: 0.3014 - val_accuracy: 0.8837\n",
      "Epoch 1338/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1544 - accuracy: 0.8806 - val_loss: 0.2895 - val_accuracy: 0.8913\n",
      "Epoch 1339/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0185 - accuracy: 0.8888 - val_loss: 0.2926 - val_accuracy: 0.8904\n",
      "Epoch 1340/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9192 - accuracy: 0.8936 - val_loss: 0.2909 - val_accuracy: 0.8896\n",
      "Epoch 1341/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9252 - accuracy: 0.8923 - val_loss: 0.3533 - val_accuracy: 0.8578\n",
      "Epoch 1342/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0665 - accuracy: 0.8849 - val_loss: 0.3283 - val_accuracy: 0.8719\n",
      "Epoch 1343/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.0116 - accuracy: 0.8875 - val_loss: 0.3046 - val_accuracy: 0.8839\n",
      "Epoch 1344/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3821 - accuracy: 0.8700 - val_loss: 0.6188 - val_accuracy: 0.7577\n",
      "Epoch 1345/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1550 - accuracy: 0.8349 - val_loss: 0.3326 - val_accuracy: 0.8797\n",
      "Epoch 1346/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3997 - accuracy: 0.8742 - val_loss: 0.3414 - val_accuracy: 0.8674\n",
      "Epoch 1347/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1212 - accuracy: 0.8867 - val_loss: 0.2997 - val_accuracy: 0.8872\n",
      "Epoch 1348/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1020 - accuracy: 0.8830 - val_loss: 0.3039 - val_accuracy: 0.8846\n",
      "Epoch 1349/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8088 - accuracy: 0.8497 - val_loss: 0.3313 - val_accuracy: 0.8784\n",
      "Epoch 1350/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5299 - accuracy: 0.8727 - val_loss: 0.4047 - val_accuracy: 0.8364\n",
      "Epoch 1351/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3116 - accuracy: 0.8744 - val_loss: 0.2935 - val_accuracy: 0.8903\n",
      "Epoch 1352/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2259 - accuracy: 0.8789 - val_loss: 0.2969 - val_accuracy: 0.8881\n",
      "Epoch 1353/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0601 - accuracy: 0.8865 - val_loss: 0.3243 - val_accuracy: 0.8733\n",
      "Epoch 1354/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0028 - accuracy: 0.8889 - val_loss: 0.2889 - val_accuracy: 0.8907\n",
      "Epoch 1355/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9976 - accuracy: 0.8890 - val_loss: 0.3000 - val_accuracy: 0.8851\n",
      "Epoch 1356/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9702 - accuracy: 0.8908 - val_loss: 0.3305 - val_accuracy: 0.8705\n",
      "Epoch 1357/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9988 - accuracy: 0.8882 - val_loss: 0.3355 - val_accuracy: 0.8684\n",
      "Epoch 1358/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9684 - accuracy: 0.8896 - val_loss: 0.3151 - val_accuracy: 0.8767\n",
      "Epoch 1359/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0414 - accuracy: 0.8856 - val_loss: 0.3193 - val_accuracy: 0.8760\n",
      "Epoch 1360/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7091 - accuracy: 0.8551 - val_loss: 0.5195 - val_accuracy: 0.7892\n",
      "Epoch 1361/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7711 - accuracy: 0.8525 - val_loss: 0.3329 - val_accuracy: 0.8767\n",
      "Epoch 1362/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.2979 - accuracy: 0.8767 - val_loss: 0.3013 - val_accuracy: 0.8886\n",
      "Epoch 1363/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1351 - accuracy: 0.8877 - val_loss: 0.3267 - val_accuracy: 0.8720\n",
      "Epoch 1364/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0311 - accuracy: 0.8858 - val_loss: 0.2866 - val_accuracy: 0.8915\n",
      "Epoch 1365/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9827 - accuracy: 0.8900 - val_loss: 0.3162 - val_accuracy: 0.8759\n",
      "Epoch 1366/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0174 - accuracy: 0.8881 - val_loss: 0.3274 - val_accuracy: 0.8706\n",
      "Epoch 1367/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9429 - accuracy: 0.8906 - val_loss: 0.3069 - val_accuracy: 0.8821\n",
      "Epoch 1368/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8979 - accuracy: 0.8933 - val_loss: 0.3036 - val_accuracy: 0.8831\n",
      "Epoch 1369/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9902 - accuracy: 0.8874 - val_loss: 0.2872 - val_accuracy: 0.8913\n",
      "Epoch 1370/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0332 - accuracy: 0.8863 - val_loss: 0.2955 - val_accuracy: 0.8884\n",
      "Epoch 1371/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9955 - accuracy: 0.8898 - val_loss: 0.3076 - val_accuracy: 0.8818\n",
      "Epoch 1372/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2758 - accuracy: 0.8751 - val_loss: 0.2946 - val_accuracy: 0.8908\n",
      "Epoch 1373/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0362 - accuracy: 0.8369 - val_loss: 0.3307 - val_accuracy: 0.8738\n",
      "Epoch 1374/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4740 - accuracy: 0.8730 - val_loss: 0.4008 - val_accuracy: 0.8388\n",
      "Epoch 1375/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.1768 - accuracy: 0.8811 - val_loss: 0.2962 - val_accuracy: 0.8895\n",
      "Epoch 1376/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.0282 - accuracy: 0.8879 - val_loss: 0.2936 - val_accuracy: 0.8877\n",
      "Epoch 1377/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9824 - accuracy: 0.8895 - val_loss: 0.2902 - val_accuracy: 0.8893\n",
      "Epoch 1378/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9362 - accuracy: 0.8921 - val_loss: 0.2950 - val_accuracy: 0.8870\n",
      "Epoch 1379/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9254 - accuracy: 0.8925 - val_loss: 0.3231 - val_accuracy: 0.8731\n",
      "Epoch 1380/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9998 - accuracy: 0.8879 - val_loss: 0.3168 - val_accuracy: 0.8770\n",
      "Epoch 1381/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9790 - accuracy: 0.8895 - val_loss: 0.3181 - val_accuracy: 0.8763\n",
      "Epoch 1382/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9509 - accuracy: 0.8910 - val_loss: 0.2929 - val_accuracy: 0.8896\n",
      "Epoch 1383/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9194 - accuracy: 0.8930 - val_loss: 0.3125 - val_accuracy: 0.8785\n",
      "Epoch 1384/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8785 - accuracy: 0.8938 - val_loss: 0.2941 - val_accuracy: 0.8881\n",
      "Epoch 1385/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0224 - accuracy: 0.8877 - val_loss: 0.3267 - val_accuracy: 0.8713\n",
      "Epoch 1386/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0124 - accuracy: 0.8873 - val_loss: 0.3310 - val_accuracy: 0.8689\n",
      "Epoch 1387/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1080 - accuracy: 0.8824 - val_loss: 0.3166 - val_accuracy: 0.8796\n",
      "Epoch 1388/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0314 - accuracy: 0.8865 - val_loss: 0.3037 - val_accuracy: 0.8843\n",
      "Epoch 1389/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5734 - accuracy: 0.8626 - val_loss: 0.4152 - val_accuracy: 0.8396\n",
      "Epoch 1390/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9940 - accuracy: 0.8445 - val_loss: 0.4595 - val_accuracy: 0.8141\n",
      "Epoch 1391/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4492 - accuracy: 0.8657 - val_loss: 0.3046 - val_accuracy: 0.8853\n",
      "Epoch 1392/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1451 - accuracy: 0.8852 - val_loss: 0.3005 - val_accuracy: 0.8858\n",
      "Epoch 1393/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9787 - accuracy: 0.8905 - val_loss: 0.3178 - val_accuracy: 0.8773\n",
      "Epoch 1394/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9646 - accuracy: 0.8892 - val_loss: 0.2876 - val_accuracy: 0.8902\n",
      "Epoch 1395/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9207 - accuracy: 0.8919 - val_loss: 0.2967 - val_accuracy: 0.8868\n",
      "Epoch 1396/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9404 - accuracy: 0.8911 - val_loss: 0.2988 - val_accuracy: 0.8861\n",
      "Epoch 1397/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.0410 - accuracy: 0.8856 - val_loss: 0.2893 - val_accuracy: 0.8906\n",
      "Epoch 1398/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9983 - accuracy: 0.8896 - val_loss: 0.3181 - val_accuracy: 0.8759\n",
      "Epoch 1399/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9381 - accuracy: 0.8911 - val_loss: 0.2872 - val_accuracy: 0.8914\n",
      "Epoch 1400/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8929 - accuracy: 0.8941 - val_loss: 0.3526 - val_accuracy: 0.8592\n",
      "Epoch 1401/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1956 - accuracy: 0.8784 - val_loss: 0.3115 - val_accuracy: 0.8809\n",
      "Epoch 1402/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7429 - accuracy: 0.8508 - val_loss: 0.3490 - val_accuracy: 0.8712\n",
      "Epoch 1403/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.4681 - accuracy: 0.8690 - val_loss: 0.3357 - val_accuracy: 0.8735\n",
      "Epoch 1404/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1488 - accuracy: 0.8846 - val_loss: 0.3364 - val_accuracy: 0.8689\n",
      "Epoch 1405/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0635 - accuracy: 0.8861 - val_loss: 0.3205 - val_accuracy: 0.8753\n",
      "Epoch 1406/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6109 - accuracy: 0.8575 - val_loss: 0.3648 - val_accuracy: 0.8635\n",
      "Epoch 1407/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4521 - accuracy: 0.8709 - val_loss: 0.3298 - val_accuracy: 0.8750\n",
      "Epoch 1408/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0755 - accuracy: 0.8878 - val_loss: 0.3043 - val_accuracy: 0.8829\n",
      "Epoch 1409/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9580 - accuracy: 0.8904 - val_loss: 0.2847 - val_accuracy: 0.8924\n",
      "Epoch 1410/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9279 - accuracy: 0.8914 - val_loss: 0.2868 - val_accuracy: 0.8908\n",
      "Epoch 1411/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9702 - accuracy: 0.8897 - val_loss: 0.2911 - val_accuracy: 0.8888\n",
      "Epoch 1412/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.8915 - accuracy: 0.8937 - val_loss: 0.2899 - val_accuracy: 0.8895\n",
      "Epoch 1413/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9097 - accuracy: 0.8920 - val_loss: 0.2905 - val_accuracy: 0.8898\n",
      "Epoch 1414/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0041 - accuracy: 0.8880 - val_loss: 0.2942 - val_accuracy: 0.8878\n",
      "Epoch 1415/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9389 - accuracy: 0.8915 - val_loss: 0.3263 - val_accuracy: 0.8721\n",
      "Epoch 1416/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1196 - accuracy: 0.8826 - val_loss: 0.2994 - val_accuracy: 0.8862\n",
      "Epoch 1417/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.0831 - accuracy: 0.8332 - val_loss: 0.3715 - val_accuracy: 0.8556\n",
      "Epoch 1418/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.4517 - accuracy: 0.8725 - val_loss: 0.3343 - val_accuracy: 0.8718\n",
      "Epoch 1419/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1349 - accuracy: 0.8841 - val_loss: 0.2909 - val_accuracy: 0.8919\n",
      "Epoch 1420/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0106 - accuracy: 0.8904 - val_loss: 0.2965 - val_accuracy: 0.8862\n",
      "Epoch 1421/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0099 - accuracy: 0.8874 - val_loss: 0.3027 - val_accuracy: 0.8825\n",
      "Epoch 1422/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9205 - accuracy: 0.8925 - val_loss: 0.2997 - val_accuracy: 0.8848\n",
      "Epoch 1423/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9389 - accuracy: 0.8912 - val_loss: 0.3150 - val_accuracy: 0.8763\n",
      "Epoch 1424/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8982 - accuracy: 0.8923 - val_loss: 0.2879 - val_accuracy: 0.8906\n",
      "Epoch 1425/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9244 - accuracy: 0.8914 - val_loss: 0.2849 - val_accuracy: 0.8921\n",
      "Epoch 1426/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2283 - accuracy: 0.8755 - val_loss: 0.3518 - val_accuracy: 0.8629\n",
      "Epoch 1427/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4398 - accuracy: 0.8699 - val_loss: 0.3035 - val_accuracy: 0.8864\n",
      "Epoch 1428/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0810 - accuracy: 0.8864 - val_loss: 0.2914 - val_accuracy: 0.8906\n",
      "Epoch 1429/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9874 - accuracy: 0.8911 - val_loss: 0.2972 - val_accuracy: 0.8865\n",
      "Epoch 1430/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4992 - accuracy: 0.8652 - val_loss: 0.4695 - val_accuracy: 0.8070\n",
      "Epoch 1431/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5188 - accuracy: 0.8626 - val_loss: 0.3535 - val_accuracy: 0.8638\n",
      "Epoch 1432/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1789 - accuracy: 0.8807 - val_loss: 0.2952 - val_accuracy: 0.8903\n",
      "Epoch 1433/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0508 - accuracy: 0.8885 - val_loss: 0.3166 - val_accuracy: 0.8761\n",
      "Epoch 1434/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9850 - accuracy: 0.8884 - val_loss: 0.2973 - val_accuracy: 0.8854\n",
      "Epoch 1435/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.9265 - accuracy: 0.8920 - val_loss: 0.3168 - val_accuracy: 0.8762\n",
      "Epoch 1436/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9476 - accuracy: 0.8901 - val_loss: 0.3063 - val_accuracy: 0.8808\n",
      "Epoch 1437/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.8949 - accuracy: 0.8926 - val_loss: 0.2932 - val_accuracy: 0.8891\n",
      "Epoch 1438/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.8583 - accuracy: 0.8943 - val_loss: 0.2831 - val_accuracy: 0.8929\n",
      "Epoch 1439/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9448 - accuracy: 0.8906 - val_loss: 0.2875 - val_accuracy: 0.8919\n",
      "Epoch 1440/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8868 - accuracy: 0.8932 - val_loss: 0.3089 - val_accuracy: 0.8800\n",
      "Epoch 1441/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9087 - accuracy: 0.8920 - val_loss: 0.3372 - val_accuracy: 0.8665\n",
      "Epoch 1442/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9232 - accuracy: 0.8905 - val_loss: 0.2811 - val_accuracy: 0.8942\n",
      "Epoch 1443/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0247 - accuracy: 0.8868 - val_loss: 0.2869 - val_accuracy: 0.8922\n",
      "Epoch 1444/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.9702 - accuracy: 0.8903 - val_loss: 0.2907 - val_accuracy: 0.8901\n",
      "Epoch 1445/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0053 - accuracy: 0.8885 - val_loss: 0.4002 - val_accuracy: 0.8358\n",
      "Epoch 1446/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.2414 - accuracy: 0.8285 - val_loss: 0.3563 - val_accuracy: 0.8660\n",
      "Epoch 1447/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5337 - accuracy: 0.8686 - val_loss: 0.3221 - val_accuracy: 0.8814\n",
      "Epoch 1448/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1648 - accuracy: 0.8838 - val_loss: 0.3099 - val_accuracy: 0.8832\n",
      "Epoch 1449/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0651 - accuracy: 0.8890 - val_loss: 0.3206 - val_accuracy: 0.8743\n",
      "Epoch 1450/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9846 - accuracy: 0.8890 - val_loss: 0.3255 - val_accuracy: 0.8705\n",
      "Epoch 1451/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9376 - accuracy: 0.8908 - val_loss: 0.2933 - val_accuracy: 0.8877\n",
      "Epoch 1452/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9096 - accuracy: 0.8929 - val_loss: 0.3120 - val_accuracy: 0.8777\n",
      "Epoch 1453/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8766 - accuracy: 0.8934 - val_loss: 0.2943 - val_accuracy: 0.8865\n",
      "Epoch 1454/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8915 - accuracy: 0.8930 - val_loss: 0.2830 - val_accuracy: 0.8931\n",
      "Epoch 1455/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9957 - accuracy: 0.8878 - val_loss: 0.2954 - val_accuracy: 0.8872\n",
      "Epoch 1456/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9198 - accuracy: 0.8917 - val_loss: 0.2842 - val_accuracy: 0.8927\n",
      "Epoch 1457/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.8917 - accuracy: 0.8937 - val_loss: 0.2953 - val_accuracy: 0.8878\n",
      "Epoch 1458/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.8562 - accuracy: 0.8944 - val_loss: 0.2912 - val_accuracy: 0.8884\n",
      "Epoch 1459/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0329 - accuracy: 0.8836 - val_loss: 0.3535 - val_accuracy: 0.8620\n",
      "Epoch 1460/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3384 - accuracy: 0.8253 - val_loss: 0.3751 - val_accuracy: 0.8550\n",
      "Epoch 1461/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5300 - accuracy: 0.8715 - val_loss: 0.3278 - val_accuracy: 0.8764\n",
      "Epoch 1462/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1641 - accuracy: 0.8819 - val_loss: 0.2905 - val_accuracy: 0.8920\n",
      "Epoch 1463/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0176 - accuracy: 0.8905 - val_loss: 0.3231 - val_accuracy: 0.8737\n",
      "Epoch 1464/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0202 - accuracy: 0.8865 - val_loss: 0.2879 - val_accuracy: 0.8908\n",
      "Epoch 1465/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0177 - accuracy: 0.8890 - val_loss: 0.3197 - val_accuracy: 0.8756\n",
      "Epoch 1466/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9199 - accuracy: 0.8913 - val_loss: 0.2845 - val_accuracy: 0.8929\n",
      "Epoch 1467/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8860 - accuracy: 0.8939 - val_loss: 0.2886 - val_accuracy: 0.8899\n",
      "Epoch 1468/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.8709 - accuracy: 0.8938 - val_loss: 0.2859 - val_accuracy: 0.8908\n",
      "Epoch 1469/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9736 - accuracy: 0.8891 - val_loss: 0.3279 - val_accuracy: 0.8704\n",
      "Epoch 1470/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6200 - accuracy: 0.8570 - val_loss: 0.4849 - val_accuracy: 0.8072\n",
      "Epoch 1471/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7490 - accuracy: 0.8560 - val_loss: 0.3527 - val_accuracy: 0.8642\n",
      "Epoch 1472/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2655 - accuracy: 0.8773 - val_loss: 0.3346 - val_accuracy: 0.8729\n",
      "Epoch 1473/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0362 - accuracy: 0.8898 - val_loss: 0.2981 - val_accuracy: 0.8867\n",
      "Epoch 1474/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9905 - accuracy: 0.8888 - val_loss: 0.2845 - val_accuracy: 0.8918\n",
      "Epoch 1475/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9862 - accuracy: 0.8895 - val_loss: 0.3192 - val_accuracy: 0.8742\n",
      "Epoch 1476/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1893 - accuracy: 0.8764 - val_loss: 0.3756 - val_accuracy: 0.8505\n",
      "Epoch 1477/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7507 - accuracy: 0.8588 - val_loss: 0.4191 - val_accuracy: 0.8298\n",
      "Epoch 1478/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2388 - accuracy: 0.8776 - val_loss: 0.2977 - val_accuracy: 0.8881\n",
      "Epoch 1479/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.0315 - accuracy: 0.8882 - val_loss: 0.2993 - val_accuracy: 0.8861\n",
      "Epoch 1480/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9146 - accuracy: 0.8932 - val_loss: 0.3108 - val_accuracy: 0.8783\n",
      "Epoch 1481/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9713 - accuracy: 0.8891 - val_loss: 0.3379 - val_accuracy: 0.8666\n",
      "Epoch 1482/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0134 - accuracy: 0.8859 - val_loss: 0.2879 - val_accuracy: 0.8913\n",
      "Epoch 1483/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2363 - accuracy: 0.8766 - val_loss: 0.2951 - val_accuracy: 0.8894\n",
      "Epoch 1484/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5603 - accuracy: 0.8621 - val_loss: 0.3272 - val_accuracy: 0.8780\n",
      "Epoch 1485/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3140 - accuracy: 0.8772 - val_loss: 0.3854 - val_accuracy: 0.8492\n",
      "Epoch 1486/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1078 - accuracy: 0.8842 - val_loss: 0.3600 - val_accuracy: 0.8561\n",
      "Epoch 1487/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0043 - accuracy: 0.8873 - val_loss: 0.2860 - val_accuracy: 0.8920\n",
      "Epoch 1488/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2844 - accuracy: 0.8737 - val_loss: 0.3412 - val_accuracy: 0.8680\n",
      "Epoch 1489/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5055 - accuracy: 0.8644 - val_loss: 0.2997 - val_accuracy: 0.8900\n",
      "Epoch 1490/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0887 - accuracy: 0.8869 - val_loss: 0.3199 - val_accuracy: 0.8779\n",
      "Epoch 1491/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9394 - accuracy: 0.8923 - val_loss: 0.2893 - val_accuracy: 0.8898\n",
      "Epoch 1492/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9061 - accuracy: 0.8926 - val_loss: 0.2977 - val_accuracy: 0.8865\n",
      "Epoch 1493/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0621 - accuracy: 0.8840 - val_loss: 0.2868 - val_accuracy: 0.8916\n",
      "Epoch 1494/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6220 - accuracy: 0.8555 - val_loss: 0.3199 - val_accuracy: 0.8794\n",
      "Epoch 1495/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2510 - accuracy: 0.8813 - val_loss: 0.3122 - val_accuracy: 0.8821\n",
      "Epoch 1496/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0159 - accuracy: 0.8875 - val_loss: 0.2872 - val_accuracy: 0.8913\n",
      "Epoch 1497/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4019 - accuracy: 0.8684 - val_loss: 0.3427 - val_accuracy: 0.8681\n",
      "Epoch 1498/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4581 - accuracy: 0.8679 - val_loss: 0.4547 - val_accuracy: 0.8150\n",
      "Epoch 1499/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.3505 - accuracy: 0.8703 - val_loss: 0.3075 - val_accuracy: 0.8836\n",
      "Epoch 1500/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1656 - accuracy: 0.8817 - val_loss: 0.3075 - val_accuracy: 0.8823\n",
      "Epoch 1501/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9963 - accuracy: 0.8894 - val_loss: 0.2876 - val_accuracy: 0.8913\n",
      "Epoch 1502/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9257 - accuracy: 0.8912 - val_loss: 0.2944 - val_accuracy: 0.8873\n",
      "Epoch 1503/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8666 - accuracy: 0.8940 - val_loss: 0.3064 - val_accuracy: 0.8805\n",
      "Epoch 1504/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.8667 - accuracy: 0.8938 - val_loss: 0.3009 - val_accuracy: 0.8835\n",
      "Epoch 1505/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8526 - accuracy: 0.8941 - val_loss: 0.3031 - val_accuracy: 0.8827\n",
      "Epoch 1506/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8376 - accuracy: 0.8943 - val_loss: 0.2856 - val_accuracy: 0.8914\n",
      "Epoch 1507/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.8823 - accuracy: 0.8935 - val_loss: 0.3200 - val_accuracy: 0.8732\n",
      "Epoch 1508/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.9006 - accuracy: 0.8911 - val_loss: 0.3008 - val_accuracy: 0.8841\n",
      "Epoch 1509/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3949 - accuracy: 0.8696 - val_loss: 0.4544 - val_accuracy: 0.8140\n",
      "Epoch 1510/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5425 - accuracy: 0.8612 - val_loss: 0.3568 - val_accuracy: 0.8631\n",
      "Epoch 1511/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3646 - accuracy: 0.8713 - val_loss: 0.3196 - val_accuracy: 0.8810\n",
      "Epoch 1512/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0565 - accuracy: 0.8884 - val_loss: 0.3108 - val_accuracy: 0.8800\n",
      "Epoch 1513/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9203 - accuracy: 0.8922 - val_loss: 0.2822 - val_accuracy: 0.8938\n",
      "Epoch 1514/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9157 - accuracy: 0.8920 - val_loss: 0.2970 - val_accuracy: 0.8856\n",
      "Epoch 1515/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8488 - accuracy: 0.8957 - val_loss: 0.3201 - val_accuracy: 0.8727\n",
      "Epoch 1516/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0321 - accuracy: 0.8861 - val_loss: 0.3023 - val_accuracy: 0.8827\n",
      "Epoch 1517/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8269 - accuracy: 0.8456 - val_loss: 0.3437 - val_accuracy: 0.8704\n",
      "Epoch 1518/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4116 - accuracy: 0.8726 - val_loss: 0.3088 - val_accuracy: 0.8843\n",
      "Epoch 1519/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1841 - accuracy: 0.8802 - val_loss: 0.2866 - val_accuracy: 0.8936\n",
      "Epoch 1520/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9667 - accuracy: 0.8929 - val_loss: 0.3037 - val_accuracy: 0.8817\n",
      "Epoch 1521/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8823 - accuracy: 0.8927 - val_loss: 0.2869 - val_accuracy: 0.8909\n",
      "Epoch 1522/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.8721 - accuracy: 0.8935 - val_loss: 0.2842 - val_accuracy: 0.8918\n",
      "Epoch 1523/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8940 - accuracy: 0.8917 - val_loss: 0.2846 - val_accuracy: 0.8919\n",
      "Epoch 1524/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9565 - accuracy: 0.8904 - val_loss: 0.3054 - val_accuracy: 0.8818\n",
      "Epoch 1525/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9249 - accuracy: 0.8902 - val_loss: 0.2810 - val_accuracy: 0.8941\n",
      "Epoch 1526/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8410 - accuracy: 0.8953 - val_loss: 0.3001 - val_accuracy: 0.8845\n",
      "Epoch 1527/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.8273 - accuracy: 0.8958 - val_loss: 0.3081 - val_accuracy: 0.8796\n",
      "Epoch 1528/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3168 - accuracy: 0.8708 - val_loss: 0.3265 - val_accuracy: 0.8782\n",
      "Epoch 1529/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4092 - accuracy: 0.8694 - val_loss: 0.3102 - val_accuracy: 0.8828\n",
      "Epoch 1530/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9703 - accuracy: 0.8908 - val_loss: 0.3073 - val_accuracy: 0.8830\n",
      "Epoch 1531/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8868 - accuracy: 0.8949 - val_loss: 0.2948 - val_accuracy: 0.8867\n",
      "Epoch 1532/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8842 - accuracy: 0.8914 - val_loss: 0.2942 - val_accuracy: 0.8874\n",
      "Epoch 1533/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6335 - accuracy: 0.8553 - val_loss: 0.3916 - val_accuracy: 0.8574\n",
      "Epoch 1534/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5646 - accuracy: 0.8652 - val_loss: 0.3290 - val_accuracy: 0.8770\n",
      "Epoch 1535/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1158 - accuracy: 0.8863 - val_loss: 0.3185 - val_accuracy: 0.8792\n",
      "Epoch 1536/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0167 - accuracy: 0.8872 - val_loss: 0.2956 - val_accuracy: 0.8880\n",
      "Epoch 1537/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9735 - accuracy: 0.8907 - val_loss: 0.3178 - val_accuracy: 0.8758\n",
      "Epoch 1538/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3504 - accuracy: 0.8685 - val_loss: 0.3564 - val_accuracy: 0.8604\n",
      "Epoch 1539/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8031 - accuracy: 0.8537 - val_loss: 0.3213 - val_accuracy: 0.8817\n",
      "Epoch 1540/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2195 - accuracy: 0.8825 - val_loss: 0.3062 - val_accuracy: 0.8854\n",
      "Epoch 1541/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0138 - accuracy: 0.8890 - val_loss: 0.2995 - val_accuracy: 0.8867\n",
      "Epoch 1542/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9119 - accuracy: 0.8941 - val_loss: 0.3014 - val_accuracy: 0.8832\n",
      "Epoch 1543/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8743 - accuracy: 0.8936 - val_loss: 0.2899 - val_accuracy: 0.8888\n",
      "Epoch 1544/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9132 - accuracy: 0.8923 - val_loss: 0.3262 - val_accuracy: 0.8693\n",
      "Epoch 1545/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9633 - accuracy: 0.8880 - val_loss: 0.2911 - val_accuracy: 0.8897\n",
      "Epoch 1546/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9511 - accuracy: 0.8903 - val_loss: 0.3194 - val_accuracy: 0.8752\n",
      "Epoch 1547/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1310 - accuracy: 0.8788 - val_loss: 0.3744 - val_accuracy: 0.8512\n",
      "Epoch 1548/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5884 - accuracy: 0.8653 - val_loss: 0.4502 - val_accuracy: 0.8189\n",
      "Epoch 1549/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3569 - accuracy: 0.8708 - val_loss: 0.3126 - val_accuracy: 0.8824\n",
      "Epoch 1550/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.0909 - accuracy: 0.8855 - val_loss: 0.2884 - val_accuracy: 0.8918\n",
      "Epoch 1551/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9510 - accuracy: 0.8912 - val_loss: 0.2948 - val_accuracy: 0.8876\n",
      "Epoch 1552/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0991 - accuracy: 0.8837 - val_loss: 0.4574 - val_accuracy: 0.8080\n",
      "Epoch 1553/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3181 - accuracy: 0.8710 - val_loss: 0.2915 - val_accuracy: 0.8914\n",
      "Epoch 1554/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0139 - accuracy: 0.8878 - val_loss: 0.2969 - val_accuracy: 0.8869\n",
      "Epoch 1555/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0278 - accuracy: 0.8865 - val_loss: 0.3787 - val_accuracy: 0.8467\n",
      "Epoch 1556/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0573 - accuracy: 0.8833 - val_loss: 0.2944 - val_accuracy: 0.8891\n",
      "Epoch 1557/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.8812 - accuracy: 0.8941 - val_loss: 0.2821 - val_accuracy: 0.8936\n",
      "Epoch 1558/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9060 - accuracy: 0.8931 - val_loss: 0.3577 - val_accuracy: 0.8542\n",
      "Epoch 1559/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5345 - accuracy: 0.8614 - val_loss: 0.4098 - val_accuracy: 0.8296\n",
      "Epoch 1560/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.2728 - accuracy: 0.8755 - val_loss: 0.2963 - val_accuracy: 0.8907\n",
      "Epoch 1561/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0268 - accuracy: 0.8881 - val_loss: 0.3255 - val_accuracy: 0.8740\n",
      "Epoch 1562/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.8996 - accuracy: 0.8936 - val_loss: 0.2842 - val_accuracy: 0.8932\n",
      "Epoch 1563/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8579 - accuracy: 0.8944 - val_loss: 0.3122 - val_accuracy: 0.8778\n",
      "Epoch 1564/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 2.9064 - accuracy: 0.8913 - val_loss: 0.3094 - val_accuracy: 0.8792\n",
      "Epoch 1565/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.8912 - accuracy: 0.8931 - val_loss: 0.3022 - val_accuracy: 0.8823\n",
      "Epoch 1566/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1289 - accuracy: 0.8813 - val_loss: 0.5265 - val_accuracy: 0.7814\n",
      "Epoch 1567/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6682 - accuracy: 0.8532 - val_loss: 0.3463 - val_accuracy: 0.8663\n",
      "Epoch 1568/3000\n",
      " 3/10 [========>.....................] - ETA: 0s - loss: 3.5835 - accuracy: 0.8591Epoch 2486/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.6085 - accuracy: 0.9030 - val_loss: 0.2935 - val_accuracy: 0.8872\n",
      "Epoch 2487/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.5871 - accuracy: 0.9038 - val_loss: 0.2977 - val_accuracy: 0.8852\n",
      "Epoch 2488/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.5993 - accuracy: 0.9027 - val_loss: 0.2791 - val_accuracy: 0.8952\n",
      "Epoch 2489/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.5925 - accuracy: 0.9041 - val_loss: 0.3163 - val_accuracy: 0.8756\n",
      "Epoch 2490/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.7435 - accuracy: 0.8941 - val_loss: 0.3591 - val_accuracy: 0.8633\n",
      "Epoch 2491/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2346 - accuracy: 0.8753 - val_loss: 0.3081 - val_accuracy: 0.8878\n",
      "Epoch 2492/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.8992 - accuracy: 0.8907 - val_loss: 0.2883 - val_accuracy: 0.8932\n",
      "Epoch 2493/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.7557 - accuracy: 0.8980 - val_loss: 0.2800 - val_accuracy: 0.8945\n",
      "Epoch 2494/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.6838 - accuracy: 0.9005 - val_loss: 0.3562 - val_accuracy: 0.8562\n",
      "Epoch 2495/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6215 - accuracy: 0.8555 - val_loss: 0.3222 - val_accuracy: 0.8818\n",
      "Epoch 2496/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3605 - accuracy: 0.8699 - val_loss: 0.3650 - val_accuracy: 0.8593\n",
      "Epoch 2497/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9877 - accuracy: 0.8877 - val_loss: 0.2842 - val_accuracy: 0.8942\n",
      "Epoch 2498/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.7376 - accuracy: 0.8983 - val_loss: 0.2899 - val_accuracy: 0.8890\n",
      "Epoch 2499/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.6432 - accuracy: 0.9025 - val_loss: 0.2759 - val_accuracy: 0.8965\n",
      "Epoch 2500/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.6188 - accuracy: 0.9026 - val_loss: 0.2758 - val_accuracy: 0.8976\n",
      "Epoch 2501/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.6314 - accuracy: 0.9022 - val_loss: 0.2924 - val_accuracy: 0.8877\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape = trainFeature.shape[1]))\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(8, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(3, activation = \"softmax\"))\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate = 0.0005)\n",
    "\n",
    "model.compile(optimizer = Adam, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "class_weight = {0 : 7.,\n",
    "                1 : 18.,\n",
    "                2 : 8.}\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", min_delta = 0.00001, patience = 300, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(trainFeature, trainTarget, epochs = 3000, validation_split = 0.3, shuffle = True,\n",
    "                    verbose = 1, batch_size = 15000, class_weight = class_weight, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(testFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8967436735314234"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.argmax(result, axis = 1) == test[\"class\"]) / len(test[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv(\"./RawData/test.csv\")\n",
    "submit = pd.read_csv(\"./RawData/sample_submission.csv\")\n",
    "result = model.predict(pred.drop(\"id\", axis = \"columns\"))\n",
    "submit[\"class\"] = np.argmax(result, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>399995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>399996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>399997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>399998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>399999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  class\n",
       "0      320000      0\n",
       "1      320001      0\n",
       "2      320002      0\n",
       "3      320003      0\n",
       "4      320004      0\n",
       "...       ...    ...\n",
       "79995  399995      0\n",
       "79996  399996      0\n",
       "79997  399997      0\n",
       "79998  399998      0\n",
       "79999  399999      0\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"C:/Users/Family/Desktop/submit.csv\", index = False, encoding = \"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./RawData/train.csv\")\n",
    "train = train.drop([\"id\"], axis = \"columns\")\n",
    "\n",
    "#clf = IsolationForest(n_estimators = 100)\n",
    "#clf.fit(train)\n",
    "#pred = clf.predict(train)\n",
    "#train[\"anomaly\"] = pred\n",
    "#train = train.loc[train[\"anomaly\"] != -1]\n",
    "#train = train.drop(\"anomaly\", axis = \"columns\")\n",
    "\n",
    "train, test = train_test_split(train, test_size = .2)\n",
    "\n",
    "train, valid = train_test_split(train, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeature = train.drop(\"class\", axis = \"columns\")\n",
    "trainTarget = train[\"class\"]\n",
    "\n",
    "validFeature = valid.drop(\"class\", axis = \"columns\")\n",
    "validTarget = valid[\"class\"]\n",
    "\n",
    "testFeature = test.drop(\"class\", axis = \"columns\")\n",
    "testTarget = test[\"class\"]\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "res = scale.fit(trainFeature)\n",
    "res = scale.transform(trainFeature)\n",
    "trainFeature = np.array(res)\n",
    "\n",
    "res = scale.transform(validFeature)\n",
    "validFeature = np.array(res)\n",
    "\n",
    "res = scale.transform(testFeature)\n",
    "testFeature = np.array(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.10302\n",
      "[1]\tvalidation_0-merror:0.09603\n",
      "[2]\tvalidation_0-merror:0.09449\n",
      "[3]\tvalidation_0-merror:0.09323\n",
      "[4]\tvalidation_0-merror:0.09174\n",
      "[5]\tvalidation_0-merror:0.09107\n",
      "[6]\tvalidation_0-merror:0.09008\n",
      "[7]\tvalidation_0-merror:0.08936\n",
      "[8]\tvalidation_0-merror:0.08826\n",
      "[9]\tvalidation_0-merror:0.08767\n",
      "[10]\tvalidation_0-merror:0.08725\n",
      "[11]\tvalidation_0-merror:0.08654\n",
      "[12]\tvalidation_0-merror:0.08592\n",
      "[13]\tvalidation_0-merror:0.08538\n",
      "[14]\tvalidation_0-merror:0.08495\n",
      "[15]\tvalidation_0-merror:0.08428\n",
      "[16]\tvalidation_0-merror:0.08396\n",
      "[17]\tvalidation_0-merror:0.08363\n",
      "[18]\tvalidation_0-merror:0.08349\n",
      "[19]\tvalidation_0-merror:0.08315\n",
      "[20]\tvalidation_0-merror:0.08306\n",
      "[21]\tvalidation_0-merror:0.08266\n",
      "[22]\tvalidation_0-merror:0.08215\n",
      "[23]\tvalidation_0-merror:0.08182\n",
      "[24]\tvalidation_0-merror:0.08145\n",
      "[25]\tvalidation_0-merror:0.08106\n",
      "[26]\tvalidation_0-merror:0.08090\n",
      "[27]\tvalidation_0-merror:0.08052\n",
      "[28]\tvalidation_0-merror:0.08046\n",
      "[29]\tvalidation_0-merror:0.08043\n",
      "[30]\tvalidation_0-merror:0.08012\n",
      "[31]\tvalidation_0-merror:0.08008\n",
      "[32]\tvalidation_0-merror:0.07963\n",
      "[33]\tvalidation_0-merror:0.07940\n",
      "[34]\tvalidation_0-merror:0.07914\n",
      "[35]\tvalidation_0-merror:0.07923\n",
      "[36]\tvalidation_0-merror:0.07888\n",
      "[37]\tvalidation_0-merror:0.07875\n",
      "[38]\tvalidation_0-merror:0.07869\n",
      "[39]\tvalidation_0-merror:0.07836\n",
      "[40]\tvalidation_0-merror:0.07844\n",
      "[41]\tvalidation_0-merror:0.07836\n",
      "[42]\tvalidation_0-merror:0.07838\n",
      "[43]\tvalidation_0-merror:0.07829\n",
      "[44]\tvalidation_0-merror:0.07805\n",
      "[45]\tvalidation_0-merror:0.07789\n",
      "[46]\tvalidation_0-merror:0.07772\n",
      "[47]\tvalidation_0-merror:0.07785\n",
      "[48]\tvalidation_0-merror:0.07764\n",
      "[49]\tvalidation_0-merror:0.07758\n",
      "[50]\tvalidation_0-merror:0.07737\n",
      "[51]\tvalidation_0-merror:0.07742\n",
      "[52]\tvalidation_0-merror:0.07729\n",
      "[53]\tvalidation_0-merror:0.07721\n",
      "[54]\tvalidation_0-merror:0.07701\n",
      "[55]\tvalidation_0-merror:0.07682\n",
      "[56]\tvalidation_0-merror:0.07669\n",
      "[57]\tvalidation_0-merror:0.07659\n",
      "[58]\tvalidation_0-merror:0.07620\n",
      "[59]\tvalidation_0-merror:0.07609\n",
      "[60]\tvalidation_0-merror:0.07622\n",
      "[61]\tvalidation_0-merror:0.07621\n",
      "[62]\tvalidation_0-merror:0.07621\n",
      "[63]\tvalidation_0-merror:0.07625\n",
      "[64]\tvalidation_0-merror:0.07626\n",
      "[65]\tvalidation_0-merror:0.07612\n",
      "[66]\tvalidation_0-merror:0.07619\n",
      "[67]\tvalidation_0-merror:0.07622\n",
      "[68]\tvalidation_0-merror:0.07625\n",
      "[69]\tvalidation_0-merror:0.07616\n",
      "[70]\tvalidation_0-merror:0.07625\n",
      "[71]\tvalidation_0-merror:0.07622\n",
      "[72]\tvalidation_0-merror:0.07616\n",
      "[73]\tvalidation_0-merror:0.07628\n",
      "[74]\tvalidation_0-merror:0.07612\n",
      "[75]\tvalidation_0-merror:0.07612\n",
      "[76]\tvalidation_0-merror:0.07624\n",
      "[77]\tvalidation_0-merror:0.07622\n",
      "[78]\tvalidation_0-merror:0.07602\n",
      "[79]\tvalidation_0-merror:0.07600\n",
      "[80]\tvalidation_0-merror:0.07600\n",
      "[81]\tvalidation_0-merror:0.07598\n",
      "[82]\tvalidation_0-merror:0.07599\n",
      "[83]\tvalidation_0-merror:0.07591\n",
      "[84]\tvalidation_0-merror:0.07586\n",
      "[85]\tvalidation_0-merror:0.07591\n",
      "[86]\tvalidation_0-merror:0.07590\n",
      "[87]\tvalidation_0-merror:0.07599\n",
      "[88]\tvalidation_0-merror:0.07596\n",
      "[89]\tvalidation_0-merror:0.07595\n",
      "[90]\tvalidation_0-merror:0.07585\n",
      "[91]\tvalidation_0-merror:0.07592\n",
      "[92]\tvalidation_0-merror:0.07586\n",
      "[93]\tvalidation_0-merror:0.07587\n",
      "[94]\tvalidation_0-merror:0.07590\n",
      "[95]\tvalidation_0-merror:0.07573\n",
      "[96]\tvalidation_0-merror:0.07574\n",
      "[97]\tvalidation_0-merror:0.07576\n",
      "[98]\tvalidation_0-merror:0.07565\n",
      "[99]\tvalidation_0-merror:0.07555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = xgboost.XGBClassifier(objective = \"softprob\")\n",
    "tree.fit(trainFeature, trainTarget, eval_set = [(validFeature, validTarget)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = {\n",
    "    \"subsample\" : [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"max_depth\" : [2, 3, 4, 5, 6, 7],\n",
    "    \"n_estimators\" : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    \"gamma\" : [0.5, 1, 1.5, 2, 2.5],\n",
    "    \"learning_rate\" : [0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(tree, param_grid = xgb_param, scoring = \"accuracy\", cv = 5)\n",
    "grid_xgb.fit(trainFeature, trainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924171875"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tree.predict(testFeature)\n",
    "sum(result == testTarget.reset_index(drop = True)) / len(testTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv(\"./RawData/test.csv\")\n",
    "submit = pd.read_csv(\"./RawData/sample_submission.csv\")\n",
    "result = tree.predict(np.array(pred.drop(\"id\", axis = \"columns\")))\n",
    "submit[\"class\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"C:/Users/Family/Desktop/submit.csv\", index = False, encoding = \"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
