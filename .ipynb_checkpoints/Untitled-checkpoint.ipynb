{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras\n",
    "from xgboost import plot_importance\n",
    "from plotly.offline import plot\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(connected = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Family\\\\Documents\\\\GitHub\\\\Astro'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./RawData/train.csv\")\n",
    "train = train.drop([\"id\"], axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(n_estimators = 300)\n",
    "clf.fit(train)\n",
    "pred = clf.predict(train)\n",
    "train[\"anomaly\"] = pred\n",
    "\n",
    "train = train.loc[train[\"anomaly\"] != -1]\n",
    "train = train.drop(\"anomaly\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>dered_u</th>\n",
       "      <th>dered_g</th>\n",
       "      <th>dered_r</th>\n",
       "      <th>dered_i</th>\n",
       "      <th>dered_z</th>\n",
       "      <th>nObserve</th>\n",
       "      <th>nDetect</th>\n",
       "      <th>airmass_u</th>\n",
       "      <th>airmass_g</th>\n",
       "      <th>airmass_r</th>\n",
       "      <th>airmass_i</th>\n",
       "      <th>airmass_z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "      <td>271436.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.641930</td>\n",
       "      <td>18.237203</td>\n",
       "      <td>17.576619</td>\n",
       "      <td>17.189570</td>\n",
       "      <td>16.899771</td>\n",
       "      <td>0.059588</td>\n",
       "      <td>19.459596</td>\n",
       "      <td>18.092043</td>\n",
       "      <td>17.475915</td>\n",
       "      <td>17.114803</td>\n",
       "      <td>16.836809</td>\n",
       "      <td>5.846745</td>\n",
       "      <td>5.712422</td>\n",
       "      <td>1.161838</td>\n",
       "      <td>1.162131</td>\n",
       "      <td>1.161670</td>\n",
       "      <td>1.161738</td>\n",
       "      <td>1.161968</td>\n",
       "      <td>1.191994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.531686</td>\n",
       "      <td>1.218757</td>\n",
       "      <td>1.062318</td>\n",
       "      <td>0.999557</td>\n",
       "      <td>24.373434</td>\n",
       "      <td>0.344468</td>\n",
       "      <td>1.488982</td>\n",
       "      <td>1.188908</td>\n",
       "      <td>1.046085</td>\n",
       "      <td>0.991696</td>\n",
       "      <td>27.206814</td>\n",
       "      <td>8.179031</td>\n",
       "      <td>7.943147</td>\n",
       "      <td>0.095012</td>\n",
       "      <td>0.095668</td>\n",
       "      <td>0.094548</td>\n",
       "      <td>0.094756</td>\n",
       "      <td>0.095316</td>\n",
       "      <td>0.908649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.081344</td>\n",
       "      <td>14.975357</td>\n",
       "      <td>14.043669</td>\n",
       "      <td>12.242290</td>\n",
       "      <td>-9791.561274</td>\n",
       "      <td>-86.618158</td>\n",
       "      <td>14.381620</td>\n",
       "      <td>13.562930</td>\n",
       "      <td>13.912000</td>\n",
       "      <td>12.078640</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000059</td>\n",
       "      <td>1.000012</td>\n",
       "      <td>1.000179</td>\n",
       "      <td>1.000109</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.740150</td>\n",
       "      <td>17.501029</td>\n",
       "      <td>16.908777</td>\n",
       "      <td>16.554286</td>\n",
       "      <td>16.319118</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>18.593637</td>\n",
       "      <td>17.383210</td>\n",
       "      <td>16.824185</td>\n",
       "      <td>16.488277</td>\n",
       "      <td>16.267997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.086601</td>\n",
       "      <td>1.087003</td>\n",
       "      <td>1.086323</td>\n",
       "      <td>1.086516</td>\n",
       "      <td>1.086830</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.356823</td>\n",
       "      <td>18.091417</td>\n",
       "      <td>17.482649</td>\n",
       "      <td>17.107607</td>\n",
       "      <td>16.875365</td>\n",
       "      <td>0.055490</td>\n",
       "      <td>19.210200</td>\n",
       "      <td>17.978265</td>\n",
       "      <td>17.402480</td>\n",
       "      <td>17.046970</td>\n",
       "      <td>16.828920</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.173573</td>\n",
       "      <td>1.173068</td>\n",
       "      <td>1.174134</td>\n",
       "      <td>1.173867</td>\n",
       "      <td>1.173339</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.117558</td>\n",
       "      <td>18.698384</td>\n",
       "      <td>18.026036</td>\n",
       "      <td>17.662443</td>\n",
       "      <td>17.456378</td>\n",
       "      <td>0.097262</td>\n",
       "      <td>19.925305</td>\n",
       "      <td>18.547863</td>\n",
       "      <td>17.907485</td>\n",
       "      <td>17.576705</td>\n",
       "      <td>17.393160</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.210865</td>\n",
       "      <td>1.209931</td>\n",
       "      <td>1.211320</td>\n",
       "      <td>1.211057</td>\n",
       "      <td>1.210232</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.388600</td>\n",
       "      <td>31.765897</td>\n",
       "      <td>30.639861</td>\n",
       "      <td>28.494407</td>\n",
       "      <td>28.748876</td>\n",
       "      <td>62.323343</td>\n",
       "      <td>29.672990</td>\n",
       "      <td>29.925390</td>\n",
       "      <td>25.558920</td>\n",
       "      <td>28.227670</td>\n",
       "      <td>26.108300</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.509738</td>\n",
       "      <td>1.523230</td>\n",
       "      <td>1.514571</td>\n",
       "      <td>1.509467</td>\n",
       "      <td>1.516430</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   u              g              r              i  \\\n",
       "count  271436.000000  271436.000000  271436.000000  271436.000000   \n",
       "mean       19.641930      18.237203      17.576619      17.189570   \n",
       "std         1.531686       1.218757       1.062318       0.999557   \n",
       "min        10.081344      14.975357      14.043669      12.242290   \n",
       "25%        18.740150      17.501029      16.908777      16.554286   \n",
       "50%        19.356823      18.091417      17.482649      17.107607   \n",
       "75%        20.117558      18.698384      18.026036      17.662443   \n",
       "max        33.388600      31.765897      30.639861      28.494407   \n",
       "\n",
       "                   z       redshift        dered_u        dered_g  \\\n",
       "count  271436.000000  271436.000000  271436.000000  271436.000000   \n",
       "mean       16.899771       0.059588      19.459596      18.092043   \n",
       "std        24.373434       0.344468       1.488982       1.188908   \n",
       "min     -9791.561274     -86.618158      14.381620      13.562930   \n",
       "25%        16.319118       0.000073      18.593637      17.383210   \n",
       "50%        16.875365       0.055490      19.210200      17.978265   \n",
       "75%        17.456378       0.097262      19.925305      18.547863   \n",
       "max        28.748876      62.323343      29.672990      29.925390   \n",
       "\n",
       "             dered_r        dered_i        dered_z       nObserve  \\\n",
       "count  271436.000000  271436.000000  271436.000000  271436.000000   \n",
       "mean       17.475915      17.114803      16.836809       5.846745   \n",
       "std         1.046085       0.991696      27.206814       8.179031   \n",
       "min        13.912000      12.078640   -9999.000000       1.000000   \n",
       "25%        16.824185      16.488277      16.267997       1.000000   \n",
       "50%        17.402480      17.046970      16.828920       2.000000   \n",
       "75%        17.907485      17.576705      17.393160       4.000000   \n",
       "max        25.558920      28.227670      26.108300      43.000000   \n",
       "\n",
       "             nDetect      airmass_u      airmass_g      airmass_r  \\\n",
       "count  271436.000000  271436.000000  271436.000000  271436.000000   \n",
       "mean        5.712422       1.161838       1.162131       1.161670   \n",
       "std         7.943147       0.095012       0.095668       0.094548   \n",
       "min         1.000000       1.000059       1.000012       1.000179   \n",
       "25%         1.000000       1.086601       1.087003       1.086323   \n",
       "50%         2.000000       1.173573       1.173068       1.174134   \n",
       "75%         4.000000       1.210865       1.209931       1.211320   \n",
       "max        41.000000       1.509738       1.523230       1.514571   \n",
       "\n",
       "           airmass_i      airmass_z          class  \n",
       "count  271436.000000  271436.000000  271436.000000  \n",
       "mean        1.161738       1.161968       1.191994  \n",
       "std         0.094756       0.095316       0.908649  \n",
       "min         1.000109       1.000027       0.000000  \n",
       "25%         1.086516       1.086830       0.000000  \n",
       "50%         1.173867       1.173339       2.000000  \n",
       "75%         1.211057       1.210232       2.000000  \n",
       "max         1.509467       1.516430       2.000000  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>dered_u</th>\n",
       "      <th>dered_g</th>\n",
       "      <th>dered_r</th>\n",
       "      <th>dered_i</th>\n",
       "      <th>dered_z</th>\n",
       "      <th>nObserve</th>\n",
       "      <th>nDetect</th>\n",
       "      <th>airmass_u</th>\n",
       "      <th>airmass_g</th>\n",
       "      <th>airmass_r</th>\n",
       "      <th>airmass_i</th>\n",
       "      <th>airmass_z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920384</td>\n",
       "      <td>0.790114</td>\n",
       "      <td>0.625414</td>\n",
       "      <td>0.021315</td>\n",
       "      <td>-0.021900</td>\n",
       "      <td>0.971121</td>\n",
       "      <td>0.894310</td>\n",
       "      <td>0.763670</td>\n",
       "      <td>0.599717</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.277655</td>\n",
       "      <td>0.277101</td>\n",
       "      <td>0.108146</td>\n",
       "      <td>0.108394</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.107954</td>\n",
       "      <td>0.108295</td>\n",
       "      <td>-0.343683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0.920384</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941895</td>\n",
       "      <td>0.818393</td>\n",
       "      <td>0.029261</td>\n",
       "      <td>-0.013847</td>\n",
       "      <td>0.905614</td>\n",
       "      <td>0.979470</td>\n",
       "      <td>0.919894</td>\n",
       "      <td>0.795859</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.281117</td>\n",
       "      <td>0.279468</td>\n",
       "      <td>0.109217</td>\n",
       "      <td>0.109285</td>\n",
       "      <td>0.108960</td>\n",
       "      <td>0.109114</td>\n",
       "      <td>0.109276</td>\n",
       "      <td>-0.348025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.790114</td>\n",
       "      <td>0.941895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942721</td>\n",
       "      <td>0.035680</td>\n",
       "      <td>-0.020137</td>\n",
       "      <td>0.781902</td>\n",
       "      <td>0.930507</td>\n",
       "      <td>0.986870</td>\n",
       "      <td>0.927720</td>\n",
       "      <td>0.031285</td>\n",
       "      <td>0.270437</td>\n",
       "      <td>0.267918</td>\n",
       "      <td>0.105917</td>\n",
       "      <td>0.105972</td>\n",
       "      <td>0.105678</td>\n",
       "      <td>0.105822</td>\n",
       "      <td>0.105969</td>\n",
       "      <td>-0.376357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.625414</td>\n",
       "      <td>0.818393</td>\n",
       "      <td>0.942721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039693</td>\n",
       "      <td>-0.022409</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.814455</td>\n",
       "      <td>0.937730</td>\n",
       "      <td>0.991084</td>\n",
       "      <td>0.035044</td>\n",
       "      <td>0.256186</td>\n",
       "      <td>0.253229</td>\n",
       "      <td>0.100996</td>\n",
       "      <td>0.101309</td>\n",
       "      <td>0.100505</td>\n",
       "      <td>0.100774</td>\n",
       "      <td>0.101177</td>\n",
       "      <td>-0.374995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.021315</td>\n",
       "      <td>0.029261</td>\n",
       "      <td>0.035680</td>\n",
       "      <td>0.039693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>0.021185</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>0.035609</td>\n",
       "      <td>0.039492</td>\n",
       "      <td>0.995158</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>-0.017929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redshift</th>\n",
       "      <td>-0.021900</td>\n",
       "      <td>-0.013847</td>\n",
       "      <td>-0.020137</td>\n",
       "      <td>-0.022409</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018948</td>\n",
       "      <td>-0.009416</td>\n",
       "      <td>-0.016750</td>\n",
       "      <td>-0.019786</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>-0.020227</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.007961</td>\n",
       "      <td>-0.007953</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>-0.007960</td>\n",
       "      <td>-0.007959</td>\n",
       "      <td>0.120763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dered_u</th>\n",
       "      <td>0.971121</td>\n",
       "      <td>0.905614</td>\n",
       "      <td>0.781902</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.021185</td>\n",
       "      <td>-0.018948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920874</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.620614</td>\n",
       "      <td>0.018893</td>\n",
       "      <td>0.263313</td>\n",
       "      <td>0.263163</td>\n",
       "      <td>0.094326</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>0.093886</td>\n",
       "      <td>0.094128</td>\n",
       "      <td>0.094483</td>\n",
       "      <td>-0.321893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dered_g</th>\n",
       "      <td>0.894310</td>\n",
       "      <td>0.979470</td>\n",
       "      <td>0.930507</td>\n",
       "      <td>0.814455</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>-0.009416</td>\n",
       "      <td>0.920874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939697</td>\n",
       "      <td>0.816324</td>\n",
       "      <td>0.026046</td>\n",
       "      <td>0.265298</td>\n",
       "      <td>0.264085</td>\n",
       "      <td>0.094908</td>\n",
       "      <td>0.095007</td>\n",
       "      <td>0.094639</td>\n",
       "      <td>0.094796</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>-0.322785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dered_r</th>\n",
       "      <td>0.763670</td>\n",
       "      <td>0.919894</td>\n",
       "      <td>0.986870</td>\n",
       "      <td>0.937730</td>\n",
       "      <td>0.035609</td>\n",
       "      <td>-0.016750</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.939697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942534</td>\n",
       "      <td>0.031728</td>\n",
       "      <td>0.256751</td>\n",
       "      <td>0.254568</td>\n",
       "      <td>0.094336</td>\n",
       "      <td>0.094419</td>\n",
       "      <td>0.094084</td>\n",
       "      <td>0.094233</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>-0.355379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dered_i</th>\n",
       "      <td>0.599717</td>\n",
       "      <td>0.795859</td>\n",
       "      <td>0.927720</td>\n",
       "      <td>0.991084</td>\n",
       "      <td>0.039492</td>\n",
       "      <td>-0.019786</td>\n",
       "      <td>0.620614</td>\n",
       "      <td>0.816324</td>\n",
       "      <td>0.942534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035263</td>\n",
       "      <td>0.244102</td>\n",
       "      <td>0.241432</td>\n",
       "      <td>0.091414</td>\n",
       "      <td>0.091750</td>\n",
       "      <td>0.090914</td>\n",
       "      <td>0.091186</td>\n",
       "      <td>0.091604</td>\n",
       "      <td>-0.356929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dered_z</th>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.031285</td>\n",
       "      <td>0.035044</td>\n",
       "      <td>0.995158</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>0.018893</td>\n",
       "      <td>0.026046</td>\n",
       "      <td>0.031728</td>\n",
       "      <td>0.035263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>-0.015785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nObserve</th>\n",
       "      <td>0.277655</td>\n",
       "      <td>0.281117</td>\n",
       "      <td>0.270437</td>\n",
       "      <td>0.256186</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>-0.020227</td>\n",
       "      <td>0.263313</td>\n",
       "      <td>0.265298</td>\n",
       "      <td>0.256751</td>\n",
       "      <td>0.244102</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995649</td>\n",
       "      <td>0.275782</td>\n",
       "      <td>0.281055</td>\n",
       "      <td>0.269997</td>\n",
       "      <td>0.272956</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>-0.236161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nDetect</th>\n",
       "      <td>0.277101</td>\n",
       "      <td>0.279468</td>\n",
       "      <td>0.267918</td>\n",
       "      <td>0.253229</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>0.263163</td>\n",
       "      <td>0.264085</td>\n",
       "      <td>0.254568</td>\n",
       "      <td>0.241432</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>0.995649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.275707</td>\n",
       "      <td>0.281024</td>\n",
       "      <td>0.269879</td>\n",
       "      <td>0.272859</td>\n",
       "      <td>0.278434</td>\n",
       "      <td>-0.238762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airmass_u</th>\n",
       "      <td>0.108146</td>\n",
       "      <td>0.109217</td>\n",
       "      <td>0.105917</td>\n",
       "      <td>0.100996</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>-0.007961</td>\n",
       "      <td>0.094326</td>\n",
       "      <td>0.094908</td>\n",
       "      <td>0.094336</td>\n",
       "      <td>0.091414</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.275782</td>\n",
       "      <td>0.275707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999175</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>-0.099279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airmass_g</th>\n",
       "      <td>0.108394</td>\n",
       "      <td>0.109285</td>\n",
       "      <td>0.105972</td>\n",
       "      <td>0.101309</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>-0.007953</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>0.095007</td>\n",
       "      <td>0.094419</td>\n",
       "      <td>0.091750</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.281055</td>\n",
       "      <td>0.281024</td>\n",
       "      <td>0.999175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996670</td>\n",
       "      <td>0.998135</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>-0.099342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airmass_r</th>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.108960</td>\n",
       "      <td>0.105678</td>\n",
       "      <td>0.100505</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>0.093886</td>\n",
       "      <td>0.094639</td>\n",
       "      <td>0.094084</td>\n",
       "      <td>0.090914</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.269997</td>\n",
       "      <td>0.269879</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>0.996670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>-0.099034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airmass_i</th>\n",
       "      <td>0.107954</td>\n",
       "      <td>0.109114</td>\n",
       "      <td>0.105822</td>\n",
       "      <td>0.100774</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-0.007960</td>\n",
       "      <td>0.094128</td>\n",
       "      <td>0.094796</td>\n",
       "      <td>0.094233</td>\n",
       "      <td>0.091186</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.272956</td>\n",
       "      <td>0.272859</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.998135</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>-0.099181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airmass_z</th>\n",
       "      <td>0.108295</td>\n",
       "      <td>0.109276</td>\n",
       "      <td>0.105969</td>\n",
       "      <td>0.101177</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>-0.007959</td>\n",
       "      <td>0.094483</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.091604</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.278434</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.099335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>-0.343683</td>\n",
       "      <td>-0.348025</td>\n",
       "      <td>-0.376357</td>\n",
       "      <td>-0.374995</td>\n",
       "      <td>-0.017929</td>\n",
       "      <td>0.120763</td>\n",
       "      <td>-0.321893</td>\n",
       "      <td>-0.322785</td>\n",
       "      <td>-0.355379</td>\n",
       "      <td>-0.356929</td>\n",
       "      <td>-0.015785</td>\n",
       "      <td>-0.236161</td>\n",
       "      <td>-0.238762</td>\n",
       "      <td>-0.099279</td>\n",
       "      <td>-0.099342</td>\n",
       "      <td>-0.099034</td>\n",
       "      <td>-0.099181</td>\n",
       "      <td>-0.099335</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  u         g         r         i         z  redshift  \\\n",
       "u          1.000000  0.920384  0.790114  0.625414  0.021315 -0.021900   \n",
       "g          0.920384  1.000000  0.941895  0.818393  0.029261 -0.013847   \n",
       "r          0.790114  0.941895  1.000000  0.942721  0.035680 -0.020137   \n",
       "i          0.625414  0.818393  0.942721  1.000000  0.039693 -0.022409   \n",
       "z          0.021315  0.029261  0.035680  0.039693  1.000000 -0.001416   \n",
       "redshift  -0.021900 -0.013847 -0.020137 -0.022409 -0.001416  1.000000   \n",
       "dered_u    0.971121  0.905614  0.781902  0.621505  0.021185 -0.018948   \n",
       "dered_g    0.894310  0.979470  0.930507  0.814455  0.029210 -0.009416   \n",
       "dered_r    0.763670  0.919894  0.986870  0.937730  0.035609 -0.016750   \n",
       "dered_i    0.599717  0.795859  0.927720  0.991084  0.039492 -0.019786   \n",
       "dered_z    0.018283  0.025428  0.031285  0.035044  0.995158 -0.001231   \n",
       "nObserve   0.277655  0.281117  0.270437  0.256186  0.010325 -0.020227   \n",
       "nDetect    0.277101  0.279468  0.267918  0.253229  0.010328 -0.020294   \n",
       "airmass_u  0.108146  0.109217  0.105917  0.100996  0.000848 -0.007961   \n",
       "airmass_g  0.108394  0.109285  0.105972  0.101309  0.000866 -0.007953   \n",
       "airmass_r  0.107712  0.108960  0.105678  0.100505  0.000827 -0.007954   \n",
       "airmass_i  0.107954  0.109114  0.105822  0.100774  0.000838 -0.007960   \n",
       "airmass_z  0.108295  0.109276  0.105969  0.101177  0.000857 -0.007959   \n",
       "class     -0.343683 -0.348025 -0.376357 -0.374995 -0.017929  0.120763   \n",
       "\n",
       "            dered_u   dered_g   dered_r   dered_i   dered_z  nObserve  \\\n",
       "u          0.971121  0.894310  0.763670  0.599717  0.018283  0.277655   \n",
       "g          0.905614  0.979470  0.919894  0.795859  0.025428  0.281117   \n",
       "r          0.781902  0.930507  0.986870  0.927720  0.031285  0.270437   \n",
       "i          0.621505  0.814455  0.937730  0.991084  0.035044  0.256186   \n",
       "z          0.021185  0.029210  0.035609  0.039492  0.995158  0.010325   \n",
       "redshift  -0.018948 -0.009416 -0.016750 -0.019786 -0.001231 -0.020227   \n",
       "dered_u    1.000000  0.920874  0.787351  0.620614  0.018893  0.263313   \n",
       "dered_g    0.920874  1.000000  0.939697  0.816324  0.026046  0.265298   \n",
       "dered_r    0.787351  0.939697  1.000000  0.942534  0.031728  0.256751   \n",
       "dered_i    0.620614  0.816324  0.942534  1.000000  0.035263  0.244102   \n",
       "dered_z    0.018893  0.026046  0.031728  0.035263  1.000000  0.008930   \n",
       "nObserve   0.263313  0.265298  0.256751  0.244102  0.008930  1.000000   \n",
       "nDetect    0.263163  0.264085  0.254568  0.241432  0.008972  0.995649   \n",
       "airmass_u  0.094326  0.094908  0.094336  0.091414  0.000078  0.275782   \n",
       "airmass_g  0.094596  0.095007  0.094419  0.091750  0.000082  0.281055   \n",
       "airmass_r  0.093886  0.094639  0.094084  0.090914  0.000073  0.269997   \n",
       "airmass_i  0.094128  0.094796  0.094233  0.091186  0.000075  0.272956   \n",
       "airmass_z  0.094483  0.094980  0.094400  0.091604  0.000080  0.278486   \n",
       "class     -0.321893 -0.322785 -0.355379 -0.356929 -0.015785 -0.236161   \n",
       "\n",
       "            nDetect  airmass_u  airmass_g  airmass_r  airmass_i  airmass_z  \\\n",
       "u          0.277101   0.108146   0.108394   0.107712   0.107954   0.108295   \n",
       "g          0.279468   0.109217   0.109285   0.108960   0.109114   0.109276   \n",
       "r          0.267918   0.105917   0.105972   0.105678   0.105822   0.105969   \n",
       "i          0.253229   0.100996   0.101309   0.100505   0.100774   0.101177   \n",
       "z          0.010328   0.000848   0.000866   0.000827   0.000838   0.000857   \n",
       "redshift  -0.020294  -0.007961  -0.007953  -0.007954  -0.007960  -0.007959   \n",
       "dered_u    0.263163   0.094326   0.094596   0.093886   0.094128   0.094483   \n",
       "dered_g    0.264085   0.094908   0.095007   0.094639   0.094796   0.094980   \n",
       "dered_r    0.254568   0.094336   0.094419   0.094084   0.094233   0.094400   \n",
       "dered_i    0.241432   0.091414   0.091750   0.090914   0.091186   0.091604   \n",
       "dered_z    0.008972   0.000078   0.000082   0.000073   0.000075   0.000080   \n",
       "nObserve   0.995649   0.275782   0.281055   0.269997   0.272956   0.278486   \n",
       "nDetect    1.000000   0.275707   0.281024   0.269879   0.272859   0.278434   \n",
       "airmass_u  0.275707   1.000000   0.999175   0.999160   0.999791   0.999793   \n",
       "airmass_g  0.281024   0.999175   1.000000   0.996670   0.998135   0.999795   \n",
       "airmass_r  0.269879   0.999160   0.996670   1.000000   0.999789   0.998118   \n",
       "airmass_i  0.272859   0.999791   0.998135   0.999789   1.000000   0.999167   \n",
       "airmass_z  0.278434   0.999793   0.999795   0.998118   0.999167   1.000000   \n",
       "class     -0.238762  -0.099279  -0.099342  -0.099034  -0.099181  -0.099335   \n",
       "\n",
       "              class  \n",
       "u         -0.343683  \n",
       "g         -0.348025  \n",
       "r         -0.376357  \n",
       "i         -0.374995  \n",
       "z         -0.017929  \n",
       "redshift   0.120763  \n",
       "dered_u   -0.321893  \n",
       "dered_g   -0.322785  \n",
       "dered_r   -0.355379  \n",
       "dered_i   -0.356929  \n",
       "dered_z   -0.015785  \n",
       "nObserve  -0.236161  \n",
       "nDetect   -0.238762  \n",
       "airmass_u -0.099279  \n",
       "airmass_g -0.099342  \n",
       "airmass_r -0.099034  \n",
       "airmass_i -0.099181  \n",
       "airmass_z -0.099335  \n",
       "class      1.000000  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr(method = \"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'u'}>,\n",
       "        <AxesSubplot:title={'center':'g'}>,\n",
       "        <AxesSubplot:title={'center':'r'}>,\n",
       "        <AxesSubplot:title={'center':'i'}>],\n",
       "       [<AxesSubplot:title={'center':'z'}>,\n",
       "        <AxesSubplot:title={'center':'redshift'}>,\n",
       "        <AxesSubplot:title={'center':'dered_u'}>,\n",
       "        <AxesSubplot:title={'center':'dered_g'}>],\n",
       "       [<AxesSubplot:title={'center':'dered_r'}>,\n",
       "        <AxesSubplot:title={'center':'dered_i'}>,\n",
       "        <AxesSubplot:title={'center':'dered_z'}>,\n",
       "        <AxesSubplot:title={'center':'nObserve'}>],\n",
       "       [<AxesSubplot:title={'center':'nDetect'}>,\n",
       "        <AxesSubplot:title={'center':'airmass_u'}>,\n",
       "        <AxesSubplot:title={'center':'airmass_g'}>,\n",
       "        <AxesSubplot:title={'center':'airmass_r'}>],\n",
       "       [<AxesSubplot:title={'center':'airmass_i'}>,\n",
       "        <AxesSubplot:title={'center':'airmass_z'}>,\n",
       "        <AxesSubplot:title={'center':'class'}>, <AxesSubplot:>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.hist(figsize = (12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86728 36017 140433\n"
     ]
    }
   ],
   "source": [
    "print(sum(train[\"class\"] == 0), sum(train[\"class\"] == 1), sum(train[\"class\"] == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(train, test_size = .2)\n",
    "\n",
    "trainTarget = keras.utils.to_categorical(train[\"class\"])\n",
    "testTarget = keras.utils.to_categorical(test[\"class\"])\n",
    "\n",
    "trainFeature = train.drop([\"class\"], axis = \"columns\")\n",
    "testFeature = test.drop([\"class\"], axis = \"columns\")\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "res = scale.fit(trainFeature)\n",
    "res = scale.transform(trainFeature)\n",
    "trainFeature = np.array(res)\n",
    "\n",
    "res = scale.transform(testFeature)\n",
    "testFeature = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 9.8935 - accuracy: 0.4949 - val_loss: 1.0866 - val_accuracy: 0.5416\n",
      "Epoch 2/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 9.7487 - accuracy: 0.5459 - val_loss: 1.0499 - val_accuracy: 0.5483\n",
      "Epoch 3/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 9.3753 - accuracy: 0.5551 - val_loss: 0.9752 - val_accuracy: 0.5818\n",
      "Epoch 4/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 8.9804 - accuracy: 0.6171 - val_loss: 0.9134 - val_accuracy: 0.6573\n",
      "Epoch 5/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 8.7296 - accuracy: 0.6652 - val_loss: 0.8998 - val_accuracy: 0.6720\n",
      "Epoch 6/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 8.5791 - accuracy: 0.6734 - val_loss: 0.8810 - val_accuracy: 0.6756\n",
      "Epoch 7/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 8.4599 - accuracy: 0.6757 - val_loss: 0.8646 - val_accuracy: 0.6745\n",
      "Epoch 8/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 8.4013 - accuracy: 0.6710 - val_loss: 0.8476 - val_accuracy: 0.6807\n",
      "Epoch 9/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 8.1872 - accuracy: 0.6815 - val_loss: 0.8191 - val_accuracy: 0.6798\n",
      "Epoch 10/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 7.9779 - accuracy: 0.6906 - val_loss: 0.7921 - val_accuracy: 0.6934\n",
      "Epoch 11/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 7.8011 - accuracy: 0.7003 - val_loss: 0.7664 - val_accuracy: 0.7030\n",
      "Epoch 12/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 7.6706 - accuracy: 0.7086 - val_loss: 0.7719 - val_accuracy: 0.7188\n",
      "Epoch 13/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 7.8245 - accuracy: 0.6962 - val_loss: 0.7629 - val_accuracy: 0.6999\n",
      "Epoch 14/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 7.5382 - accuracy: 0.7102 - val_loss: 0.7458 - val_accuracy: 0.7217\n",
      "Epoch 15/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 7.3508 - accuracy: 0.7198 - val_loss: 0.7135 - val_accuracy: 0.7203\n",
      "Epoch 16/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 7.2119 - accuracy: 0.7253 - val_loss: 0.7024 - val_accuracy: 0.7249\n",
      "Epoch 17/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 7.1068 - accuracy: 0.7298 - val_loss: 0.6898 - val_accuracy: 0.7303\n",
      "Epoch 18/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 7.0236 - accuracy: 0.7320 - val_loss: 0.6831 - val_accuracy: 0.7344\n",
      "Epoch 19/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.9461 - accuracy: 0.7340 - val_loss: 0.6808 - val_accuracy: 0.7354\n",
      "Epoch 20/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.9190 - accuracy: 0.7338 - val_loss: 0.6696 - val_accuracy: 0.7346\n",
      "Epoch 21/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 6.8323 - accuracy: 0.7346 - val_loss: 0.6744 - val_accuracy: 0.7349\n",
      "Epoch 22/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.8175 - accuracy: 0.7327 - val_loss: 0.6681 - val_accuracy: 0.7350\n",
      "Epoch 23/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 6.7814 - accuracy: 0.7324 - val_loss: 0.6828 - val_accuracy: 0.7279\n",
      "Epoch 24/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 6.7423 - accuracy: 0.7320 - val_loss: 0.6548 - val_accuracy: 0.7297\n",
      "Epoch 25/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 6.6760 - accuracy: 0.7351 - val_loss: 0.6486 - val_accuracy: 0.7374\n",
      "Epoch 26/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.6024 - accuracy: 0.7380 - val_loss: 0.6464 - val_accuracy: 0.7377\n",
      "Epoch 27/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.5824 - accuracy: 0.7370 - val_loss: 0.6422 - val_accuracy: 0.7388\n",
      "Epoch 28/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.5568 - accuracy: 0.7366 - val_loss: 0.6523 - val_accuracy: 0.7331\n",
      "Epoch 29/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.5768 - accuracy: 0.7330 - val_loss: 0.6359 - val_accuracy: 0.7376\n",
      "Epoch 30/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.4779 - accuracy: 0.7398 - val_loss: 0.6413 - val_accuracy: 0.7351\n",
      "Epoch 31/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.4935 - accuracy: 0.7359 - val_loss: 0.6245 - val_accuracy: 0.7408\n",
      "Epoch 32/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.5134 - accuracy: 0.7356 - val_loss: 0.6318 - val_accuracy: 0.7381\n",
      "Epoch 33/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.4312 - accuracy: 0.7386 - val_loss: 0.6324 - val_accuracy: 0.7379\n",
      "Epoch 34/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.3966 - accuracy: 0.7411 - val_loss: 0.6200 - val_accuracy: 0.7406\n",
      "Epoch 35/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.4539 - accuracy: 0.7347 - val_loss: 0.6203 - val_accuracy: 0.7402\n",
      "Epoch 36/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.4356 - accuracy: 0.7336 - val_loss: 0.6243 - val_accuracy: 0.7335\n",
      "Epoch 37/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.3844 - accuracy: 0.7382 - val_loss: 0.6321 - val_accuracy: 0.7363\n",
      "Epoch 38/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.3947 - accuracy: 0.7358 - val_loss: 0.6200 - val_accuracy: 0.7413\n",
      "Epoch 39/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.3222 - accuracy: 0.7425 - val_loss: 0.6182 - val_accuracy: 0.7410\n",
      "Epoch 40/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.2965 - accuracy: 0.7419 - val_loss: 0.6225 - val_accuracy: 0.7419\n",
      "Epoch 41/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.3572 - accuracy: 0.7361 - val_loss: 0.6160 - val_accuracy: 0.7398\n",
      "Epoch 42/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.3110 - accuracy: 0.7384 - val_loss: 0.6228 - val_accuracy: 0.7391\n",
      "Epoch 43/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.2860 - accuracy: 0.7403 - val_loss: 0.6171 - val_accuracy: 0.7423\n",
      "Epoch 44/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.3123 - accuracy: 0.7374 - val_loss: 0.6271 - val_accuracy: 0.7363\n",
      "Epoch 45/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.2978 - accuracy: 0.7375 - val_loss: 0.6183 - val_accuracy: 0.7405\n",
      "Epoch 46/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.2580 - accuracy: 0.7408 - val_loss: 0.6108 - val_accuracy: 0.7440\n",
      "Epoch 47/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.2435 - accuracy: 0.7420 - val_loss: 0.6151 - val_accuracy: 0.7386\n",
      "Epoch 48/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.2704 - accuracy: 0.7389 - val_loss: 0.6166 - val_accuracy: 0.7379\n",
      "Epoch 49/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.2508 - accuracy: 0.7389 - val_loss: 0.6173 - val_accuracy: 0.7400\n",
      "Epoch 50/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.1937 - accuracy: 0.7439 - val_loss: 0.6086 - val_accuracy: 0.7433\n",
      "Epoch 51/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.2097 - accuracy: 0.7425 - val_loss: 0.6117 - val_accuracy: 0.7406\n",
      "Epoch 52/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.2412 - accuracy: 0.7385 - val_loss: 0.6122 - val_accuracy: 0.7408\n",
      "Epoch 53/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1751 - accuracy: 0.7430 - val_loss: 0.6093 - val_accuracy: 0.7424\n",
      "Epoch 54/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1722 - accuracy: 0.7433 - val_loss: 0.6083 - val_accuracy: 0.7430\n",
      "Epoch 55/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1611 - accuracy: 0.7433 - val_loss: 0.6098 - val_accuracy: 0.7409\n",
      "Epoch 56/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1954 - accuracy: 0.7400 - val_loss: 0.6076 - val_accuracy: 0.7442\n",
      "Epoch 57/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1509 - accuracy: 0.7424 - val_loss: 0.6098 - val_accuracy: 0.7402\n",
      "Epoch 58/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1676 - accuracy: 0.7422 - val_loss: 0.6129 - val_accuracy: 0.7384\n",
      "Epoch 59/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1832 - accuracy: 0.7406 - val_loss: 0.6094 - val_accuracy: 0.7437\n",
      "Epoch 60/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.1135 - accuracy: 0.7450 - val_loss: 0.6052 - val_accuracy: 0.7454\n",
      "Epoch 61/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1175 - accuracy: 0.7453 - val_loss: 0.6078 - val_accuracy: 0.7445\n",
      "Epoch 62/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.0873 - accuracy: 0.7460 - val_loss: 0.6015 - val_accuracy: 0.7486\n",
      "Epoch 63/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1792 - accuracy: 0.7386 - val_loss: 0.6073 - val_accuracy: 0.7442\n",
      "Epoch 64/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 6.1323 - accuracy: 0.7410 - val_loss: 0.6095 - val_accuracy: 0.7431\n",
      "Epoch 65/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.1349 - accuracy: 0.7419 - val_loss: 0.6102 - val_accuracy: 0.7422\n",
      "Epoch 66/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.1013 - accuracy: 0.7451 - val_loss: 0.6023 - val_accuracy: 0.7482\n",
      "Epoch 67/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.0716 - accuracy: 0.7461 - val_loss: 0.6009 - val_accuracy: 0.7476\n",
      "Epoch 68/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.0643 - accuracy: 0.7470 - val_loss: 0.6018 - val_accuracy: 0.7487\n",
      "Epoch 69/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1131 - accuracy: 0.7425 - val_loss: 0.6210 - val_accuracy: 0.7326\n",
      "Epoch 70/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 6.1008 - accuracy: 0.7403 - val_loss: 0.6056 - val_accuracy: 0.7444\n",
      "Epoch 71/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.0573 - accuracy: 0.7464 - val_loss: 0.5977 - val_accuracy: 0.7502\n",
      "Epoch 72/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.0570 - accuracy: 0.7471 - val_loss: 0.6094 - val_accuracy: 0.7416\n",
      "Epoch 73/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.0629 - accuracy: 0.7458 - val_loss: 0.6185 - val_accuracy: 0.7339\n",
      "Epoch 74/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.0907 - accuracy: 0.7408 - val_loss: 0.6003 - val_accuracy: 0.7481\n",
      "Epoch 75/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1142 - accuracy: 0.7391 - val_loss: 0.6127 - val_accuracy: 0.7393\n",
      "Epoch 76/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.0434 - accuracy: 0.7454 - val_loss: 0.6080 - val_accuracy: 0.7419\n",
      "Epoch 77/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.0431 - accuracy: 0.7457 - val_loss: 0.6056 - val_accuracy: 0.7434\n",
      "Epoch 78/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.0339 - accuracy: 0.7456 - val_loss: 0.5943 - val_accuracy: 0.7524\n",
      "Epoch 79/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.9944 - accuracy: 0.7498 - val_loss: 0.5959 - val_accuracy: 0.7506\n",
      "Epoch 80/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.9856 - accuracy: 0.7495 - val_loss: 0.5954 - val_accuracy: 0.7531\n",
      "Epoch 81/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.9674 - accuracy: 0.7509 - val_loss: 0.5961 - val_accuracy: 0.7506\n",
      "Epoch 82/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.9981 - accuracy: 0.7489 - val_loss: 0.6056 - val_accuracy: 0.7415\n",
      "Epoch 83/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.9981 - accuracy: 0.7472 - val_loss: 0.6211 - val_accuracy: 0.7283\n",
      "Epoch 84/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.0519 - accuracy: 0.7412 - val_loss: 0.6000 - val_accuracy: 0.7460\n",
      "Epoch 85/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.9812 - accuracy: 0.7471 - val_loss: 0.6033 - val_accuracy: 0.7455\n",
      "Epoch 86/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.9688 - accuracy: 0.7506 - val_loss: 0.5900 - val_accuracy: 0.7559\n",
      "Epoch 87/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.9940 - accuracy: 0.7492 - val_loss: 0.5995 - val_accuracy: 0.7461\n",
      "Epoch 88/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.9337 - accuracy: 0.7517 - val_loss: 0.5969 - val_accuracy: 0.7478\n",
      "Epoch 89/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.9208 - accuracy: 0.7531 - val_loss: 0.5885 - val_accuracy: 0.7563\n",
      "Epoch 90/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.0675 - accuracy: 0.7421 - val_loss: 0.6046 - val_accuracy: 0.7433\n",
      "Epoch 91/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.0144 - accuracy: 0.7437 - val_loss: 0.6139 - val_accuracy: 0.7307\n",
      "Epoch 92/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 6.1293 - accuracy: 0.7330 - val_loss: 0.6240 - val_accuracy: 0.7329\n",
      "Epoch 93/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.1897 - accuracy: 0.7267 - val_loss: 0.6093 - val_accuracy: 0.7372\n",
      "Epoch 94/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 6.0457 - accuracy: 0.7390 - val_loss: 0.6089 - val_accuracy: 0.7357\n",
      "Epoch 95/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.0038 - accuracy: 0.7433 - val_loss: 0.6024 - val_accuracy: 0.7432\n",
      "Epoch 96/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.9446 - accuracy: 0.7498 - val_loss: 0.6124 - val_accuracy: 0.7329\n",
      "Epoch 97/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.9627 - accuracy: 0.7482 - val_loss: 0.5945 - val_accuracy: 0.7506\n",
      "Epoch 98/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8972 - accuracy: 0.7541 - val_loss: 0.5903 - val_accuracy: 0.7541\n",
      "Epoch 99/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8871 - accuracy: 0.7558 - val_loss: 0.5874 - val_accuracy: 0.7580\n",
      "Epoch 100/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8594 - accuracy: 0.7581 - val_loss: 0.5882 - val_accuracy: 0.7550\n",
      "Epoch 101/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.8865 - accuracy: 0.7549 - val_loss: 0.5842 - val_accuracy: 0.7588\n",
      "Epoch 102/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.8638 - accuracy: 0.7566 - val_loss: 0.5898 - val_accuracy: 0.7512\n",
      "Epoch 103/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.8518 - accuracy: 0.7579 - val_loss: 0.5868 - val_accuracy: 0.7543\n",
      "Epoch 104/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.9210 - accuracy: 0.7515 - val_loss: 0.6021 - val_accuracy: 0.7460\n",
      "Epoch 105/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.0586 - accuracy: 0.7392 - val_loss: 0.6264 - val_accuracy: 0.7176\n",
      "Epoch 106/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.9728 - accuracy: 0.7418 - val_loss: 0.5935 - val_accuracy: 0.7495\n",
      "Epoch 107/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.8726 - accuracy: 0.7530 - val_loss: 0.5874 - val_accuracy: 0.7560\n",
      "Epoch 108/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.8345 - accuracy: 0.7591 - val_loss: 0.5847 - val_accuracy: 0.7534\n",
      "Epoch 109/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.9997 - accuracy: 0.7440 - val_loss: 0.5899 - val_accuracy: 0.7572\n",
      "Epoch 110/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.9358 - accuracy: 0.7466 - val_loss: 0.6011 - val_accuracy: 0.7391\n",
      "Epoch 111/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8413 - accuracy: 0.7547 - val_loss: 0.5818 - val_accuracy: 0.7570\n",
      "Epoch 112/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.8241 - accuracy: 0.7601 - val_loss: 0.5860 - val_accuracy: 0.7565\n",
      "Epoch 113/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7841 - accuracy: 0.7623 - val_loss: 0.5803 - val_accuracy: 0.7597\n",
      "Epoch 114/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7982 - accuracy: 0.7614 - val_loss: 0.5754 - val_accuracy: 0.7651\n",
      "Epoch 115/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7647 - accuracy: 0.7638 - val_loss: 0.5745 - val_accuracy: 0.7639\n",
      "Epoch 116/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.7466 - accuracy: 0.7648 - val_loss: 0.5733 - val_accuracy: 0.7655\n",
      "Epoch 117/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.7515 - accuracy: 0.7656 - val_loss: 0.5714 - val_accuracy: 0.7663\n",
      "Epoch 118/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.7641 - accuracy: 0.7644 - val_loss: 0.5778 - val_accuracy: 0.7618\n",
      "Epoch 119/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.7741 - accuracy: 0.7618 - val_loss: 0.5739 - val_accuracy: 0.7651\n",
      "Epoch 120/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7425 - accuracy: 0.7632 - val_loss: 0.5689 - val_accuracy: 0.7688\n",
      "Epoch 121/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.7083 - accuracy: 0.7671 - val_loss: 0.5694 - val_accuracy: 0.7674\n",
      "Epoch 122/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.7206 - accuracy: 0.7650 - val_loss: 0.5682 - val_accuracy: 0.7687\n",
      "Epoch 123/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.7203 - accuracy: 0.7662 - val_loss: 0.5674 - val_accuracy: 0.7681\n",
      "Epoch 124/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.7034 - accuracy: 0.7669 - val_loss: 0.5842 - val_accuracy: 0.7547\n",
      "Epoch 125/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.7596 - accuracy: 0.7624 - val_loss: 0.5798 - val_accuracy: 0.7563\n",
      "Epoch 126/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 6.1643 - accuracy: 0.7313 - val_loss: 0.6412 - val_accuracy: 0.7034\n",
      "Epoch 127/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 6.0791 - accuracy: 0.7267 - val_loss: 0.5928 - val_accuracy: 0.7521\n",
      "Epoch 128/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8540 - accuracy: 0.7477 - val_loss: 0.5702 - val_accuracy: 0.7648\n",
      "Epoch 129/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7211 - accuracy: 0.7650 - val_loss: 0.5816 - val_accuracy: 0.7571\n",
      "Epoch 130/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.7108 - accuracy: 0.7657 - val_loss: 0.5790 - val_accuracy: 0.7587\n",
      "Epoch 131/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.7658 - accuracy: 0.7599 - val_loss: 0.5841 - val_accuracy: 0.7587\n",
      "Epoch 132/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.7256 - accuracy: 0.7603 - val_loss: 0.5801 - val_accuracy: 0.7596\n",
      "Epoch 133/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.6805 - accuracy: 0.7678 - val_loss: 0.5703 - val_accuracy: 0.7626\n",
      "Epoch 134/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.6482 - accuracy: 0.7702 - val_loss: 0.5659 - val_accuracy: 0.7668\n",
      "Epoch 135/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.6584 - accuracy: 0.7677 - val_loss: 0.5664 - val_accuracy: 0.7655\n",
      "Epoch 136/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7053 - accuracy: 0.7625 - val_loss: 0.6116 - val_accuracy: 0.7251\n",
      "Epoch 137/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.8976 - accuracy: 0.7461 - val_loss: 0.5888 - val_accuracy: 0.7509\n",
      "Epoch 138/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.6860 - accuracy: 0.7601 - val_loss: 0.5608 - val_accuracy: 0.7687\n",
      "Epoch 139/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.6063 - accuracy: 0.7713 - val_loss: 0.5608 - val_accuracy: 0.7713\n",
      "Epoch 140/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.5863 - accuracy: 0.7731 - val_loss: 0.5553 - val_accuracy: 0.7740\n",
      "Epoch 141/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.6056 - accuracy: 0.7719 - val_loss: 0.5704 - val_accuracy: 0.7662\n",
      "Epoch 142/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.8781 - accuracy: 0.7521 - val_loss: 0.6088 - val_accuracy: 0.7397\n",
      "Epoch 143/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.8252 - accuracy: 0.7468 - val_loss: 0.5929 - val_accuracy: 0.7371\n",
      "Epoch 144/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.7065 - accuracy: 0.7578 - val_loss: 0.5637 - val_accuracy: 0.7648\n",
      "Epoch 145/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.6674 - accuracy: 0.7651 - val_loss: 0.5705 - val_accuracy: 0.7623\n",
      "Epoch 146/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.6503 - accuracy: 0.7645 - val_loss: 0.5751 - val_accuracy: 0.7518\n",
      "Epoch 147/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.6620 - accuracy: 0.7637 - val_loss: 0.5635 - val_accuracy: 0.7661\n",
      "Epoch 148/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.5613 - accuracy: 0.7717 - val_loss: 0.5569 - val_accuracy: 0.7696\n",
      "Epoch 149/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.5276 - accuracy: 0.7758 - val_loss: 0.5517 - val_accuracy: 0.7753\n",
      "Epoch 150/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.5610 - accuracy: 0.7730 - val_loss: 0.5519 - val_accuracy: 0.7727\n",
      "Epoch 151/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.5242 - accuracy: 0.7729 - val_loss: 0.5557 - val_accuracy: 0.7705\n",
      "Epoch 152/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.5519 - accuracy: 0.7712 - val_loss: 0.5590 - val_accuracy: 0.7617\n",
      "Epoch 153/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.7331 - accuracy: 0.7550 - val_loss: 0.6089 - val_accuracy: 0.7203\n",
      "Epoch 154/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.8192 - accuracy: 0.7413 - val_loss: 0.5954 - val_accuracy: 0.7536\n",
      "Epoch 155/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.7800 - accuracy: 0.7463 - val_loss: 0.5905 - val_accuracy: 0.7365\n",
      "Epoch 156/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.6376 - accuracy: 0.7546 - val_loss: 0.5655 - val_accuracy: 0.7649\n",
      "Epoch 157/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.5664 - accuracy: 0.7627 - val_loss: 0.5731 - val_accuracy: 0.7596\n",
      "Epoch 158/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.5815 - accuracy: 0.7595 - val_loss: 0.5953 - val_accuracy: 0.7528\n",
      "Epoch 159/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.5334 - accuracy: 0.7620 - val_loss: 0.5501 - val_accuracy: 0.7726\n",
      "Epoch 160/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.5515 - accuracy: 0.7634 - val_loss: 0.5491 - val_accuracy: 0.7634\n",
      "Epoch 161/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.4905 - accuracy: 0.7649 - val_loss: 0.5448 - val_accuracy: 0.7678\n",
      "Epoch 162/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.4823 - accuracy: 0.7655 - val_loss: 0.5690 - val_accuracy: 0.7446\n",
      "Epoch 163/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.5695 - accuracy: 0.7593 - val_loss: 0.5582 - val_accuracy: 0.7574\n",
      "Epoch 164/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.4918 - accuracy: 0.7654 - val_loss: 0.5552 - val_accuracy: 0.7550\n",
      "Epoch 165/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.4031 - accuracy: 0.7694 - val_loss: 0.5363 - val_accuracy: 0.7694\n",
      "Epoch 166/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.3707 - accuracy: 0.7736 - val_loss: 0.5343 - val_accuracy: 0.7762\n",
      "Epoch 167/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.3292 - accuracy: 0.7810 - val_loss: 0.5412 - val_accuracy: 0.7787\n",
      "Epoch 168/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.3483 - accuracy: 0.7851 - val_loss: 0.5394 - val_accuracy: 0.7752\n",
      "Epoch 169/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.5975 - accuracy: 0.7703 - val_loss: 0.5619 - val_accuracy: 0.7547\n",
      "Epoch 170/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.4507 - accuracy: 0.7781 - val_loss: 0.5333 - val_accuracy: 0.7904\n",
      "Epoch 171/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.3289 - accuracy: 0.7914 - val_loss: 0.5335 - val_accuracy: 0.7909\n",
      "Epoch 172/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.3725 - accuracy: 0.7938 - val_loss: 0.5367 - val_accuracy: 0.7820\n",
      "Epoch 173/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.3579 - accuracy: 0.7929 - val_loss: 0.5405 - val_accuracy: 0.7813\n",
      "Epoch 174/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.4019 - accuracy: 0.7896 - val_loss: 0.5293 - val_accuracy: 0.7917\n",
      "Epoch 175/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 5.3784 - accuracy: 0.7928 - val_loss: 0.5283 - val_accuracy: 0.7937\n",
      "Epoch 176/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.3291 - accuracy: 0.7949 - val_loss: 0.5175 - val_accuracy: 0.8013\n",
      "Epoch 177/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.2957 - accuracy: 0.7988 - val_loss: 0.5240 - val_accuracy: 0.7978\n",
      "Epoch 178/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.2467 - accuracy: 0.8010 - val_loss: 0.5279 - val_accuracy: 0.7983\n",
      "Epoch 179/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.3083 - accuracy: 0.7981 - val_loss: 0.5259 - val_accuracy: 0.7974\n",
      "Epoch 180/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.3958 - accuracy: 0.7894 - val_loss: 0.5246 - val_accuracy: 0.7967\n",
      "Epoch 181/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.2629 - accuracy: 0.7993 - val_loss: 0.5211 - val_accuracy: 0.8000\n",
      "Epoch 182/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.2409 - accuracy: 0.8039 - val_loss: 0.5205 - val_accuracy: 0.8013\n",
      "Epoch 183/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.2610 - accuracy: 0.8011 - val_loss: 0.5535 - val_accuracy: 0.7715\n",
      "Epoch 184/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.4157 - accuracy: 0.7875 - val_loss: 0.5296 - val_accuracy: 0.7867\n",
      "Epoch 185/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.2443 - accuracy: 0.7996 - val_loss: 0.5153 - val_accuracy: 0.8003\n",
      "Epoch 186/3000\n",
      "10/10 [==============================] - ETA: 0s - loss: 5.2198 - accuracy: 0.80 - 1s 76ms/step - loss: 5.2198 - accuracy: 0.8027 - val_loss: 0.5202 - val_accuracy: 0.7963\n",
      "Epoch 187/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.2198 - accuracy: 0.8030 - val_loss: 0.5154 - val_accuracy: 0.8027\n",
      "Epoch 188/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.2864 - accuracy: 0.7986 - val_loss: 0.5357 - val_accuracy: 0.7952\n",
      "Epoch 189/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.2843 - accuracy: 0.7983 - val_loss: 0.5440 - val_accuracy: 0.7878\n",
      "Epoch 190/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.2547 - accuracy: 0.7992 - val_loss: 0.5266 - val_accuracy: 0.7975\n",
      "Epoch 191/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.1808 - accuracy: 0.8042 - val_loss: 0.5138 - val_accuracy: 0.8049\n",
      "Epoch 192/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.2086 - accuracy: 0.8036 - val_loss: 0.5163 - val_accuracy: 0.8025\n",
      "Epoch 193/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1574 - accuracy: 0.8070 - val_loss: 0.5164 - val_accuracy: 0.7995\n",
      "Epoch 194/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.2167 - accuracy: 0.8024 - val_loss: 0.5260 - val_accuracy: 0.7878\n",
      "Epoch 195/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.3483 - accuracy: 0.7915 - val_loss: 0.5370 - val_accuracy: 0.7797\n",
      "Epoch 196/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.2230 - accuracy: 0.7978 - val_loss: 0.5143 - val_accuracy: 0.7987\n",
      "Epoch 197/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.2049 - accuracy: 0.8032 - val_loss: 0.5185 - val_accuracy: 0.7997\n",
      "Epoch 198/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.2225 - accuracy: 0.8019 - val_loss: 0.5158 - val_accuracy: 0.7969\n",
      "Epoch 199/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.1807 - accuracy: 0.8034 - val_loss: 0.5075 - val_accuracy: 0.8035\n",
      "Epoch 200/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.1480 - accuracy: 0.8057 - val_loss: 0.5179 - val_accuracy: 0.7949\n",
      "Epoch 201/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.2919 - accuracy: 0.7945 - val_loss: 0.5257 - val_accuracy: 0.7884\n",
      "Epoch 202/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.1820 - accuracy: 0.8010 - val_loss: 0.5044 - val_accuracy: 0.8062\n",
      "Epoch 203/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.1944 - accuracy: 0.8016 - val_loss: 0.5051 - val_accuracy: 0.8060\n",
      "Epoch 204/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.1758 - accuracy: 0.8032 - val_loss: 0.5061 - val_accuracy: 0.8039\n",
      "Epoch 205/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.1032 - accuracy: 0.8079 - val_loss: 0.4991 - val_accuracy: 0.8099\n",
      "Epoch 206/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 5.0897 - accuracy: 0.8102 - val_loss: 0.5096 - val_accuracy: 0.8022\n",
      "Epoch 207/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.1423 - accuracy: 0.8068 - val_loss: 0.5077 - val_accuracy: 0.8047\n",
      "Epoch 208/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1220 - accuracy: 0.8053 - val_loss: 0.5154 - val_accuracy: 0.8026\n",
      "Epoch 209/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.0931 - accuracy: 0.8087 - val_loss: 0.5178 - val_accuracy: 0.8007\n",
      "Epoch 210/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1225 - accuracy: 0.8056 - val_loss: 0.5204 - val_accuracy: 0.8010\n",
      "Epoch 211/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.1192 - accuracy: 0.8051 - val_loss: 0.5012 - val_accuracy: 0.8099\n",
      "Epoch 212/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1072 - accuracy: 0.8071 - val_loss: 0.5099 - val_accuracy: 0.8010\n",
      "Epoch 213/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.2198 - accuracy: 0.7987 - val_loss: 0.5169 - val_accuracy: 0.8014\n",
      "Epoch 214/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 5.1685 - accuracy: 0.8001 - val_loss: 0.5012 - val_accuracy: 0.8081\n",
      "Epoch 215/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.0810 - accuracy: 0.8094 - val_loss: 0.5022 - val_accuracy: 0.8078\n",
      "Epoch 216/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.0671 - accuracy: 0.8095 - val_loss: 0.4946 - val_accuracy: 0.8108\n",
      "Epoch 217/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.0795 - accuracy: 0.8094 - val_loss: 0.5146 - val_accuracy: 0.8048\n",
      "Epoch 218/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.2067 - accuracy: 0.8009 - val_loss: 0.5133 - val_accuracy: 0.8002\n",
      "Epoch 219/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.1864 - accuracy: 0.8010 - val_loss: 0.5175 - val_accuracy: 0.7995\n",
      "Epoch 220/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1187 - accuracy: 0.8031 - val_loss: 0.5072 - val_accuracy: 0.8082\n",
      "Epoch 221/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.0321 - accuracy: 0.8099 - val_loss: 0.4967 - val_accuracy: 0.8116\n",
      "Epoch 222/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.9945 - accuracy: 0.8104 - val_loss: 0.4867 - val_accuracy: 0.8182\n",
      "Epoch 223/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 4.9063 - accuracy: 0.8139 - val_loss: 0.4824 - val_accuracy: 0.8193\n",
      "Epoch 224/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.8872 - accuracy: 0.8141 - val_loss: 0.4941 - val_accuracy: 0.8170\n",
      "Epoch 225/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.9471 - accuracy: 0.8126 - val_loss: 0.6095 - val_accuracy: 0.7409\n",
      "Epoch 226/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 6.3277 - accuracy: 0.7311 - val_loss: 0.6883 - val_accuracy: 0.7394\n",
      "Epoch 227/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 6.1107 - accuracy: 0.7464 - val_loss: 0.6367 - val_accuracy: 0.7360\n",
      "Epoch 228/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.6890 - accuracy: 0.7614 - val_loss: 0.5935 - val_accuracy: 0.7563\n",
      "Epoch 229/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.3879 - accuracy: 0.7828 - val_loss: 0.5359 - val_accuracy: 0.7918\n",
      "Epoch 230/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.2442 - accuracy: 0.7953 - val_loss: 0.5231 - val_accuracy: 0.7974\n",
      "Epoch 231/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.1664 - accuracy: 0.7996 - val_loss: 0.5173 - val_accuracy: 0.7986\n",
      "Epoch 232/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.1072 - accuracy: 0.8013 - val_loss: 0.5018 - val_accuracy: 0.8061\n",
      "Epoch 233/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 5.0574 - accuracy: 0.8064 - val_loss: 0.5082 - val_accuracy: 0.8010\n",
      "Epoch 234/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 5.0078 - accuracy: 0.8088 - val_loss: 0.5087 - val_accuracy: 0.8010\n",
      "Epoch 235/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.9808 - accuracy: 0.8105 - val_loss: 0.4895 - val_accuracy: 0.8107\n",
      "Epoch 236/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.9682 - accuracy: 0.8103 - val_loss: 0.4883 - val_accuracy: 0.8127\n",
      "Epoch 237/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.9499 - accuracy: 0.8103 - val_loss: 0.4764 - val_accuracy: 0.8171\n",
      "Epoch 238/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.9025 - accuracy: 0.8099 - val_loss: 0.4661 - val_accuracy: 0.8203\n",
      "Epoch 239/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.8403 - accuracy: 0.8140 - val_loss: 0.4848 - val_accuracy: 0.8134\n",
      "Epoch 240/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.7652 - accuracy: 0.8189 - val_loss: 0.4796 - val_accuracy: 0.8097\n",
      "Epoch 241/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.6763 - accuracy: 0.8211 - val_loss: 0.4681 - val_accuracy: 0.8183\n",
      "Epoch 242/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.5964 - accuracy: 0.8259 - val_loss: 0.4535 - val_accuracy: 0.8263\n",
      "Epoch 243/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.6206 - accuracy: 0.8209 - val_loss: 0.4510 - val_accuracy: 0.8296\n",
      "Epoch 244/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 5.1602 - accuracy: 0.7928 - val_loss: 0.5059 - val_accuracy: 0.7897\n",
      "Epoch 245/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 5.1934 - accuracy: 0.7916 - val_loss: 0.5657 - val_accuracy: 0.7616\n",
      "Epoch 246/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.8121 - accuracy: 0.8079 - val_loss: 0.4687 - val_accuracy: 0.8180\n",
      "Epoch 247/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.5722 - accuracy: 0.8191 - val_loss: 0.4319 - val_accuracy: 0.8331\n",
      "Epoch 248/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.4909 - accuracy: 0.8249 - val_loss: 0.4665 - val_accuracy: 0.8111\n",
      "Epoch 249/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.5332 - accuracy: 0.8230 - val_loss: 0.5234 - val_accuracy: 0.7902\n",
      "Epoch 250/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.8342 - accuracy: 0.8020 - val_loss: 0.5210 - val_accuracy: 0.7736\n",
      "Epoch 251/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.6469 - accuracy: 0.8146 - val_loss: 0.4537 - val_accuracy: 0.8204\n",
      "Epoch 252/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.4283 - accuracy: 0.8256 - val_loss: 0.4297 - val_accuracy: 0.8347\n",
      "Epoch 253/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3465 - accuracy: 0.8313 - val_loss: 0.4413 - val_accuracy: 0.8258\n",
      "Epoch 254/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.4039 - accuracy: 0.8261 - val_loss: 0.4148 - val_accuracy: 0.8416\n",
      "Epoch 255/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.4724 - accuracy: 0.8263 - val_loss: 0.5291 - val_accuracy: 0.7672\n",
      "Epoch 256/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.9006 - accuracy: 0.8005 - val_loss: 0.5128 - val_accuracy: 0.7782\n",
      "Epoch 257/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.5428 - accuracy: 0.8193 - val_loss: 0.4466 - val_accuracy: 0.8250\n",
      "Epoch 258/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.3484 - accuracy: 0.8298 - val_loss: 0.4223 - val_accuracy: 0.8365\n",
      "Epoch 259/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3193 - accuracy: 0.8305 - val_loss: 0.4335 - val_accuracy: 0.8297\n",
      "Epoch 260/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.3490 - accuracy: 0.8297 - val_loss: 0.5494 - val_accuracy: 0.7580\n",
      "Epoch 261/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.6368 - accuracy: 0.8108 - val_loss: 0.4232 - val_accuracy: 0.8360\n",
      "Epoch 262/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.4622 - accuracy: 0.8245 - val_loss: 0.4180 - val_accuracy: 0.8423\n",
      "Epoch 263/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 4.3260 - accuracy: 0.8307 - val_loss: 0.4219 - val_accuracy: 0.8381\n",
      "Epoch 264/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 4.3495 - accuracy: 0.8298 - val_loss: 0.4185 - val_accuracy: 0.8383\n",
      "Epoch 265/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.2255 - accuracy: 0.8359 - val_loss: 0.4210 - val_accuracy: 0.8347\n",
      "Epoch 266/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.5135 - accuracy: 0.8207 - val_loss: 0.5811 - val_accuracy: 0.7472\n",
      "Epoch 267/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.4351 - accuracy: 0.8210 - val_loss: 0.4250 - val_accuracy: 0.8350\n",
      "Epoch 268/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3238 - accuracy: 0.8299 - val_loss: 0.4092 - val_accuracy: 0.8435\n",
      "Epoch 269/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.2083 - accuracy: 0.8354 - val_loss: 0.4113 - val_accuracy: 0.8407\n",
      "Epoch 270/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1841 - accuracy: 0.8362 - val_loss: 0.4015 - val_accuracy: 0.8463\n",
      "Epoch 271/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1823 - accuracy: 0.8386 - val_loss: 0.4045 - val_accuracy: 0.8451\n",
      "Epoch 272/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3141 - accuracy: 0.8303 - val_loss: 0.4732 - val_accuracy: 0.8087\n",
      "Epoch 273/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.4470 - accuracy: 0.8200 - val_loss: 0.4198 - val_accuracy: 0.8402\n",
      "Epoch 274/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.2316 - accuracy: 0.8353 - val_loss: 0.4282 - val_accuracy: 0.8301\n",
      "Epoch 275/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1373 - accuracy: 0.8388 - val_loss: 0.4327 - val_accuracy: 0.8256\n",
      "Epoch 276/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1741 - accuracy: 0.8363 - val_loss: 0.4085 - val_accuracy: 0.8414\n",
      "Epoch 277/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.1626 - accuracy: 0.8394 - val_loss: 0.5264 - val_accuracy: 0.7825\n",
      "Epoch 278/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.5442 - accuracy: 0.8142 - val_loss: 0.4087 - val_accuracy: 0.8434\n",
      "Epoch 279/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3923 - accuracy: 0.8258 - val_loss: 0.4129 - val_accuracy: 0.8432\n",
      "Epoch 280/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.2037 - accuracy: 0.8357 - val_loss: 0.4151 - val_accuracy: 0.8391\n",
      "Epoch 281/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1404 - accuracy: 0.8397 - val_loss: 0.4090 - val_accuracy: 0.8411\n",
      "Epoch 282/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.2027 - accuracy: 0.8343 - val_loss: 0.4140 - val_accuracy: 0.8414\n",
      "Epoch 283/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.2438 - accuracy: 0.8318 - val_loss: 0.4057 - val_accuracy: 0.8446\n",
      "Epoch 284/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.2090 - accuracy: 0.8381 - val_loss: 0.4587 - val_accuracy: 0.8088\n",
      "Epoch 285/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.1016 - accuracy: 0.8399 - val_loss: 0.4110 - val_accuracy: 0.8392\n",
      "Epoch 286/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1206 - accuracy: 0.8396 - val_loss: 0.4006 - val_accuracy: 0.8452\n",
      "Epoch 287/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.2276 - accuracy: 0.8314 - val_loss: 0.4127 - val_accuracy: 0.8432\n",
      "Epoch 288/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.2184 - accuracy: 0.8364 - val_loss: 0.4558 - val_accuracy: 0.8115\n",
      "Epoch 289/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.1190 - accuracy: 0.8393 - val_loss: 0.4236 - val_accuracy: 0.8311\n",
      "Epoch 290/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1184 - accuracy: 0.8379 - val_loss: 0.4014 - val_accuracy: 0.8451\n",
      "Epoch 291/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0644 - accuracy: 0.8413 - val_loss: 0.4063 - val_accuracy: 0.8414\n",
      "Epoch 292/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0505 - accuracy: 0.8435 - val_loss: 0.4038 - val_accuracy: 0.8434\n",
      "Epoch 293/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1616 - accuracy: 0.8360 - val_loss: 0.4049 - val_accuracy: 0.8428\n",
      "Epoch 294/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0893 - accuracy: 0.8398 - val_loss: 0.4019 - val_accuracy: 0.8454\n",
      "Epoch 295/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1566 - accuracy: 0.8354 - val_loss: 0.4012 - val_accuracy: 0.8456\n",
      "Epoch 296/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1435 - accuracy: 0.8406 - val_loss: 0.4474 - val_accuracy: 0.8163\n",
      "Epoch 297/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0997 - accuracy: 0.8401 - val_loss: 0.4405 - val_accuracy: 0.8221\n",
      "Epoch 298/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0666 - accuracy: 0.8413 - val_loss: 0.4073 - val_accuracy: 0.8406\n",
      "Epoch 299/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0824 - accuracy: 0.8412 - val_loss: 0.4221 - val_accuracy: 0.8307\n",
      "Epoch 300/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1717 - accuracy: 0.8358 - val_loss: 0.4004 - val_accuracy: 0.8479\n",
      "Epoch 301/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.3280 - accuracy: 0.8288 - val_loss: 0.4969 - val_accuracy: 0.7974\n",
      "Epoch 302/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 4.2010 - accuracy: 0.8344 - val_loss: 0.4387 - val_accuracy: 0.8239\n",
      "Epoch 303/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.0676 - accuracy: 0.8421 - val_loss: 0.3997 - val_accuracy: 0.8452\n",
      "Epoch 304/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.0032 - accuracy: 0.8468 - val_loss: 0.3927 - val_accuracy: 0.8490\n",
      "Epoch 305/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0002 - accuracy: 0.8465 - val_loss: 0.4444 - val_accuracy: 0.8146\n",
      "Epoch 306/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0394 - accuracy: 0.8426 - val_loss: 0.4316 - val_accuracy: 0.8245\n",
      "Epoch 307/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1763 - accuracy: 0.8366 - val_loss: 0.4850 - val_accuracy: 0.7949\n",
      "Epoch 308/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.3345 - accuracy: 0.8263 - val_loss: 0.4002 - val_accuracy: 0.8457\n",
      "Epoch 309/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1410 - accuracy: 0.8392 - val_loss: 0.4038 - val_accuracy: 0.8460\n",
      "Epoch 310/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1225 - accuracy: 0.8419 - val_loss: 0.4547 - val_accuracy: 0.8139\n",
      "Epoch 311/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0604 - accuracy: 0.8412 - val_loss: 0.3916 - val_accuracy: 0.8500\n",
      "Epoch 312/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1062 - accuracy: 0.8428 - val_loss: 0.5317 - val_accuracy: 0.7696\n",
      "Epoch 313/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.2429 - accuracy: 0.8294 - val_loss: 0.3947 - val_accuracy: 0.8479\n",
      "Epoch 314/3000\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 4.0886 - accuracy: 0.8430 - val_loss: 0.4014 - val_accuracy: 0.8453\n",
      "Epoch 315/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.1020 - accuracy: 0.8388 - val_loss: 0.3949 - val_accuracy: 0.8475\n",
      "Epoch 316/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0533 - accuracy: 0.8448 - val_loss: 0.4361 - val_accuracy: 0.8242\n",
      "Epoch 317/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.0164 - accuracy: 0.8445 - val_loss: 0.4089 - val_accuracy: 0.8392\n",
      "Epoch 318/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9912 - accuracy: 0.8468 - val_loss: 0.3975 - val_accuracy: 0.8465\n",
      "Epoch 319/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0429 - accuracy: 0.8426 - val_loss: 0.3881 - val_accuracy: 0.8521\n",
      "Epoch 320/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0099 - accuracy: 0.8466 - val_loss: 0.3930 - val_accuracy: 0.8482\n",
      "Epoch 321/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9320 - accuracy: 0.8503 - val_loss: 0.3988 - val_accuracy: 0.8429\n",
      "Epoch 322/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9340 - accuracy: 0.8482 - val_loss: 0.3894 - val_accuracy: 0.8504\n",
      "Epoch 323/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.0528 - accuracy: 0.8435 - val_loss: 0.3851 - val_accuracy: 0.8516\n",
      "Epoch 324/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0021 - accuracy: 0.8457 - val_loss: 0.3813 - val_accuracy: 0.8551\n",
      "Epoch 325/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9607 - accuracy: 0.8492 - val_loss: 0.3905 - val_accuracy: 0.8490\n",
      "Epoch 326/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1178 - accuracy: 0.8393 - val_loss: 0.4078 - val_accuracy: 0.8403\n",
      "Epoch 327/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.0284 - accuracy: 0.8450 - val_loss: 0.4160 - val_accuracy: 0.8356\n",
      "Epoch 328/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9280 - accuracy: 0.8494 - val_loss: 0.3834 - val_accuracy: 0.8547\n",
      "Epoch 329/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1411 - accuracy: 0.8389 - val_loss: 0.3972 - val_accuracy: 0.8457\n",
      "Epoch 330/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0098 - accuracy: 0.8466 - val_loss: 0.4375 - val_accuracy: 0.8227\n",
      "Epoch 331/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9748 - accuracy: 0.8465 - val_loss: 0.4066 - val_accuracy: 0.8406\n",
      "Epoch 332/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0459 - accuracy: 0.8418 - val_loss: 0.3968 - val_accuracy: 0.8482\n",
      "Epoch 333/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.9331 - accuracy: 0.8495 - val_loss: 0.3880 - val_accuracy: 0.8495\n",
      "Epoch 334/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9278 - accuracy: 0.8501 - val_loss: 0.4032 - val_accuracy: 0.8413\n",
      "Epoch 335/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9912 - accuracy: 0.8456 - val_loss: 0.3984 - val_accuracy: 0.8442\n",
      "Epoch 336/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1588 - accuracy: 0.8345 - val_loss: 0.3945 - val_accuracy: 0.8500\n",
      "Epoch 337/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0429 - accuracy: 0.8453 - val_loss: 0.4250 - val_accuracy: 0.8333\n",
      "Epoch 338/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9657 - accuracy: 0.8471 - val_loss: 0.3879 - val_accuracy: 0.8509\n",
      "Epoch 339/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.9694 - accuracy: 0.8480 - val_loss: 0.3913 - val_accuracy: 0.8492\n",
      "Epoch 340/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1095 - accuracy: 0.8400 - val_loss: 0.4169 - val_accuracy: 0.8354\n",
      "Epoch 341/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 4.0284 - accuracy: 0.8431 - val_loss: 0.3862 - val_accuracy: 0.8543\n",
      "Epoch 342/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9507 - accuracy: 0.8497 - val_loss: 0.4265 - val_accuracy: 0.8299\n",
      "Epoch 343/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9038 - accuracy: 0.8510 - val_loss: 0.3898 - val_accuracy: 0.8490\n",
      "Epoch 344/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9252 - accuracy: 0.8493 - val_loss: 0.3823 - val_accuracy: 0.8523\n",
      "Epoch 345/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1423 - accuracy: 0.8402 - val_loss: 0.4403 - val_accuracy: 0.8249\n",
      "Epoch 346/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9997 - accuracy: 0.8441 - val_loss: 0.3778 - val_accuracy: 0.8562\n",
      "Epoch 347/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0454 - accuracy: 0.8447 - val_loss: 0.4205 - val_accuracy: 0.8319\n",
      "Epoch 348/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0326 - accuracy: 0.8447 - val_loss: 0.4099 - val_accuracy: 0.8379\n",
      "Epoch 349/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9058 - accuracy: 0.8501 - val_loss: 0.3838 - val_accuracy: 0.8533\n",
      "Epoch 350/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9639 - accuracy: 0.8473 - val_loss: 0.3757 - val_accuracy: 0.8570\n",
      "Epoch 351/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9463 - accuracy: 0.8490 - val_loss: 0.3867 - val_accuracy: 0.8500\n",
      "Epoch 352/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9256 - accuracy: 0.8508 - val_loss: 0.4498 - val_accuracy: 0.8214\n",
      "Epoch 353/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0167 - accuracy: 0.8441 - val_loss: 0.3862 - val_accuracy: 0.8534\n",
      "Epoch 354/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9415 - accuracy: 0.8493 - val_loss: 0.3938 - val_accuracy: 0.8466\n",
      "Epoch 355/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9119 - accuracy: 0.8515 - val_loss: 0.4396 - val_accuracy: 0.8252\n",
      "Epoch 356/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9739 - accuracy: 0.8464 - val_loss: 0.3889 - val_accuracy: 0.8494\n",
      "Epoch 357/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9423 - accuracy: 0.8472 - val_loss: 0.3906 - val_accuracy: 0.8488\n",
      "Epoch 358/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0883 - accuracy: 0.8440 - val_loss: 0.4565 - val_accuracy: 0.8148\n",
      "Epoch 359/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9252 - accuracy: 0.8487 - val_loss: 0.3888 - val_accuracy: 0.8503\n",
      "Epoch 360/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8572 - accuracy: 0.8541 - val_loss: 0.3826 - val_accuracy: 0.8517\n",
      "Epoch 361/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.8643 - accuracy: 0.8534 - val_loss: 0.4091 - val_accuracy: 0.8354\n",
      "Epoch 362/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8546 - accuracy: 0.8529 - val_loss: 0.3794 - val_accuracy: 0.8540\n",
      "Epoch 363/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.8820 - accuracy: 0.8524 - val_loss: 0.3812 - val_accuracy: 0.8527\n",
      "Epoch 364/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8909 - accuracy: 0.8507 - val_loss: 0.3814 - val_accuracy: 0.8522\n",
      "Epoch 365/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.8478 - accuracy: 0.8545 - val_loss: 0.3876 - val_accuracy: 0.8495\n",
      "Epoch 366/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9113 - accuracy: 0.8508 - val_loss: 0.3891 - val_accuracy: 0.8484\n",
      "Epoch 367/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0631 - accuracy: 0.8400 - val_loss: 0.3845 - val_accuracy: 0.8524\n",
      "Epoch 368/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9129 - accuracy: 0.8517 - val_loss: 0.4211 - val_accuracy: 0.8321\n",
      "Epoch 369/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8716 - accuracy: 0.8529 - val_loss: 0.3904 - val_accuracy: 0.8482\n",
      "Epoch 370/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8722 - accuracy: 0.8521 - val_loss: 0.3947 - val_accuracy: 0.8456\n",
      "Epoch 371/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8659 - accuracy: 0.8529 - val_loss: 0.4269 - val_accuracy: 0.8298\n",
      "Epoch 372/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8986 - accuracy: 0.8508 - val_loss: 0.4341 - val_accuracy: 0.8234\n",
      "Epoch 373/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9158 - accuracy: 0.8500 - val_loss: 0.4165 - val_accuracy: 0.8339\n",
      "Epoch 374/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8735 - accuracy: 0.8522 - val_loss: 0.3804 - val_accuracy: 0.8541\n",
      "Epoch 375/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8388 - accuracy: 0.8536 - val_loss: 0.3722 - val_accuracy: 0.8578\n",
      "Epoch 376/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8970 - accuracy: 0.8515 - val_loss: 0.3733 - val_accuracy: 0.8581\n",
      "Epoch 377/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9507 - accuracy: 0.8490 - val_loss: 0.3702 - val_accuracy: 0.8585\n",
      "Epoch 378/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9482 - accuracy: 0.8507 - val_loss: 0.4139 - val_accuracy: 0.8363\n",
      "Epoch 379/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9211 - accuracy: 0.8504 - val_loss: 0.3905 - val_accuracy: 0.8497\n",
      "Epoch 380/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1896 - accuracy: 0.8365 - val_loss: 0.5107 - val_accuracy: 0.7852\n",
      "Epoch 381/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.1320 - accuracy: 0.8371 - val_loss: 0.4067 - val_accuracy: 0.8447\n",
      "Epoch 382/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9440 - accuracy: 0.8494 - val_loss: 0.3849 - val_accuracy: 0.8537\n",
      "Epoch 383/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.8819 - accuracy: 0.8519 - val_loss: 0.3685 - val_accuracy: 0.8594\n",
      "Epoch 384/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8257 - accuracy: 0.8560 - val_loss: 0.3797 - val_accuracy: 0.8534\n",
      "Epoch 385/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8281 - accuracy: 0.8550 - val_loss: 0.3809 - val_accuracy: 0.8537\n",
      "Epoch 386/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9237 - accuracy: 0.8482 - val_loss: 0.3783 - val_accuracy: 0.8564\n",
      "Epoch 387/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8973 - accuracy: 0.8529 - val_loss: 0.4363 - val_accuracy: 0.8238\n",
      "Epoch 388/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9321 - accuracy: 0.8488 - val_loss: 0.3955 - val_accuracy: 0.8451\n",
      "Epoch 389/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8142 - accuracy: 0.8547 - val_loss: 0.3907 - val_accuracy: 0.8480\n",
      "Epoch 390/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8047 - accuracy: 0.8568 - val_loss: 0.4381 - val_accuracy: 0.8255\n",
      "Epoch 391/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8370 - accuracy: 0.8537 - val_loss: 0.3774 - val_accuracy: 0.8553\n",
      "Epoch 392/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8808 - accuracy: 0.8512 - val_loss: 0.3657 - val_accuracy: 0.8609\n",
      "Epoch 393/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9603 - accuracy: 0.8494 - val_loss: 0.4454 - val_accuracy: 0.8225\n",
      "Epoch 394/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.2125 - accuracy: 0.8328 - val_loss: 0.3765 - val_accuracy: 0.8566\n",
      "Epoch 395/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0580 - accuracy: 0.8459 - val_loss: 0.3793 - val_accuracy: 0.8554\n",
      "Epoch 396/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8997 - accuracy: 0.8512 - val_loss: 0.3733 - val_accuracy: 0.8584\n",
      "Epoch 397/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8457 - accuracy: 0.8539 - val_loss: 0.3723 - val_accuracy: 0.8573\n",
      "Epoch 398/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8281 - accuracy: 0.8561 - val_loss: 0.3899 - val_accuracy: 0.8475\n",
      "Epoch 399/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8526 - accuracy: 0.8535 - val_loss: 0.4103 - val_accuracy: 0.8349\n",
      "Epoch 400/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8144 - accuracy: 0.8549 - val_loss: 0.3807 - val_accuracy: 0.8529\n",
      "Epoch 401/3000\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.8452 - accuracy: 0.85 - 1s 75ms/step - loss: 3.8452 - accuracy: 0.8542 - val_loss: 0.3793 - val_accuracy: 0.8538\n",
      "Epoch 402/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.8327 - accuracy: 0.8535 - val_loss: 0.3696 - val_accuracy: 0.8596\n",
      "Epoch 403/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 3.7747 - accuracy: 0.8585 - val_loss: 0.4166 - val_accuracy: 0.8325\n",
      "Epoch 404/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8502 - accuracy: 0.8535 - val_loss: 0.4216 - val_accuracy: 0.8313\n",
      "Epoch 405/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8703 - accuracy: 0.8518 - val_loss: 0.3840 - val_accuracy: 0.8509\n",
      "Epoch 406/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7981 - accuracy: 0.8560 - val_loss: 0.3655 - val_accuracy: 0.8612\n",
      "Epoch 407/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7688 - accuracy: 0.8588 - val_loss: 0.3746 - val_accuracy: 0.8565\n",
      "Epoch 408/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7752 - accuracy: 0.8576 - val_loss: 0.3760 - val_accuracy: 0.8554\n",
      "Epoch 409/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8125 - accuracy: 0.8560 - val_loss: 0.3881 - val_accuracy: 0.8491\n",
      "Epoch 410/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8056 - accuracy: 0.8548 - val_loss: 0.3625 - val_accuracy: 0.8622\n",
      "Epoch 411/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8408 - accuracy: 0.8535 - val_loss: 0.3637 - val_accuracy: 0.8619\n",
      "Epoch 412/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8958 - accuracy: 0.8527 - val_loss: 0.4497 - val_accuracy: 0.8180\n",
      "Epoch 413/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9720 - accuracy: 0.8451 - val_loss: 0.3695 - val_accuracy: 0.8594\n",
      "Epoch 414/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7811 - accuracy: 0.8580 - val_loss: 0.3828 - val_accuracy: 0.8520\n",
      "Epoch 415/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7568 - accuracy: 0.8576 - val_loss: 0.3677 - val_accuracy: 0.8594\n",
      "Epoch 416/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8569 - accuracy: 0.8516 - val_loss: 0.3743 - val_accuracy: 0.8557\n",
      "Epoch 417/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.2139 - accuracy: 0.8375 - val_loss: 0.3916 - val_accuracy: 0.8498\n",
      "Epoch 418/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0526 - accuracy: 0.8429 - val_loss: 0.3704 - val_accuracy: 0.8595\n",
      "Epoch 419/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9075 - accuracy: 0.8520 - val_loss: 0.4062 - val_accuracy: 0.8410\n",
      "Epoch 420/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8459 - accuracy: 0.8530 - val_loss: 0.3667 - val_accuracy: 0.8605\n",
      "Epoch 421/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.8000 - accuracy: 0.8575 - val_loss: 0.3965 - val_accuracy: 0.8455\n",
      "Epoch 422/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7766 - accuracy: 0.8577 - val_loss: 0.3768 - val_accuracy: 0.8541\n",
      "Epoch 423/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7553 - accuracy: 0.8580 - val_loss: 0.3638 - val_accuracy: 0.8617\n",
      "Epoch 424/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7555 - accuracy: 0.8586 - val_loss: 0.3665 - val_accuracy: 0.8603\n",
      "Epoch 425/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7591 - accuracy: 0.8585 - val_loss: 0.3626 - val_accuracy: 0.8618\n",
      "Epoch 426/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7492 - accuracy: 0.8591 - val_loss: 0.3690 - val_accuracy: 0.8590\n",
      "Epoch 427/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7660 - accuracy: 0.8577 - val_loss: 0.3646 - val_accuracy: 0.8610\n",
      "Epoch 428/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8379 - accuracy: 0.8554 - val_loss: 0.4465 - val_accuracy: 0.8178\n",
      "Epoch 429/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9484 - accuracy: 0.8467 - val_loss: 0.3724 - val_accuracy: 0.8577\n",
      "Epoch 430/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7604 - accuracy: 0.8593 - val_loss: 0.3796 - val_accuracy: 0.8537\n",
      "Epoch 431/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7931 - accuracy: 0.8561 - val_loss: 0.3819 - val_accuracy: 0.8526\n",
      "Epoch 432/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7886 - accuracy: 0.8564 - val_loss: 0.3900 - val_accuracy: 0.8478\n",
      "Epoch 433/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8611 - accuracy: 0.8521 - val_loss: 0.4003 - val_accuracy: 0.8445\n",
      "Epoch 434/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8949 - accuracy: 0.8524 - val_loss: 0.4313 - val_accuracy: 0.8273\n",
      "Epoch 435/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7851 - accuracy: 0.8562 - val_loss: 0.3949 - val_accuracy: 0.8451\n",
      "Epoch 436/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7733 - accuracy: 0.8577 - val_loss: 0.4251 - val_accuracy: 0.8309\n",
      "Epoch 437/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8723 - accuracy: 0.8510 - val_loss: 0.3688 - val_accuracy: 0.8594\n",
      "Epoch 438/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8570 - accuracy: 0.8520 - val_loss: 0.3650 - val_accuracy: 0.8609\n",
      "Epoch 439/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8739 - accuracy: 0.8535 - val_loss: 0.4018 - val_accuracy: 0.8416\n",
      "Epoch 440/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7910 - accuracy: 0.8555 - val_loss: 0.3790 - val_accuracy: 0.8543\n",
      "Epoch 441/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8449 - accuracy: 0.8546 - val_loss: 0.4163 - val_accuracy: 0.8355\n",
      "Epoch 442/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7477 - accuracy: 0.8587 - val_loss: 0.3810 - val_accuracy: 0.8523\n",
      "Epoch 443/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7073 - accuracy: 0.8596 - val_loss: 0.3593 - val_accuracy: 0.8638\n",
      "Epoch 444/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7420 - accuracy: 0.8595 - val_loss: 0.3909 - val_accuracy: 0.8460\n",
      "Epoch 445/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7203 - accuracy: 0.8599 - val_loss: 0.4033 - val_accuracy: 0.8391\n",
      "Epoch 446/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7425 - accuracy: 0.8589 - val_loss: 0.4196 - val_accuracy: 0.8312\n",
      "Epoch 447/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9180 - accuracy: 0.8479 - val_loss: 0.3741 - val_accuracy: 0.8561\n",
      "Epoch 448/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1742 - accuracy: 0.8376 - val_loss: 0.4161 - val_accuracy: 0.8372\n",
      "Epoch 449/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8616 - accuracy: 0.8530 - val_loss: 0.4282 - val_accuracy: 0.8312\n",
      "Epoch 450/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7963 - accuracy: 0.8567 - val_loss: 0.3674 - val_accuracy: 0.8606\n",
      "Epoch 451/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7434 - accuracy: 0.8589 - val_loss: 0.3675 - val_accuracy: 0.8593\n",
      "Epoch 452/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7085 - accuracy: 0.8612 - val_loss: 0.3774 - val_accuracy: 0.8534\n",
      "Epoch 453/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7465 - accuracy: 0.8581 - val_loss: 0.3595 - val_accuracy: 0.8636\n",
      "Epoch 454/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7245 - accuracy: 0.8606 - val_loss: 0.3669 - val_accuracy: 0.8599\n",
      "Epoch 455/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7052 - accuracy: 0.8615 - val_loss: 0.3848 - val_accuracy: 0.8494\n",
      "Epoch 456/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6854 - accuracy: 0.8611 - val_loss: 0.3658 - val_accuracy: 0.8601\n",
      "Epoch 457/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7690 - accuracy: 0.8568 - val_loss: 0.3615 - val_accuracy: 0.8619\n",
      "Epoch 458/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7173 - accuracy: 0.8610 - val_loss: 0.3965 - val_accuracy: 0.8426\n",
      "Epoch 459/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7295 - accuracy: 0.8589 - val_loss: 0.3591 - val_accuracy: 0.8634\n",
      "Epoch 460/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7246 - accuracy: 0.8596 - val_loss: 0.3597 - val_accuracy: 0.8634\n",
      "Epoch 461/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8295 - accuracy: 0.8550 - val_loss: 0.3890 - val_accuracy: 0.8485\n",
      "Epoch 462/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7865 - accuracy: 0.8559 - val_loss: 0.3653 - val_accuracy: 0.8606\n",
      "Epoch 463/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7922 - accuracy: 0.8564 - val_loss: 0.3664 - val_accuracy: 0.8605\n",
      "Epoch 464/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7176 - accuracy: 0.8614 - val_loss: 0.3674 - val_accuracy: 0.8597\n",
      "Epoch 465/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7027 - accuracy: 0.8611 - val_loss: 0.3768 - val_accuracy: 0.8537\n",
      "Epoch 466/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6805 - accuracy: 0.8620 - val_loss: 0.3652 - val_accuracy: 0.8609\n",
      "Epoch 467/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6877 - accuracy: 0.8623 - val_loss: 0.3924 - val_accuracy: 0.8451\n",
      "Epoch 468/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7950 - accuracy: 0.8563 - val_loss: 0.3972 - val_accuracy: 0.8430\n",
      "Epoch 469/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6839 - accuracy: 0.8621 - val_loss: 0.3715 - val_accuracy: 0.8566\n",
      "Epoch 470/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7887 - accuracy: 0.8569 - val_loss: 0.4234 - val_accuracy: 0.8313\n",
      "Epoch 471/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8758 - accuracy: 0.8511 - val_loss: 0.3670 - val_accuracy: 0.8612\n",
      "Epoch 472/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.1625 - accuracy: 0.8385 - val_loss: 0.5244 - val_accuracy: 0.7877\n",
      "Epoch 473/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0464 - accuracy: 0.8423 - val_loss: 0.4213 - val_accuracy: 0.8357\n",
      "Epoch 474/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8903 - accuracy: 0.8508 - val_loss: 0.3963 - val_accuracy: 0.8451\n",
      "Epoch 475/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7960 - accuracy: 0.8566 - val_loss: 0.3905 - val_accuracy: 0.8468\n",
      "Epoch 476/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6936 - accuracy: 0.8612 - val_loss: 0.3671 - val_accuracy: 0.8583\n",
      "Epoch 477/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7002 - accuracy: 0.8607 - val_loss: 0.3599 - val_accuracy: 0.8627\n",
      "Epoch 478/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6703 - accuracy: 0.8631 - val_loss: 0.3810 - val_accuracy: 0.8509\n",
      "Epoch 479/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6579 - accuracy: 0.8634 - val_loss: 0.3954 - val_accuracy: 0.8427\n",
      "Epoch 480/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7504 - accuracy: 0.8575 - val_loss: 0.3721 - val_accuracy: 0.8561\n",
      "Epoch 481/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7211 - accuracy: 0.8607 - val_loss: 0.4352 - val_accuracy: 0.8280\n",
      "Epoch 482/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9404 - accuracy: 0.8457 - val_loss: 0.3733 - val_accuracy: 0.8570\n",
      "Epoch 483/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.9930 - accuracy: 0.8475 - val_loss: 0.3722 - val_accuracy: 0.8595\n",
      "Epoch 484/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7921 - accuracy: 0.8579 - val_loss: 0.3795 - val_accuracy: 0.8534\n",
      "Epoch 485/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7400 - accuracy: 0.8584 - val_loss: 0.3615 - val_accuracy: 0.8625\n",
      "Epoch 486/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6851 - accuracy: 0.8629 - val_loss: 0.3931 - val_accuracy: 0.8454\n",
      "Epoch 487/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7261 - accuracy: 0.8594 - val_loss: 0.3989 - val_accuracy: 0.8439\n",
      "Epoch 488/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7960 - accuracy: 0.8549 - val_loss: 0.3624 - val_accuracy: 0.8620\n",
      "Epoch 489/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7797 - accuracy: 0.8560 - val_loss: 0.3619 - val_accuracy: 0.8613\n",
      "Epoch 490/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6649 - accuracy: 0.8640 - val_loss: 0.4029 - val_accuracy: 0.8410\n",
      "Epoch 491/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7255 - accuracy: 0.8593 - val_loss: 0.3754 - val_accuracy: 0.8542\n",
      "Epoch 492/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6569 - accuracy: 0.8632 - val_loss: 0.3729 - val_accuracy: 0.8558\n",
      "Epoch 493/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6658 - accuracy: 0.8627 - val_loss: 0.3764 - val_accuracy: 0.8526\n",
      "Epoch 494/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6590 - accuracy: 0.8626 - val_loss: 0.3610 - val_accuracy: 0.8611\n",
      "Epoch 495/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8796 - accuracy: 0.8497 - val_loss: 0.4000 - val_accuracy: 0.8426\n",
      "Epoch 496/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 4.0546 - accuracy: 0.8425 - val_loss: 0.3744 - val_accuracy: 0.8584\n",
      "Epoch 497/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8117 - accuracy: 0.8573 - val_loss: 0.3774 - val_accuracy: 0.8549\n",
      "Epoch 498/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6686 - accuracy: 0.8629 - val_loss: 0.3541 - val_accuracy: 0.8655\n",
      "Epoch 499/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6541 - accuracy: 0.8644 - val_loss: 0.3734 - val_accuracy: 0.8550\n",
      "Epoch 500/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6710 - accuracy: 0.8618 - val_loss: 0.3923 - val_accuracy: 0.8451\n",
      "Epoch 501/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7499 - accuracy: 0.8585 - val_loss: 0.4320 - val_accuracy: 0.8232\n",
      "Epoch 502/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7107 - accuracy: 0.8583 - val_loss: 0.3622 - val_accuracy: 0.8620\n",
      "Epoch 503/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6626 - accuracy: 0.8637 - val_loss: 0.3562 - val_accuracy: 0.8644\n",
      "Epoch 504/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6629 - accuracy: 0.8631 - val_loss: 0.3619 - val_accuracy: 0.8609\n",
      "Epoch 505/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6856 - accuracy: 0.8627 - val_loss: 0.4025 - val_accuracy: 0.8392\n",
      "Epoch 506/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8756 - accuracy: 0.8510 - val_loss: 0.3696 - val_accuracy: 0.8576\n",
      "Epoch 507/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.0964 - accuracy: 0.8407 - val_loss: 0.3728 - val_accuracy: 0.8586\n",
      "Epoch 508/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8295 - accuracy: 0.8551 - val_loss: 0.3996 - val_accuracy: 0.8424\n",
      "Epoch 509/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6907 - accuracy: 0.8614 - val_loss: 0.3636 - val_accuracy: 0.8611\n",
      "Epoch 510/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6278 - accuracy: 0.8646 - val_loss: 0.3557 - val_accuracy: 0.8648\n",
      "Epoch 511/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6369 - accuracy: 0.8641 - val_loss: 0.3616 - val_accuracy: 0.8612\n",
      "Epoch 512/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6264 - accuracy: 0.8650 - val_loss: 0.3734 - val_accuracy: 0.8542\n",
      "Epoch 513/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7079 - accuracy: 0.8602 - val_loss: 0.3676 - val_accuracy: 0.8580\n",
      "Epoch 514/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7947 - accuracy: 0.8534 - val_loss: 0.3741 - val_accuracy: 0.8557\n",
      "Epoch 515/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8695 - accuracy: 0.8534 - val_loss: 0.3791 - val_accuracy: 0.8552\n",
      "Epoch 516/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8524 - accuracy: 0.8531 - val_loss: 0.4639 - val_accuracy: 0.8115\n",
      "Epoch 517/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9134 - accuracy: 0.8489 - val_loss: 0.3584 - val_accuracy: 0.8641\n",
      "Epoch 518/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7713 - accuracy: 0.8592 - val_loss: 0.3640 - val_accuracy: 0.8620\n",
      "Epoch 519/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7519 - accuracy: 0.8584 - val_loss: 0.4342 - val_accuracy: 0.8241\n",
      "Epoch 520/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9281 - accuracy: 0.8472 - val_loss: 0.3604 - val_accuracy: 0.8627\n",
      "Epoch 521/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 3.7967 - accuracy: 0.8576 - val_loss: 0.3645 - val_accuracy: 0.8617\n",
      "Epoch 522/3000\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 3.7309 - accuracy: 0.8597 - val_loss: 0.3644 - val_accuracy: 0.8597\n",
      "Epoch 523/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 3.7685 - accuracy: 0.8576 - val_loss: 0.4405 - val_accuracy: 0.8240\n",
      "Epoch 524/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 3.7657 - accuracy: 0.8572 - val_loss: 0.3714 - val_accuracy: 0.8573\n",
      "Epoch 525/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.6249 - accuracy: 0.8651 - val_loss: 0.3672 - val_accuracy: 0.8585\n",
      "Epoch 526/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.6468 - accuracy: 0.8633 - val_loss: 0.3592 - val_accuracy: 0.8620\n",
      "Epoch 527/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6558 - accuracy: 0.8621 - val_loss: 0.3619 - val_accuracy: 0.8609\n",
      "Epoch 528/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6136 - accuracy: 0.8651 - val_loss: 0.3529 - val_accuracy: 0.8653\n",
      "Epoch 529/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6050 - accuracy: 0.8656 - val_loss: 0.3923 - val_accuracy: 0.8450\n",
      "Epoch 530/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7063 - accuracy: 0.8600 - val_loss: 0.3809 - val_accuracy: 0.8518\n",
      "Epoch 531/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6567 - accuracy: 0.8613 - val_loss: 0.3497 - val_accuracy: 0.8678\n",
      "Epoch 532/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6186 - accuracy: 0.8650 - val_loss: 0.3619 - val_accuracy: 0.8597\n",
      "Epoch 533/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5951 - accuracy: 0.8659 - val_loss: 0.3495 - val_accuracy: 0.8669\n",
      "Epoch 534/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6261 - accuracy: 0.8641 - val_loss: 0.3503 - val_accuracy: 0.8677\n",
      "Epoch 535/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6068 - accuracy: 0.8655 - val_loss: 0.3556 - val_accuracy: 0.8632\n",
      "Epoch 536/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5919 - accuracy: 0.8666 - val_loss: 0.3795 - val_accuracy: 0.8509\n",
      "Epoch 537/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6201 - accuracy: 0.8643 - val_loss: 0.3669 - val_accuracy: 0.8580\n",
      "Epoch 538/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5900 - accuracy: 0.8661 - val_loss: 0.3738 - val_accuracy: 0.8542\n",
      "Epoch 539/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5993 - accuracy: 0.8655 - val_loss: 0.3566 - val_accuracy: 0.8632\n",
      "Epoch 540/3000\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 3.6220 - accuracy: 0.8641 - val_loss: 0.3608 - val_accuracy: 0.8612\n",
      "Epoch 541/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.9993 - accuracy: 0.8438 - val_loss: 0.3861 - val_accuracy: 0.8523\n",
      "Epoch 542/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8783 - accuracy: 0.8537 - val_loss: 0.3600 - val_accuracy: 0.8640\n",
      "Epoch 543/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.8046 - accuracy: 0.8562 - val_loss: 0.4301 - val_accuracy: 0.8277\n",
      "Epoch 544/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7731 - accuracy: 0.8564 - val_loss: 0.3596 - val_accuracy: 0.8638\n",
      "Epoch 545/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6703 - accuracy: 0.8636 - val_loss: 0.3736 - val_accuracy: 0.8549\n",
      "Epoch 546/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6400 - accuracy: 0.8625 - val_loss: 0.3499 - val_accuracy: 0.8674\n",
      "Epoch 547/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6272 - accuracy: 0.8655 - val_loss: 0.3895 - val_accuracy: 0.8472\n",
      "Epoch 548/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6012 - accuracy: 0.8657 - val_loss: 0.3804 - val_accuracy: 0.8512\n",
      "Epoch 549/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6285 - accuracy: 0.8645 - val_loss: 0.3932 - val_accuracy: 0.8439\n",
      "Epoch 550/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6549 - accuracy: 0.8627 - val_loss: 0.3776 - val_accuracy: 0.8529\n",
      "Epoch 551/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6120 - accuracy: 0.8650 - val_loss: 0.3694 - val_accuracy: 0.8566\n",
      "Epoch 552/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5687 - accuracy: 0.8665 - val_loss: 0.3516 - val_accuracy: 0.8658\n",
      "Epoch 553/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5705 - accuracy: 0.8681 - val_loss: 0.3768 - val_accuracy: 0.8532\n",
      "Epoch 554/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6690 - accuracy: 0.8606 - val_loss: 0.3517 - val_accuracy: 0.8662\n",
      "Epoch 555/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6620 - accuracy: 0.8633 - val_loss: 0.3768 - val_accuracy: 0.8533\n",
      "Epoch 556/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6619 - accuracy: 0.8619 - val_loss: 0.3639 - val_accuracy: 0.8600\n",
      "Epoch 557/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6082 - accuracy: 0.8659 - val_loss: 0.3622 - val_accuracy: 0.8607\n",
      "Epoch 558/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6413 - accuracy: 0.8632 - val_loss: 0.3581 - val_accuracy: 0.8625\n",
      "Epoch 559/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7511 - accuracy: 0.8577 - val_loss: 0.3616 - val_accuracy: 0.8627\n",
      "Epoch 560/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5997 - accuracy: 0.8676 - val_loss: 0.3675 - val_accuracy: 0.8581\n",
      "Epoch 561/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6212 - accuracy: 0.8635 - val_loss: 0.3553 - val_accuracy: 0.8641\n",
      "Epoch 562/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7386 - accuracy: 0.8592 - val_loss: 0.3768 - val_accuracy: 0.8539\n",
      "Epoch 563/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 3.5944 - accuracy: 0.8661 - val_loss: 0.3763 - val_accuracy: 0.8536\n",
      "Epoch 564/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5954 - accuracy: 0.8653 - val_loss: 0.3609 - val_accuracy: 0.8603\n",
      "Epoch 565/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8206 - accuracy: 0.8543 - val_loss: 0.3905 - val_accuracy: 0.8464\n",
      "Epoch 566/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.9566 - accuracy: 0.8479 - val_loss: 0.5049 - val_accuracy: 0.7944\n",
      "Epoch 567/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8981 - accuracy: 0.8501 - val_loss: 0.4126 - val_accuracy: 0.8365\n",
      "Epoch 568/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6706 - accuracy: 0.8625 - val_loss: 0.3605 - val_accuracy: 0.8627\n",
      "Epoch 569/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6114 - accuracy: 0.8656 - val_loss: 0.3589 - val_accuracy: 0.8611\n",
      "Epoch 570/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5537 - accuracy: 0.8682 - val_loss: 0.3673 - val_accuracy: 0.8561\n",
      "Epoch 571/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6191 - accuracy: 0.8651 - val_loss: 0.3966 - val_accuracy: 0.8414\n",
      "Epoch 572/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5855 - accuracy: 0.8652 - val_loss: 0.3565 - val_accuracy: 0.8623\n",
      "Epoch 573/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5679 - accuracy: 0.8665 - val_loss: 0.3456 - val_accuracy: 0.8691\n",
      "Epoch 574/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6187 - accuracy: 0.8641 - val_loss: 0.3459 - val_accuracy: 0.8689\n",
      "Epoch 575/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5481 - accuracy: 0.8688 - val_loss: 0.3502 - val_accuracy: 0.8664\n",
      "Epoch 576/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6393 - accuracy: 0.8643 - val_loss: 0.3680 - val_accuracy: 0.8583\n",
      "Epoch 577/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7106 - accuracy: 0.8583 - val_loss: 0.3683 - val_accuracy: 0.8574\n",
      "Epoch 578/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6845 - accuracy: 0.8625 - val_loss: 0.3645 - val_accuracy: 0.8599\n",
      "Epoch 579/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5596 - accuracy: 0.8681 - val_loss: 0.3632 - val_accuracy: 0.8588\n",
      "Epoch 580/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6052 - accuracy: 0.8646 - val_loss: 0.3549 - val_accuracy: 0.8638\n",
      "Epoch 581/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6226 - accuracy: 0.8642 - val_loss: 0.3576 - val_accuracy: 0.8629\n",
      "Epoch 582/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7343 - accuracy: 0.8575 - val_loss: 0.3786 - val_accuracy: 0.8534\n",
      "Epoch 583/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6535 - accuracy: 0.8613 - val_loss: 0.3493 - val_accuracy: 0.8664\n",
      "Epoch 584/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7194 - accuracy: 0.8598 - val_loss: 0.3485 - val_accuracy: 0.8680\n",
      "Epoch 585/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7440 - accuracy: 0.8586 - val_loss: 0.3685 - val_accuracy: 0.8576\n",
      "Epoch 586/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6401 - accuracy: 0.8628 - val_loss: 0.3588 - val_accuracy: 0.8619\n",
      "Epoch 587/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5556 - accuracy: 0.8684 - val_loss: 0.3535 - val_accuracy: 0.8645\n",
      "Epoch 588/3000\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.5402 - accuracy: 0.86 - 1s 72ms/step - loss: 3.5402 - accuracy: 0.8682 - val_loss: 0.3674 - val_accuracy: 0.8562\n",
      "Epoch 589/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6055 - accuracy: 0.8652 - val_loss: 0.4150 - val_accuracy: 0.8329\n",
      "Epoch 590/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5798 - accuracy: 0.8648 - val_loss: 0.3539 - val_accuracy: 0.8637\n",
      "Epoch 591/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5357 - accuracy: 0.8687 - val_loss: 0.3510 - val_accuracy: 0.8652\n",
      "Epoch 592/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5118 - accuracy: 0.8698 - val_loss: 0.3493 - val_accuracy: 0.8654\n",
      "Epoch 593/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6754 - accuracy: 0.8604 - val_loss: 0.3428 - val_accuracy: 0.8702\n",
      "Epoch 594/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7320 - accuracy: 0.8591 - val_loss: 0.4130 - val_accuracy: 0.8366\n",
      "Epoch 595/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.7793 - accuracy: 0.8543 - val_loss: 0.3545 - val_accuracy: 0.8646\n",
      "Epoch 596/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5912 - accuracy: 0.8653 - val_loss: 0.3482 - val_accuracy: 0.8676\n",
      "Epoch 597/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5756 - accuracy: 0.8659 - val_loss: 0.3459 - val_accuracy: 0.8681\n",
      "Epoch 598/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5591 - accuracy: 0.8675 - val_loss: 0.3519 - val_accuracy: 0.8659\n",
      "Epoch 599/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6641 - accuracy: 0.8605 - val_loss: 0.3820 - val_accuracy: 0.8511\n",
      "Epoch 600/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7367 - accuracy: 0.8604 - val_loss: 0.3718 - val_accuracy: 0.8553\n",
      "Epoch 601/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5311 - accuracy: 0.8690 - val_loss: 0.3750 - val_accuracy: 0.8517\n",
      "Epoch 602/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5363 - accuracy: 0.8678 - val_loss: 0.3543 - val_accuracy: 0.8629\n",
      "Epoch 603/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5369 - accuracy: 0.8676 - val_loss: 0.3433 - val_accuracy: 0.8699\n",
      "Epoch 604/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5298 - accuracy: 0.8699 - val_loss: 0.3455 - val_accuracy: 0.8679\n",
      "Epoch 605/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6842 - accuracy: 0.8602 - val_loss: 0.3431 - val_accuracy: 0.8707\n",
      "Epoch 606/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5883 - accuracy: 0.8665 - val_loss: 0.3463 - val_accuracy: 0.8689\n",
      "Epoch 607/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5804 - accuracy: 0.8661 - val_loss: 0.3491 - val_accuracy: 0.8667\n",
      "Epoch 608/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6608 - accuracy: 0.8624 - val_loss: 0.3434 - val_accuracy: 0.8706\n",
      "Epoch 609/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6252 - accuracy: 0.8655 - val_loss: 0.4432 - val_accuracy: 0.8199\n",
      "Epoch 610/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0473 - accuracy: 0.8406 - val_loss: 0.3676 - val_accuracy: 0.8613\n",
      "Epoch 611/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8593 - accuracy: 0.8549 - val_loss: 0.3775 - val_accuracy: 0.8554\n",
      "Epoch 612/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6056 - accuracy: 0.8666 - val_loss: 0.3437 - val_accuracy: 0.8696\n",
      "Epoch 613/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5364 - accuracy: 0.8687 - val_loss: 0.3435 - val_accuracy: 0.8693\n",
      "Epoch 614/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5296 - accuracy: 0.8693 - val_loss: 0.3730 - val_accuracy: 0.8547\n",
      "Epoch 615/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5214 - accuracy: 0.8688 - val_loss: 0.3569 - val_accuracy: 0.8625\n",
      "Epoch 616/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5879 - accuracy: 0.8651 - val_loss: 0.3599 - val_accuracy: 0.8604\n",
      "Epoch 617/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5548 - accuracy: 0.8678 - val_loss: 0.4049 - val_accuracy: 0.8381\n",
      "Epoch 618/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6983 - accuracy: 0.8596 - val_loss: 0.3786 - val_accuracy: 0.8530\n",
      "Epoch 619/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6169 - accuracy: 0.8631 - val_loss: 0.3441 - val_accuracy: 0.8699\n",
      "Epoch 620/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5360 - accuracy: 0.8687 - val_loss: 0.3608 - val_accuracy: 0.8607\n",
      "Epoch 621/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5158 - accuracy: 0.8688 - val_loss: 0.3492 - val_accuracy: 0.8658\n",
      "Epoch 622/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5155 - accuracy: 0.8685 - val_loss: 0.3455 - val_accuracy: 0.8681\n",
      "Epoch 623/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5320 - accuracy: 0.8682 - val_loss: 0.3365 - val_accuracy: 0.8730\n",
      "Epoch 624/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4830 - accuracy: 0.8711 - val_loss: 0.3400 - val_accuracy: 0.8712\n",
      "Epoch 625/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5632 - accuracy: 0.8663 - val_loss: 0.3564 - val_accuracy: 0.8624\n",
      "Epoch 626/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6762 - accuracy: 0.8619 - val_loss: 0.3892 - val_accuracy: 0.8476\n",
      "Epoch 627/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5335 - accuracy: 0.8681 - val_loss: 0.3760 - val_accuracy: 0.8543\n",
      "Epoch 628/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6400 - accuracy: 0.8623 - val_loss: 0.3429 - val_accuracy: 0.8704\n",
      "Epoch 629/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8827 - accuracy: 0.8515 - val_loss: 0.5585 - val_accuracy: 0.7768\n",
      "Epoch 630/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.1012 - accuracy: 0.8403 - val_loss: 0.4165 - val_accuracy: 0.8439\n",
      "Epoch 631/3000\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.6933 - accuracy: 0.86 - 1s 76ms/step - loss: 3.6933 - accuracy: 0.8622 - val_loss: 0.3799 - val_accuracy: 0.8541\n",
      "Epoch 632/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5699 - accuracy: 0.8673 - val_loss: 0.3396 - val_accuracy: 0.8719\n",
      "Epoch 633/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5103 - accuracy: 0.8702 - val_loss: 0.3470 - val_accuracy: 0.8669\n",
      "Epoch 634/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5276 - accuracy: 0.8682 - val_loss: 0.3521 - val_accuracy: 0.8636\n",
      "Epoch 635/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4739 - accuracy: 0.8708 - val_loss: 0.3441 - val_accuracy: 0.8682\n",
      "Epoch 636/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5054 - accuracy: 0.8690 - val_loss: 0.3381 - val_accuracy: 0.8718\n",
      "Epoch 637/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4848 - accuracy: 0.8711 - val_loss: 0.3503 - val_accuracy: 0.8654\n",
      "Epoch 638/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4959 - accuracy: 0.8695 - val_loss: 0.3568 - val_accuracy: 0.8618\n",
      "Epoch 639/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6276 - accuracy: 0.8630 - val_loss: 0.3933 - val_accuracy: 0.8437\n",
      "Epoch 640/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6036 - accuracy: 0.8641 - val_loss: 0.3449 - val_accuracy: 0.8700\n",
      "Epoch 641/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7202 - accuracy: 0.8576 - val_loss: 0.3392 - val_accuracy: 0.8730\n",
      "Epoch 642/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6137 - accuracy: 0.8659 - val_loss: 0.3673 - val_accuracy: 0.8582\n",
      "Epoch 643/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6089 - accuracy: 0.8637 - val_loss: 0.3604 - val_accuracy: 0.8605\n",
      "Epoch 644/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.5213 - accuracy: 0.8692 - val_loss: 0.3948 - val_accuracy: 0.8422\n",
      "Epoch 645/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5195 - accuracy: 0.8685 - val_loss: 0.3509 - val_accuracy: 0.8651\n",
      "Epoch 646/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4984 - accuracy: 0.8680 - val_loss: 0.3386 - val_accuracy: 0.8713\n",
      "Epoch 647/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.4930 - accuracy: 0.8703 - val_loss: 0.3485 - val_accuracy: 0.8662\n",
      "Epoch 648/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5242 - accuracy: 0.8682 - val_loss: 0.3377 - val_accuracy: 0.8721\n",
      "Epoch 649/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5591 - accuracy: 0.8673 - val_loss: 0.4093 - val_accuracy: 0.8372\n",
      "Epoch 650/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7675 - accuracy: 0.8553 - val_loss: 0.3798 - val_accuracy: 0.8531\n",
      "Epoch 651/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.8384 - accuracy: 0.8520 - val_loss: 0.4567 - val_accuracy: 0.8157\n",
      "Epoch 652/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6713 - accuracy: 0.8599 - val_loss: 0.3370 - val_accuracy: 0.8743\n",
      "Epoch 653/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6689 - accuracy: 0.8627 - val_loss: 0.3512 - val_accuracy: 0.8653\n",
      "Epoch 654/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6499 - accuracy: 0.8624 - val_loss: 0.4146 - val_accuracy: 0.8351\n",
      "Epoch 655/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6753 - accuracy: 0.8591 - val_loss: 0.3548 - val_accuracy: 0.8650\n",
      "Epoch 656/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6773 - accuracy: 0.8616 - val_loss: 0.3452 - val_accuracy: 0.8685\n",
      "Epoch 657/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6920 - accuracy: 0.8592 - val_loss: 0.4389 - val_accuracy: 0.8225\n",
      "Epoch 658/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6467 - accuracy: 0.8606 - val_loss: 0.3382 - val_accuracy: 0.8725\n",
      "Epoch 659/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5895 - accuracy: 0.8662 - val_loss: 0.3415 - val_accuracy: 0.8707\n",
      "Epoch 660/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6505 - accuracy: 0.8616 - val_loss: 0.4367 - val_accuracy: 0.8245\n",
      "Epoch 661/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6260 - accuracy: 0.8621 - val_loss: 0.3423 - val_accuracy: 0.8699\n",
      "Epoch 662/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5064 - accuracy: 0.8703 - val_loss: 0.3497 - val_accuracy: 0.8650\n",
      "Epoch 663/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4649 - accuracy: 0.8708 - val_loss: 0.3390 - val_accuracy: 0.8699\n",
      "Epoch 664/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4962 - accuracy: 0.8700 - val_loss: 0.3639 - val_accuracy: 0.8567\n",
      "Epoch 665/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4558 - accuracy: 0.8715 - val_loss: 0.3608 - val_accuracy: 0.8603\n",
      "Epoch 666/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5944 - accuracy: 0.8631 - val_loss: 0.3465 - val_accuracy: 0.8683\n",
      "Epoch 667/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5414 - accuracy: 0.8681 - val_loss: 0.3509 - val_accuracy: 0.8660\n",
      "Epoch 668/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5083 - accuracy: 0.8680 - val_loss: 0.3356 - val_accuracy: 0.8731\n",
      "Epoch 669/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4443 - accuracy: 0.8718 - val_loss: 0.3478 - val_accuracy: 0.8664\n",
      "Epoch 670/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4311 - accuracy: 0.8727 - val_loss: 0.3646 - val_accuracy: 0.8577\n",
      "Epoch 671/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4682 - accuracy: 0.8699 - val_loss: 0.3421 - val_accuracy: 0.8690\n",
      "Epoch 672/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4319 - accuracy: 0.8734 - val_loss: 0.3404 - val_accuracy: 0.8693\n",
      "Epoch 673/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4800 - accuracy: 0.8700 - val_loss: 0.3487 - val_accuracy: 0.8647\n",
      "Epoch 674/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4185 - accuracy: 0.8731 - val_loss: 0.3385 - val_accuracy: 0.8707\n",
      "Epoch 675/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4480 - accuracy: 0.8724 - val_loss: 0.3493 - val_accuracy: 0.8647\n",
      "Epoch 676/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4208 - accuracy: 0.8733 - val_loss: 0.3494 - val_accuracy: 0.8644\n",
      "Epoch 677/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4857 - accuracy: 0.8693 - val_loss: 0.3647 - val_accuracy: 0.8561\n",
      "Epoch 678/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4942 - accuracy: 0.8685 - val_loss: 0.4084 - val_accuracy: 0.8363\n",
      "Epoch 679/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6563 - accuracy: 0.8593 - val_loss: 0.3591 - val_accuracy: 0.8624\n",
      "Epoch 680/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6456 - accuracy: 0.8625 - val_loss: 0.3665 - val_accuracy: 0.8592\n",
      "Epoch 681/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4632 - accuracy: 0.8722 - val_loss: 0.3617 - val_accuracy: 0.8585\n",
      "Epoch 682/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4599 - accuracy: 0.8708 - val_loss: 0.3608 - val_accuracy: 0.8593\n",
      "Epoch 683/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4838 - accuracy: 0.8706 - val_loss: 0.4251 - val_accuracy: 0.8244\n",
      "Epoch 684/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6689 - accuracy: 0.8592 - val_loss: 0.3754 - val_accuracy: 0.8526\n",
      "Epoch 685/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4586 - accuracy: 0.8708 - val_loss: 0.3381 - val_accuracy: 0.8717\n",
      "Epoch 686/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4112 - accuracy: 0.8744 - val_loss: 0.3388 - val_accuracy: 0.8694\n",
      "Epoch 687/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.4324 - accuracy: 0.8723 - val_loss: 0.3685 - val_accuracy: 0.8543\n",
      "Epoch 688/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5910 - accuracy: 0.8653 - val_loss: 0.4507 - val_accuracy: 0.8091\n",
      "Epoch 689/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8412 - accuracy: 0.8497 - val_loss: 0.3515 - val_accuracy: 0.8676\n",
      "Epoch 690/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7245 - accuracy: 0.8600 - val_loss: 0.3392 - val_accuracy: 0.8726\n",
      "Epoch 691/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6896 - accuracy: 0.8601 - val_loss: 0.3786 - val_accuracy: 0.8534\n",
      "Epoch 692/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5323 - accuracy: 0.8682 - val_loss: 0.3674 - val_accuracy: 0.8568\n",
      "Epoch 693/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4850 - accuracy: 0.8705 - val_loss: 0.3524 - val_accuracy: 0.8631\n",
      "Epoch 694/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4378 - accuracy: 0.8720 - val_loss: 0.3433 - val_accuracy: 0.8677\n",
      "Epoch 695/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6336 - accuracy: 0.8601 - val_loss: 0.3849 - val_accuracy: 0.8484\n",
      "Epoch 696/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9537 - accuracy: 0.8468 - val_loss: 0.3541 - val_accuracy: 0.8663\n",
      "Epoch 697/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5981 - accuracy: 0.8672 - val_loss: 0.3350 - val_accuracy: 0.8742\n",
      "Epoch 698/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4332 - accuracy: 0.8737 - val_loss: 0.3575 - val_accuracy: 0.8609\n",
      "Epoch 699/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4158 - accuracy: 0.8738 - val_loss: 0.3577 - val_accuracy: 0.8593\n",
      "Epoch 700/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4133 - accuracy: 0.8724 - val_loss: 0.3436 - val_accuracy: 0.8678\n",
      "Epoch 701/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3788 - accuracy: 0.8744 - val_loss: 0.3327 - val_accuracy: 0.8731\n",
      "Epoch 702/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3909 - accuracy: 0.8740 - val_loss: 0.3318 - val_accuracy: 0.8735\n",
      "Epoch 703/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3781 - accuracy: 0.8748 - val_loss: 0.3330 - val_accuracy: 0.8725\n",
      "Epoch 704/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4195 - accuracy: 0.8729 - val_loss: 0.3374 - val_accuracy: 0.8707\n",
      "Epoch 705/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4233 - accuracy: 0.8722 - val_loss: 0.3306 - val_accuracy: 0.8748\n",
      "Epoch 706/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4265 - accuracy: 0.8730 - val_loss: 0.3270 - val_accuracy: 0.8767\n",
      "Epoch 707/3000\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.4044 - accuracy: 0.87 - 1s 74ms/step - loss: 3.4044 - accuracy: 0.8744 - val_loss: 0.3548 - val_accuracy: 0.8604\n",
      "Epoch 708/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4223 - accuracy: 0.8730 - val_loss: 0.3781 - val_accuracy: 0.8502\n",
      "Epoch 709/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5464 - accuracy: 0.8665 - val_loss: 0.4086 - val_accuracy: 0.8359\n",
      "Epoch 710/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5944 - accuracy: 0.8634 - val_loss: 0.3500 - val_accuracy: 0.8666\n",
      "Epoch 711/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5169 - accuracy: 0.8671 - val_loss: 0.3337 - val_accuracy: 0.8737\n",
      "Epoch 712/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5047 - accuracy: 0.8699 - val_loss: 0.3330 - val_accuracy: 0.8735\n",
      "Epoch 713/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4136 - accuracy: 0.8731 - val_loss: 0.3707 - val_accuracy: 0.8533\n",
      "Epoch 714/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4416 - accuracy: 0.8700 - val_loss: 0.3310 - val_accuracy: 0.8745\n",
      "Epoch 715/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3928 - accuracy: 0.8744 - val_loss: 0.3328 - val_accuracy: 0.8737\n",
      "Epoch 716/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3519 - accuracy: 0.8762 - val_loss: 0.3333 - val_accuracy: 0.8715\n",
      "Epoch 717/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4143 - accuracy: 0.8726 - val_loss: 0.3554 - val_accuracy: 0.8619\n",
      "Epoch 718/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4244 - accuracy: 0.8715 - val_loss: 0.3428 - val_accuracy: 0.8695\n",
      "Epoch 719/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4427 - accuracy: 0.8711 - val_loss: 0.3656 - val_accuracy: 0.8577\n",
      "Epoch 720/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3934 - accuracy: 0.8745 - val_loss: 0.3360 - val_accuracy: 0.8715\n",
      "Epoch 721/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4867 - accuracy: 0.8695 - val_loss: 0.3753 - val_accuracy: 0.8550\n",
      "Epoch 722/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3928 - accuracy: 0.8741 - val_loss: 0.3761 - val_accuracy: 0.8511\n",
      "Epoch 723/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5639 - accuracy: 0.8646 - val_loss: 0.3660 - val_accuracy: 0.8555\n",
      "Epoch 724/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5220 - accuracy: 0.8685 - val_loss: 0.4011 - val_accuracy: 0.8393\n",
      "Epoch 725/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7715 - accuracy: 0.8546 - val_loss: 0.3435 - val_accuracy: 0.8698\n",
      "Epoch 726/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8045 - accuracy: 0.8538 - val_loss: 0.3843 - val_accuracy: 0.8520\n",
      "Epoch 727/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4813 - accuracy: 0.8696 - val_loss: 0.3312 - val_accuracy: 0.8757\n",
      "Epoch 728/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3894 - accuracy: 0.8755 - val_loss: 0.3633 - val_accuracy: 0.8572\n",
      "Epoch 729/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3827 - accuracy: 0.8736 - val_loss: 0.3275 - val_accuracy: 0.8759\n",
      "Epoch 730/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3419 - accuracy: 0.8763 - val_loss: 0.3331 - val_accuracy: 0.8723\n",
      "Epoch 731/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3378 - accuracy: 0.8768 - val_loss: 0.3471 - val_accuracy: 0.8644\n",
      "Epoch 732/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3754 - accuracy: 0.8735 - val_loss: 0.3275 - val_accuracy: 0.8750\n",
      "Epoch 733/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3746 - accuracy: 0.8749 - val_loss: 0.3545 - val_accuracy: 0.8617\n",
      "Epoch 734/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5880 - accuracy: 0.8637 - val_loss: 0.3414 - val_accuracy: 0.8701\n",
      "Epoch 735/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0343 - accuracy: 0.8408 - val_loss: 0.3554 - val_accuracy: 0.8654\n",
      "Epoch 736/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7817 - accuracy: 0.8557 - val_loss: 0.3437 - val_accuracy: 0.8701\n",
      "Epoch 737/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4986 - accuracy: 0.8708 - val_loss: 0.3423 - val_accuracy: 0.8689\n",
      "Epoch 738/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4253 - accuracy: 0.8721 - val_loss: 0.3395 - val_accuracy: 0.8694\n",
      "Epoch 739/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4360 - accuracy: 0.8713 - val_loss: 0.3326 - val_accuracy: 0.8741\n",
      "Epoch 740/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3791 - accuracy: 0.8759 - val_loss: 0.3443 - val_accuracy: 0.8666\n",
      "Epoch 741/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3327 - accuracy: 0.8769 - val_loss: 0.3468 - val_accuracy: 0.8642\n",
      "Epoch 742/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4575 - accuracy: 0.8705 - val_loss: 0.3875 - val_accuracy: 0.8432\n",
      "Epoch 743/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5354 - accuracy: 0.8661 - val_loss: 0.3581 - val_accuracy: 0.8627\n",
      "Epoch 744/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3666 - accuracy: 0.8749 - val_loss: 0.3347 - val_accuracy: 0.8723\n",
      "Epoch 745/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3569 - accuracy: 0.8753 - val_loss: 0.3497 - val_accuracy: 0.8630\n",
      "Epoch 746/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3662 - accuracy: 0.8732 - val_loss: 0.3236 - val_accuracy: 0.8773\n",
      "Epoch 747/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3431 - accuracy: 0.8774 - val_loss: 0.3523 - val_accuracy: 0.8633\n",
      "Epoch 748/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4374 - accuracy: 0.8701 - val_loss: 0.3350 - val_accuracy: 0.8724\n",
      "Epoch 749/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4253 - accuracy: 0.8726 - val_loss: 0.3234 - val_accuracy: 0.8784\n",
      "Epoch 750/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5557 - accuracy: 0.8659 - val_loss: 0.3381 - val_accuracy: 0.8706\n",
      "Epoch 751/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4303 - accuracy: 0.8729 - val_loss: 0.3433 - val_accuracy: 0.8671\n",
      "Epoch 752/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4030 - accuracy: 0.8736 - val_loss: 0.3536 - val_accuracy: 0.8620\n",
      "Epoch 753/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4469 - accuracy: 0.8708 - val_loss: 0.3819 - val_accuracy: 0.8476\n",
      "Epoch 754/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4527 - accuracy: 0.8703 - val_loss: 0.3636 - val_accuracy: 0.8581\n",
      "Epoch 755/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.4341 - accuracy: 0.8713 - val_loss: 0.3533 - val_accuracy: 0.8634\n",
      "Epoch 756/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.6341 - accuracy: 0.8587 - val_loss: 0.3669 - val_accuracy: 0.8579\n",
      "Epoch 757/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0838 - accuracy: 0.8407 - val_loss: 0.3572 - val_accuracy: 0.8654\n",
      "Epoch 758/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6764 - accuracy: 0.8644 - val_loss: 0.3701 - val_accuracy: 0.8583\n",
      "Epoch 759/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4431 - accuracy: 0.8726 - val_loss: 0.3276 - val_accuracy: 0.8764\n",
      "Epoch 760/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3534 - accuracy: 0.8765 - val_loss: 0.3437 - val_accuracy: 0.8668\n",
      "Epoch 761/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3302 - accuracy: 0.8759 - val_loss: 0.3563 - val_accuracy: 0.8612\n",
      "Epoch 762/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3520 - accuracy: 0.8753 - val_loss: 0.3276 - val_accuracy: 0.8749\n",
      "Epoch 763/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3613 - accuracy: 0.8753 - val_loss: 0.3595 - val_accuracy: 0.8568\n",
      "Epoch 764/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4533 - accuracy: 0.8701 - val_loss: 0.3959 - val_accuracy: 0.8388\n",
      "Epoch 765/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6037 - accuracy: 0.8627 - val_loss: 0.3531 - val_accuracy: 0.8627\n",
      "Epoch 766/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.9015 - accuracy: 0.8502 - val_loss: 0.4725 - val_accuracy: 0.8028\n",
      "Epoch 767/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8244 - accuracy: 0.8500 - val_loss: 0.3415 - val_accuracy: 0.8731\n",
      "Epoch 768/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5095 - accuracy: 0.8708 - val_loss: 0.3294 - val_accuracy: 0.8762\n",
      "Epoch 769/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3963 - accuracy: 0.8742 - val_loss: 0.3573 - val_accuracy: 0.8599\n",
      "Epoch 770/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4131 - accuracy: 0.8722 - val_loss: 0.3484 - val_accuracy: 0.8645\n",
      "Epoch 771/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4811 - accuracy: 0.8684 - val_loss: 0.3640 - val_accuracy: 0.8568\n",
      "Epoch 772/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4364 - accuracy: 0.8712 - val_loss: 0.3275 - val_accuracy: 0.8765\n",
      "Epoch 773/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3971 - accuracy: 0.8745 - val_loss: 0.3553 - val_accuracy: 0.8618\n",
      "Epoch 774/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3103 - accuracy: 0.8771 - val_loss: 0.3323 - val_accuracy: 0.8722\n",
      "Epoch 775/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3289 - accuracy: 0.8764 - val_loss: 0.3350 - val_accuracy: 0.8724\n",
      "Epoch 776/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3555 - accuracy: 0.8750 - val_loss: 0.3564 - val_accuracy: 0.8608\n",
      "Epoch 777/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3324 - accuracy: 0.8749 - val_loss: 0.3197 - val_accuracy: 0.8797\n",
      "Epoch 778/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3936 - accuracy: 0.8739 - val_loss: 0.3354 - val_accuracy: 0.8722\n",
      "Epoch 779/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4295 - accuracy: 0.8720 - val_loss: 0.3329 - val_accuracy: 0.8721\n",
      "Epoch 780/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5019 - accuracy: 0.8670 - val_loss: 0.3328 - val_accuracy: 0.8731\n",
      "Epoch 781/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4146 - accuracy: 0.8729 - val_loss: 0.3234 - val_accuracy: 0.8785\n",
      "Epoch 782/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3273 - accuracy: 0.8772 - val_loss: 0.3650 - val_accuracy: 0.8568\n",
      "Epoch 783/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3466 - accuracy: 0.8753 - val_loss: 0.3844 - val_accuracy: 0.8464\n",
      "Epoch 784/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5359 - accuracy: 0.8666 - val_loss: 0.3672 - val_accuracy: 0.8560\n",
      "Epoch 785/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3415 - accuracy: 0.8749 - val_loss: 0.3253 - val_accuracy: 0.8764\n",
      "Epoch 786/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3223 - accuracy: 0.8758 - val_loss: 0.3251 - val_accuracy: 0.8766\n",
      "Epoch 787/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3836 - accuracy: 0.8731 - val_loss: 0.3344 - val_accuracy: 0.8723\n",
      "Epoch 788/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4160 - accuracy: 0.8727 - val_loss: 0.3265 - val_accuracy: 0.8763\n",
      "Epoch 789/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3393 - accuracy: 0.8777 - val_loss: 0.3315 - val_accuracy: 0.8729\n",
      "Epoch 790/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2989 - accuracy: 0.8779 - val_loss: 0.3465 - val_accuracy: 0.8649\n",
      "Epoch 791/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4291 - accuracy: 0.8701 - val_loss: 0.3171 - val_accuracy: 0.8810\n",
      "Epoch 792/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5116 - accuracy: 0.8675 - val_loss: 0.3869 - val_accuracy: 0.8486\n",
      "Epoch 793/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4398 - accuracy: 0.8708 - val_loss: 0.3220 - val_accuracy: 0.8794\n",
      "Epoch 794/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4553 - accuracy: 0.8703 - val_loss: 0.3412 - val_accuracy: 0.8676\n",
      "Epoch 795/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3336 - accuracy: 0.8768 - val_loss: 0.3602 - val_accuracy: 0.8591\n",
      "Epoch 796/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3014 - accuracy: 0.8773 - val_loss: 0.3226 - val_accuracy: 0.8776\n",
      "Epoch 797/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3075 - accuracy: 0.8777 - val_loss: 0.3592 - val_accuracy: 0.8586\n",
      "Epoch 798/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3616 - accuracy: 0.8724 - val_loss: 0.3228 - val_accuracy: 0.8778\n",
      "Epoch 799/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4206 - accuracy: 0.8722 - val_loss: 0.3241 - val_accuracy: 0.8787\n",
      "Epoch 800/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4820 - accuracy: 0.8704 - val_loss: 0.3597 - val_accuracy: 0.8618\n",
      "Epoch 801/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3566 - accuracy: 0.8748 - val_loss: 0.3176 - val_accuracy: 0.8804\n",
      "Epoch 802/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2957 - accuracy: 0.8783 - val_loss: 0.3217 - val_accuracy: 0.8771\n",
      "Epoch 803/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3551 - accuracy: 0.8750 - val_loss: 0.3362 - val_accuracy: 0.8704\n",
      "Epoch 804/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4832 - accuracy: 0.8676 - val_loss: 0.3280 - val_accuracy: 0.8765\n",
      "Epoch 805/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5389 - accuracy: 0.8663 - val_loss: 0.3763 - val_accuracy: 0.8555\n",
      "Epoch 806/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5703 - accuracy: 0.8631 - val_loss: 0.3517 - val_accuracy: 0.8641\n",
      "Epoch 807/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7333 - accuracy: 0.8566 - val_loss: 0.3252 - val_accuracy: 0.8775\n",
      "Epoch 808/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5119 - accuracy: 0.8685 - val_loss: 0.3329 - val_accuracy: 0.8739\n",
      "Epoch 809/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4612 - accuracy: 0.8711 - val_loss: 0.4260 - val_accuracy: 0.8266\n",
      "Epoch 810/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4143 - accuracy: 0.8702 - val_loss: 0.3180 - val_accuracy: 0.8799\n",
      "Epoch 811/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2873 - accuracy: 0.8794 - val_loss: 0.3578 - val_accuracy: 0.8610\n",
      "Epoch 812/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2873 - accuracy: 0.8782 - val_loss: 0.3427 - val_accuracy: 0.8654\n",
      "Epoch 813/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2660 - accuracy: 0.8789 - val_loss: 0.3504 - val_accuracy: 0.8627\n",
      "Epoch 814/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3312 - accuracy: 0.8749 - val_loss: 0.3184 - val_accuracy: 0.8799\n",
      "Epoch 815/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3459 - accuracy: 0.8753 - val_loss: 0.3233 - val_accuracy: 0.8785\n",
      "Epoch 816/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2981 - accuracy: 0.8791 - val_loss: 0.3228 - val_accuracy: 0.8769\n",
      "Epoch 817/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4022 - accuracy: 0.8718 - val_loss: 0.3468 - val_accuracy: 0.8667\n",
      "Epoch 818/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4056 - accuracy: 0.8744 - val_loss: 0.3294 - val_accuracy: 0.8753\n",
      "Epoch 819/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2559 - accuracy: 0.8801 - val_loss: 0.3305 - val_accuracy: 0.8729\n",
      "Epoch 820/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3047 - accuracy: 0.8768 - val_loss: 0.3930 - val_accuracy: 0.8425\n",
      "Epoch 821/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5208 - accuracy: 0.8659 - val_loss: 0.3721 - val_accuracy: 0.8548\n",
      "Epoch 822/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3460 - accuracy: 0.8752 - val_loss: 0.3251 - val_accuracy: 0.8767\n",
      "Epoch 823/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2869 - accuracy: 0.8790 - val_loss: 0.3202 - val_accuracy: 0.8780\n",
      "Epoch 824/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4783 - accuracy: 0.8672 - val_loss: 0.3854 - val_accuracy: 0.8494\n",
      "Epoch 825/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.9830 - accuracy: 0.8443 - val_loss: 0.3691 - val_accuracy: 0.8635\n",
      "Epoch 826/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6310 - accuracy: 0.8650 - val_loss: 0.3376 - val_accuracy: 0.8734\n",
      "Epoch 827/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3953 - accuracy: 0.8742 - val_loss: 0.3606 - val_accuracy: 0.8568\n",
      "Epoch 828/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3606 - accuracy: 0.8745 - val_loss: 0.3453 - val_accuracy: 0.8649\n",
      "Epoch 829/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3082 - accuracy: 0.8765 - val_loss: 0.3168 - val_accuracy: 0.8799\n",
      "Epoch 830/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2559 - accuracy: 0.8793 - val_loss: 0.3279 - val_accuracy: 0.8758\n",
      "Epoch 831/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5276 - accuracy: 0.8661 - val_loss: 0.3919 - val_accuracy: 0.8435\n",
      "Epoch 832/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 3.8308 - accuracy: 0.8510 - val_loss: 0.3455 - val_accuracy: 0.8704\n",
      "Epoch 833/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 3.5868 - accuracy: 0.8661 - val_loss: 0.3564 - val_accuracy: 0.8647\n",
      "Epoch 834/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3716 - accuracy: 0.8755 - val_loss: 0.3209 - val_accuracy: 0.8787\n",
      "Epoch 835/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.3213 - accuracy: 0.8773 - val_loss: 0.3445 - val_accuracy: 0.8650\n",
      "Epoch 836/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.2407 - accuracy: 0.8792 - val_loss: 0.3249 - val_accuracy: 0.8753\n",
      "Epoch 837/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2732 - accuracy: 0.8794 - val_loss: 0.3240 - val_accuracy: 0.8761\n",
      "Epoch 838/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3240 - accuracy: 0.8761 - val_loss: 0.3164 - val_accuracy: 0.8804\n",
      "Epoch 839/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2880 - accuracy: 0.8779 - val_loss: 0.3340 - val_accuracy: 0.8709\n",
      "Epoch 840/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3911 - accuracy: 0.8722 - val_loss: 0.3577 - val_accuracy: 0.8601\n",
      "Epoch 841/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8576 - accuracy: 0.8492 - val_loss: 0.3758 - val_accuracy: 0.8565\n",
      "Epoch 842/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6658 - accuracy: 0.8620 - val_loss: 0.4413 - val_accuracy: 0.8185\n",
      "Epoch 843/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5048 - accuracy: 0.8660 - val_loss: 0.3770 - val_accuracy: 0.8491\n",
      "Epoch 844/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4903 - accuracy: 0.8661 - val_loss: 0.3251 - val_accuracy: 0.8767\n",
      "Epoch 845/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4783 - accuracy: 0.8706 - val_loss: 0.3185 - val_accuracy: 0.8808\n",
      "Epoch 846/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2995 - accuracy: 0.8792 - val_loss: 0.3614 - val_accuracy: 0.8585\n",
      "Epoch 847/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3422 - accuracy: 0.8739 - val_loss: 0.3166 - val_accuracy: 0.8808\n",
      "Epoch 848/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2853 - accuracy: 0.8797 - val_loss: 0.3550 - val_accuracy: 0.8588\n",
      "Epoch 849/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3579 - accuracy: 0.8735 - val_loss: 0.3208 - val_accuracy: 0.8782\n",
      "Epoch 850/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3975 - accuracy: 0.8722 - val_loss: 0.3429 - val_accuracy: 0.8684\n",
      "Epoch 851/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3142 - accuracy: 0.8758 - val_loss: 0.3160 - val_accuracy: 0.8804\n",
      "Epoch 852/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2362 - accuracy: 0.8812 - val_loss: 0.3167 - val_accuracy: 0.8795\n",
      "Epoch 853/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2435 - accuracy: 0.8800 - val_loss: 0.3174 - val_accuracy: 0.8790\n",
      "Epoch 854/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2263 - accuracy: 0.8801 - val_loss: 0.3228 - val_accuracy: 0.8761\n",
      "Epoch 855/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3147 - accuracy: 0.8767 - val_loss: 0.3586 - val_accuracy: 0.8587\n",
      "Epoch 856/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3972 - accuracy: 0.8725 - val_loss: 0.3707 - val_accuracy: 0.8520\n",
      "Epoch 857/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4006 - accuracy: 0.8708 - val_loss: 0.3300 - val_accuracy: 0.8752\n",
      "Epoch 858/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5250 - accuracy: 0.8673 - val_loss: 0.3296 - val_accuracy: 0.8762\n",
      "Epoch 859/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6400 - accuracy: 0.8608 - val_loss: 0.3472 - val_accuracy: 0.8687\n",
      "Epoch 860/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3406 - accuracy: 0.8769 - val_loss: 0.3603 - val_accuracy: 0.8604\n",
      "Epoch 861/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3501 - accuracy: 0.8738 - val_loss: 0.3459 - val_accuracy: 0.8664\n",
      "Epoch 862/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8258 - accuracy: 0.8514 - val_loss: 0.3495 - val_accuracy: 0.8674\n",
      "Epoch 863/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5996 - accuracy: 0.8650 - val_loss: 0.3258 - val_accuracy: 0.8778\n",
      "Epoch 864/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3321 - accuracy: 0.8780 - val_loss: 0.3235 - val_accuracy: 0.8777\n",
      "Epoch 865/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2593 - accuracy: 0.8804 - val_loss: 0.3285 - val_accuracy: 0.8722\n",
      "Epoch 866/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2110 - accuracy: 0.8803 - val_loss: 0.3279 - val_accuracy: 0.8731\n",
      "Epoch 867/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2215 - accuracy: 0.8810 - val_loss: 0.3369 - val_accuracy: 0.8674\n",
      "Epoch 868/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.2962 - accuracy: 0.8767 - val_loss: 0.3420 - val_accuracy: 0.8657\n",
      "Epoch 869/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.3242 - accuracy: 0.8744 - val_loss: 0.3174 - val_accuracy: 0.8799\n",
      "Epoch 870/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2120 - accuracy: 0.8813 - val_loss: 0.3122 - val_accuracy: 0.8822\n",
      "Epoch 871/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2102 - accuracy: 0.8820 - val_loss: 0.3582 - val_accuracy: 0.8573\n",
      "Epoch 872/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.9896 - accuracy: 0.8415 - val_loss: 0.4069 - val_accuracy: 0.8466\n",
      "Epoch 873/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.1870 - accuracy: 0.8368 - val_loss: 0.4343 - val_accuracy: 0.8378\n",
      "Epoch 874/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6711 - accuracy: 0.8646 - val_loss: 0.4016 - val_accuracy: 0.8418\n",
      "Epoch 875/3000\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 3.3944 - accuracy: 0.8733 - val_loss: 0.3451 - val_accuracy: 0.8664\n",
      "Epoch 876/3000\n",
      "10/10 [==============================] - 1s 80ms/step - loss: 3.2837 - accuracy: 0.8778 - val_loss: 0.3290 - val_accuracy: 0.8726\n",
      "Epoch 877/3000\n",
      "10/10 [==============================] - 1s 80ms/step - loss: 3.2469 - accuracy: 0.8795 - val_loss: 0.3160 - val_accuracy: 0.8793\n",
      "Epoch 878/3000\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 3.2848 - accuracy: 0.8778 - val_loss: 0.3545 - val_accuracy: 0.8598\n",
      "Epoch 879/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2633 - accuracy: 0.8785 - val_loss: 0.3210 - val_accuracy: 0.8770\n",
      "Epoch 880/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2367 - accuracy: 0.8794 - val_loss: 0.3134 - val_accuracy: 0.8811\n",
      "Epoch 881/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2084 - accuracy: 0.8816 - val_loss: 0.3249 - val_accuracy: 0.8746\n",
      "Epoch 882/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2215 - accuracy: 0.8806 - val_loss: 0.3157 - val_accuracy: 0.8795\n",
      "Epoch 883/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2380 - accuracy: 0.8808 - val_loss: 0.3483 - val_accuracy: 0.8625\n",
      "Epoch 884/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2853 - accuracy: 0.8771 - val_loss: 0.3404 - val_accuracy: 0.8682\n",
      "Epoch 885/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2096 - accuracy: 0.8825 - val_loss: 0.3402 - val_accuracy: 0.8682\n",
      "Epoch 886/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2308 - accuracy: 0.8797 - val_loss: 0.3131 - val_accuracy: 0.8809\n",
      "Epoch 887/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.2104 - accuracy: 0.8814 - val_loss: 0.3616 - val_accuracy: 0.8572\n",
      "Epoch 888/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2317 - accuracy: 0.8789 - val_loss: 0.3108 - val_accuracy: 0.8822\n",
      "Epoch 889/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3618 - accuracy: 0.8743 - val_loss: 0.3262 - val_accuracy: 0.8738\n",
      "Epoch 890/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 3.3462 - accuracy: 0.8741 - val_loss: 0.3103 - val_accuracy: 0.8840\n",
      "Epoch 891/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.2609 - accuracy: 0.8798 - val_loss: 0.3620 - val_accuracy: 0.8592\n",
      "Epoch 892/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3012 - accuracy: 0.8779 - val_loss: 0.3596 - val_accuracy: 0.8591\n",
      "Epoch 893/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2615 - accuracy: 0.8794 - val_loss: 0.3600 - val_accuracy: 0.8582\n",
      "Epoch 894/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2925 - accuracy: 0.8776 - val_loss: 0.3513 - val_accuracy: 0.8630\n",
      "Epoch 895/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3009 - accuracy: 0.8770 - val_loss: 0.3501 - val_accuracy: 0.8636\n",
      "Epoch 896/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2486 - accuracy: 0.8791 - val_loss: 0.3288 - val_accuracy: 0.8739\n",
      "Epoch 897/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3330 - accuracy: 0.8743 - val_loss: 0.3150 - val_accuracy: 0.8805\n",
      "Epoch 898/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6132 - accuracy: 0.8640 - val_loss: 0.3494 - val_accuracy: 0.8688\n",
      "Epoch 899/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.9676 - accuracy: 0.8457 - val_loss: 0.3376 - val_accuracy: 0.8746\n",
      "Epoch 900/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5908 - accuracy: 0.8657 - val_loss: 0.3315 - val_accuracy: 0.8752\n",
      "Epoch 901/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3665 - accuracy: 0.8750 - val_loss: 0.3124 - val_accuracy: 0.8826\n",
      "Epoch 902/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2499 - accuracy: 0.8805 - val_loss: 0.3364 - val_accuracy: 0.8694\n",
      "Epoch 903/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2297 - accuracy: 0.8798 - val_loss: 0.3184 - val_accuracy: 0.8780\n",
      "Epoch 904/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2177 - accuracy: 0.8804 - val_loss: 0.3156 - val_accuracy: 0.8804\n",
      "Epoch 905/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2272 - accuracy: 0.8789 - val_loss: 0.3170 - val_accuracy: 0.8798\n",
      "Epoch 906/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.2886 - accuracy: 0.8768 - val_loss: 0.3435 - val_accuracy: 0.8676\n",
      "Epoch 907/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.8318 - accuracy: 0.8522 - val_loss: 0.3421 - val_accuracy: 0.8727\n",
      "Epoch 908/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5941 - accuracy: 0.8636 - val_loss: 0.3272 - val_accuracy: 0.8783\n",
      "Epoch 909/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3507 - accuracy: 0.8768 - val_loss: 0.3141 - val_accuracy: 0.8819\n",
      "Epoch 910/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2400 - accuracy: 0.8810 - val_loss: 0.3360 - val_accuracy: 0.8690\n",
      "Epoch 911/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2086 - accuracy: 0.8805 - val_loss: 0.3101 - val_accuracy: 0.8827\n",
      "Epoch 912/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2643 - accuracy: 0.8784 - val_loss: 0.3115 - val_accuracy: 0.8828\n",
      "Epoch 913/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2559 - accuracy: 0.8794 - val_loss: 0.3229 - val_accuracy: 0.8765\n",
      "Epoch 914/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1927 - accuracy: 0.8825 - val_loss: 0.3295 - val_accuracy: 0.8735\n",
      "Epoch 915/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1782 - accuracy: 0.8823 - val_loss: 0.3645 - val_accuracy: 0.8556\n",
      "Epoch 916/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2342 - accuracy: 0.8791 - val_loss: 0.3292 - val_accuracy: 0.8720\n",
      "Epoch 917/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3469 - accuracy: 0.8753 - val_loss: 0.3595 - val_accuracy: 0.8586\n",
      "Epoch 918/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3351 - accuracy: 0.8747 - val_loss: 0.3141 - val_accuracy: 0.8821\n",
      "Epoch 919/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2546 - accuracy: 0.8800 - val_loss: 0.3213 - val_accuracy: 0.8781\n",
      "Epoch 920/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1751 - accuracy: 0.8826 - val_loss: 0.3099 - val_accuracy: 0.8818\n",
      "Epoch 921/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2697 - accuracy: 0.8779 - val_loss: 0.3293 - val_accuracy: 0.8723\n",
      "Epoch 922/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1925 - accuracy: 0.8813 - val_loss: 0.3180 - val_accuracy: 0.8787\n",
      "Epoch 923/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1793 - accuracy: 0.8829 - val_loss: 0.3402 - val_accuracy: 0.8685\n",
      "Epoch 924/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3472 - accuracy: 0.8734 - val_loss: 0.3032 - val_accuracy: 0.8869\n",
      "Epoch 925/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2046 - accuracy: 0.8824 - val_loss: 0.3179 - val_accuracy: 0.8790\n",
      "Epoch 926/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5345 - accuracy: 0.8659 - val_loss: 0.4801 - val_accuracy: 0.8035\n",
      "Epoch 927/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7368 - accuracy: 0.8572 - val_loss: 0.3677 - val_accuracy: 0.8593\n",
      "Epoch 928/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4415 - accuracy: 0.8705 - val_loss: 0.3388 - val_accuracy: 0.8704\n",
      "Epoch 929/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6145 - accuracy: 0.8609 - val_loss: 0.3271 - val_accuracy: 0.8776\n",
      "Epoch 930/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4223 - accuracy: 0.8717 - val_loss: 0.3089 - val_accuracy: 0.8849\n",
      "Epoch 931/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4186 - accuracy: 0.8718 - val_loss: 0.3245 - val_accuracy: 0.8769\n",
      "Epoch 932/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2789 - accuracy: 0.8782 - val_loss: 0.3600 - val_accuracy: 0.8575\n",
      "Epoch 933/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2580 - accuracy: 0.8775 - val_loss: 0.3224 - val_accuracy: 0.8773\n",
      "Epoch 934/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2310 - accuracy: 0.8804 - val_loss: 0.3110 - val_accuracy: 0.8820\n",
      "Epoch 935/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1844 - accuracy: 0.8823 - val_loss: 0.3298 - val_accuracy: 0.8728\n",
      "Epoch 936/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2343 - accuracy: 0.8791 - val_loss: 0.3567 - val_accuracy: 0.8585\n",
      "Epoch 937/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2552 - accuracy: 0.8779 - val_loss: 0.3329 - val_accuracy: 0.8710\n",
      "Epoch 938/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1995 - accuracy: 0.8813 - val_loss: 0.3088 - val_accuracy: 0.8835\n",
      "Epoch 939/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2739 - accuracy: 0.8761 - val_loss: 0.3507 - val_accuracy: 0.8654\n",
      "Epoch 940/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8822 - accuracy: 0.8482 - val_loss: 0.3801 - val_accuracy: 0.8596\n",
      "Epoch 941/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6925 - accuracy: 0.8619 - val_loss: 0.3245 - val_accuracy: 0.8764\n",
      "Epoch 942/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4240 - accuracy: 0.8723 - val_loss: 0.3167 - val_accuracy: 0.8801\n",
      "Epoch 943/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2757 - accuracy: 0.8791 - val_loss: 0.3196 - val_accuracy: 0.8779\n",
      "Epoch 944/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2305 - accuracy: 0.8794 - val_loss: 0.3203 - val_accuracy: 0.8769\n",
      "Epoch 945/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1957 - accuracy: 0.8819 - val_loss: 0.3225 - val_accuracy: 0.8763\n",
      "Epoch 946/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2223 - accuracy: 0.8786 - val_loss: 0.3057 - val_accuracy: 0.8851\n",
      "Epoch 947/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2353 - accuracy: 0.8811 - val_loss: 0.3572 - val_accuracy: 0.8594\n",
      "Epoch 948/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1748 - accuracy: 0.8821 - val_loss: 0.3154 - val_accuracy: 0.8792\n",
      "Epoch 949/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1367 - accuracy: 0.8840 - val_loss: 0.3024 - val_accuracy: 0.8862\n",
      "Epoch 950/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.2173 - accuracy: 0.8815 - val_loss: 0.3687 - val_accuracy: 0.8538\n",
      "Epoch 951/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1959 - accuracy: 0.8807 - val_loss: 0.3146 - val_accuracy: 0.8805\n",
      "Epoch 952/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4394 - accuracy: 0.8700 - val_loss: 0.4590 - val_accuracy: 0.8135\n",
      "Epoch 953/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9131 - accuracy: 0.8484 - val_loss: 0.4478 - val_accuracy: 0.8207\n",
      "Epoch 954/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4124 - accuracy: 0.8722 - val_loss: 0.3365 - val_accuracy: 0.8710\n",
      "Epoch 955/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3530 - accuracy: 0.8755 - val_loss: 0.4412 - val_accuracy: 0.8165\n",
      "Epoch 956/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4459 - accuracy: 0.8689 - val_loss: 0.3750 - val_accuracy: 0.8526\n",
      "Epoch 957/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3858 - accuracy: 0.8719 - val_loss: 0.3129 - val_accuracy: 0.8822\n",
      "Epoch 958/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2483 - accuracy: 0.8801 - val_loss: 0.3108 - val_accuracy: 0.8828\n",
      "Epoch 959/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2952 - accuracy: 0.8782 - val_loss: 0.3299 - val_accuracy: 0.8732\n",
      "Epoch 960/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4489 - accuracy: 0.8699 - val_loss: 0.4460 - val_accuracy: 0.8174\n",
      "Epoch 961/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3545 - accuracy: 0.8743 - val_loss: 0.3604 - val_accuracy: 0.8608\n",
      "Epoch 962/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2752 - accuracy: 0.8776 - val_loss: 0.3136 - val_accuracy: 0.8807\n",
      "Epoch 963/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2476 - accuracy: 0.8798 - val_loss: 0.3189 - val_accuracy: 0.8777\n",
      "Epoch 964/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3437 - accuracy: 0.8750 - val_loss: 0.4069 - val_accuracy: 0.8353\n",
      "Epoch 965/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6646 - accuracy: 0.8572 - val_loss: 0.3778 - val_accuracy: 0.8527\n",
      "Epoch 966/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4143 - accuracy: 0.8723 - val_loss: 0.3563 - val_accuracy: 0.8612\n",
      "Epoch 967/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2188 - accuracy: 0.8812 - val_loss: 0.3091 - val_accuracy: 0.8836\n",
      "Epoch 968/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1385 - accuracy: 0.8848 - val_loss: 0.3168 - val_accuracy: 0.8781\n",
      "Epoch 969/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1653 - accuracy: 0.8823 - val_loss: 0.3265 - val_accuracy: 0.8731\n",
      "Epoch 970/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1235 - accuracy: 0.8847 - val_loss: 0.3167 - val_accuracy: 0.8775\n",
      "Epoch 971/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1571 - accuracy: 0.8836 - val_loss: 0.3436 - val_accuracy: 0.8650\n",
      "Epoch 972/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1872 - accuracy: 0.8807 - val_loss: 0.3278 - val_accuracy: 0.8755\n",
      "Epoch 973/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1401 - accuracy: 0.8842 - val_loss: 0.3214 - val_accuracy: 0.8759\n",
      "Epoch 974/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1413 - accuracy: 0.8846 - val_loss: 0.3296 - val_accuracy: 0.8708\n",
      "Epoch 975/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2635 - accuracy: 0.8781 - val_loss: 0.3972 - val_accuracy: 0.8373\n",
      "Epoch 976/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.9551 - accuracy: 0.8440 - val_loss: 0.4229 - val_accuracy: 0.8301\n",
      "Epoch 977/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5746 - accuracy: 0.8673 - val_loss: 0.3644 - val_accuracy: 0.8616\n",
      "Epoch 978/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2666 - accuracy: 0.8803 - val_loss: 0.3283 - val_accuracy: 0.8736\n",
      "Epoch 979/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1659 - accuracy: 0.8830 - val_loss: 0.3078 - val_accuracy: 0.8826\n",
      "Epoch 980/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2570 - accuracy: 0.8781 - val_loss: 0.3152 - val_accuracy: 0.8799\n",
      "Epoch 981/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1908 - accuracy: 0.8834 - val_loss: 0.3352 - val_accuracy: 0.8682\n",
      "Epoch 982/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2073 - accuracy: 0.8791 - val_loss: 0.3098 - val_accuracy: 0.8819\n",
      "Epoch 983/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2406 - accuracy: 0.8784 - val_loss: 0.3034 - val_accuracy: 0.8866\n",
      "Epoch 984/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1823 - accuracy: 0.8840 - val_loss: 0.3330 - val_accuracy: 0.8705\n",
      "Epoch 985/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1862 - accuracy: 0.8828 - val_loss: 0.3368 - val_accuracy: 0.8694\n",
      "Epoch 986/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1081 - accuracy: 0.8850 - val_loss: 0.3120 - val_accuracy: 0.8811\n",
      "Epoch 987/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1011 - accuracy: 0.8853 - val_loss: 0.3063 - val_accuracy: 0.8833\n",
      "Epoch 988/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0888 - accuracy: 0.8861 - val_loss: 0.3148 - val_accuracy: 0.8787\n",
      "Epoch 989/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3121 - accuracy: 0.8754 - val_loss: 0.3778 - val_accuracy: 0.8499\n",
      "Epoch 990/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 4.0821 - accuracy: 0.8391 - val_loss: 0.5801 - val_accuracy: 0.7856\n",
      "Epoch 991/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.9841 - accuracy: 0.8491 - val_loss: 0.3829 - val_accuracy: 0.8540\n",
      "Epoch 992/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.4469 - accuracy: 0.8719 - val_loss: 0.3261 - val_accuracy: 0.8752\n",
      "Epoch 993/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2820 - accuracy: 0.8781 - val_loss: 0.3305 - val_accuracy: 0.8720\n",
      "Epoch 994/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1979 - accuracy: 0.8821 - val_loss: 0.3176 - val_accuracy: 0.8772\n",
      "Epoch 995/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1472 - accuracy: 0.8825 - val_loss: 0.3037 - val_accuracy: 0.8851\n",
      "Epoch 996/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1654 - accuracy: 0.8832 - val_loss: 0.3124 - val_accuracy: 0.8800\n",
      "Epoch 997/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1544 - accuracy: 0.8832 - val_loss: 0.3098 - val_accuracy: 0.8817\n",
      "Epoch 998/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2309 - accuracy: 0.8792 - val_loss: 0.3354 - val_accuracy: 0.8693\n",
      "Epoch 999/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2312 - accuracy: 0.8805 - val_loss: 0.3239 - val_accuracy: 0.8753\n",
      "Epoch 1000/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4171 - accuracy: 0.8712 - val_loss: 0.4786 - val_accuracy: 0.8042\n",
      "Epoch 1001/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7252 - accuracy: 0.8565 - val_loss: 0.4301 - val_accuracy: 0.8272\n",
      "Epoch 1002/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3845 - accuracy: 0.8726 - val_loss: 0.3636 - val_accuracy: 0.8586\n",
      "Epoch 1003/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1864 - accuracy: 0.8824 - val_loss: 0.3087 - val_accuracy: 0.8829\n",
      "Epoch 1004/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1142 - accuracy: 0.8853 - val_loss: 0.3015 - val_accuracy: 0.8860\n",
      "Epoch 1005/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1323 - accuracy: 0.8851 - val_loss: 0.3440 - val_accuracy: 0.8626\n",
      "Epoch 1006/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1911 - accuracy: 0.8807 - val_loss: 0.3039 - val_accuracy: 0.8861\n",
      "Epoch 1007/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1424 - accuracy: 0.8847 - val_loss: 0.3334 - val_accuracy: 0.8702\n",
      "Epoch 1008/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1475 - accuracy: 0.8836 - val_loss: 0.3526 - val_accuracy: 0.8596\n",
      "Epoch 1009/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1831 - accuracy: 0.8817 - val_loss: 0.3807 - val_accuracy: 0.8453\n",
      "Epoch 1010/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.2051 - accuracy: 0.8795 - val_loss: 0.3206 - val_accuracy: 0.8780\n",
      "Epoch 1011/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.3740 - accuracy: 0.8705 - val_loss: 0.3435 - val_accuracy: 0.8680\n",
      "Epoch 1012/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.8295 - accuracy: 0.8498 - val_loss: 0.3140 - val_accuracy: 0.8820\n",
      "Epoch 1013/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5159 - accuracy: 0.8702 - val_loss: 0.3204 - val_accuracy: 0.8807\n",
      "Epoch 1014/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3332 - accuracy: 0.8764 - val_loss: 0.3115 - val_accuracy: 0.8836\n",
      "Epoch 1015/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2992 - accuracy: 0.8776 - val_loss: 0.3032 - val_accuracy: 0.8854\n",
      "Epoch 1016/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1468 - accuracy: 0.8840 - val_loss: 0.3231 - val_accuracy: 0.8772\n",
      "Epoch 1017/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1671 - accuracy: 0.8834 - val_loss: 0.3418 - val_accuracy: 0.8639\n",
      "Epoch 1018/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1341 - accuracy: 0.8841 - val_loss: 0.3423 - val_accuracy: 0.8641\n",
      "Epoch 1019/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0945 - accuracy: 0.8855 - val_loss: 0.3034 - val_accuracy: 0.8852\n",
      "Epoch 1020/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0868 - accuracy: 0.8859 - val_loss: 0.3052 - val_accuracy: 0.8835\n",
      "Epoch 1021/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1216 - accuracy: 0.8852 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "Epoch 1022/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2434 - accuracy: 0.8783 - val_loss: 0.3317 - val_accuracy: 0.8712\n",
      "Epoch 1023/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1542 - accuracy: 0.8839 - val_loss: 0.3233 - val_accuracy: 0.8771\n",
      "Epoch 1024/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0931 - accuracy: 0.8859 - val_loss: 0.3027 - val_accuracy: 0.8857\n",
      "Epoch 1025/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2326 - accuracy: 0.8804 - val_loss: 0.3906 - val_accuracy: 0.8408\n",
      "Epoch 1026/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7525 - accuracy: 0.8544 - val_loss: 0.3714 - val_accuracy: 0.8528\n",
      "Epoch 1027/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4946 - accuracy: 0.8696 - val_loss: 0.3570 - val_accuracy: 0.8654\n",
      "Epoch 1028/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3843 - accuracy: 0.8729 - val_loss: 0.3114 - val_accuracy: 0.8834\n",
      "Epoch 1029/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3108 - accuracy: 0.8775 - val_loss: 0.3109 - val_accuracy: 0.8820\n",
      "Epoch 1030/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1699 - accuracy: 0.8842 - val_loss: 0.3334 - val_accuracy: 0.8708\n",
      "Epoch 1031/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1669 - accuracy: 0.8821 - val_loss: 0.3108 - val_accuracy: 0.8812\n",
      "Epoch 1032/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0925 - accuracy: 0.8868 - val_loss: 0.3042 - val_accuracy: 0.8844\n",
      "Epoch 1033/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0939 - accuracy: 0.8864 - val_loss: 0.3079 - val_accuracy: 0.8825\n",
      "Epoch 1034/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1818 - accuracy: 0.8806 - val_loss: 0.3077 - val_accuracy: 0.8828\n",
      "Epoch 1035/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0951 - accuracy: 0.8866 - val_loss: 0.3297 - val_accuracy: 0.8707\n",
      "Epoch 1036/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0976 - accuracy: 0.8851 - val_loss: 0.3015 - val_accuracy: 0.8859\n",
      "Epoch 1037/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1650 - accuracy: 0.8826 - val_loss: 0.3074 - val_accuracy: 0.8841\n",
      "Epoch 1038/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1746 - accuracy: 0.8829 - val_loss: 0.3026 - val_accuracy: 0.8864\n",
      "Epoch 1039/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1223 - accuracy: 0.8854 - val_loss: 0.3249 - val_accuracy: 0.8744\n",
      "Epoch 1040/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0725 - accuracy: 0.8855 - val_loss: 0.3249 - val_accuracy: 0.8759\n",
      "Epoch 1041/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.0133 - accuracy: 0.8433 - val_loss: 0.4460 - val_accuracy: 0.8210\n",
      "Epoch 1042/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4998 - accuracy: 0.8698 - val_loss: 0.3579 - val_accuracy: 0.8658\n",
      "Epoch 1043/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2425 - accuracy: 0.8790 - val_loss: 0.3093 - val_accuracy: 0.8829\n",
      "Epoch 1044/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1502 - accuracy: 0.8847 - val_loss: 0.3434 - val_accuracy: 0.8626\n",
      "Epoch 1045/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2403 - accuracy: 0.8788 - val_loss: 0.3681 - val_accuracy: 0.8523\n",
      "Epoch 1046/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7409 - accuracy: 0.8530 - val_loss: 0.3901 - val_accuracy: 0.8410\n",
      "Epoch 1047/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5662 - accuracy: 0.8657 - val_loss: 0.3511 - val_accuracy: 0.8682\n",
      "Epoch 1048/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2960 - accuracy: 0.8781 - val_loss: 0.3167 - val_accuracy: 0.8798\n",
      "Epoch 1049/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1928 - accuracy: 0.8821 - val_loss: 0.3206 - val_accuracy: 0.8749\n",
      "Epoch 1050/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1322 - accuracy: 0.8829 - val_loss: 0.3007 - val_accuracy: 0.8860\n",
      "Epoch 1051/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1528 - accuracy: 0.8834 - val_loss: 0.3062 - val_accuracy: 0.8843\n",
      "Epoch 1052/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0899 - accuracy: 0.8862 - val_loss: 0.3224 - val_accuracy: 0.8757\n",
      "Epoch 1053/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0596 - accuracy: 0.8874 - val_loss: 0.3063 - val_accuracy: 0.8830\n",
      "Epoch 1054/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1093 - accuracy: 0.8847 - val_loss: 0.3257 - val_accuracy: 0.8739\n",
      "Epoch 1055/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1321 - accuracy: 0.8835 - val_loss: 0.3013 - val_accuracy: 0.8863\n",
      "Epoch 1056/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1371 - accuracy: 0.8834 - val_loss: 0.3013 - val_accuracy: 0.8866\n",
      "Epoch 1057/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1751 - accuracy: 0.8825 - val_loss: 0.3175 - val_accuracy: 0.8786\n",
      "Epoch 1058/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2158 - accuracy: 0.8796 - val_loss: 0.3019 - val_accuracy: 0.8871\n",
      "Epoch 1059/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1136 - accuracy: 0.8859 - val_loss: 0.3100 - val_accuracy: 0.8817\n",
      "Epoch 1060/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1167 - accuracy: 0.8847 - val_loss: 0.3370 - val_accuracy: 0.8669\n",
      "Epoch 1061/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2119 - accuracy: 0.8801 - val_loss: 0.3891 - val_accuracy: 0.8407\n",
      "Epoch 1062/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3815 - accuracy: 0.8715 - val_loss: 0.3090 - val_accuracy: 0.8837\n",
      "Epoch 1063/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1617 - accuracy: 0.8830 - val_loss: 0.3091 - val_accuracy: 0.8824\n",
      "Epoch 1064/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.1796 - accuracy: 0.8828 - val_loss: 0.3112 - val_accuracy: 0.8808\n",
      "Epoch 1065/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1296 - accuracy: 0.8842 - val_loss: 0.3855 - val_accuracy: 0.8416\n",
      "Epoch 1066/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4425 - accuracy: 0.8679 - val_loss: 0.3099 - val_accuracy: 0.8840\n",
      "Epoch 1067/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3188 - accuracy: 0.8768 - val_loss: 0.3892 - val_accuracy: 0.8459\n",
      "Epoch 1068/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6346 - accuracy: 0.8593 - val_loss: 0.3330 - val_accuracy: 0.8716\n",
      "Epoch 1069/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4766 - accuracy: 0.8700 - val_loss: 0.3737 - val_accuracy: 0.8532\n",
      "Epoch 1070/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3139 - accuracy: 0.8769 - val_loss: 0.3379 - val_accuracy: 0.8699\n",
      "Epoch 1071/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1251 - accuracy: 0.8842 - val_loss: 0.2993 - val_accuracy: 0.8860\n",
      "Epoch 1072/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0736 - accuracy: 0.8864 - val_loss: 0.2997 - val_accuracy: 0.8860\n",
      "Epoch 1073/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0966 - accuracy: 0.8851 - val_loss: 0.3025 - val_accuracy: 0.8861\n",
      "Epoch 1074/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.2012 - accuracy: 0.8807 - val_loss: 0.3030 - val_accuracy: 0.8864\n",
      "Epoch 1075/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1746 - accuracy: 0.8835 - val_loss: 0.3329 - val_accuracy: 0.8709\n",
      "Epoch 1076/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2234 - accuracy: 0.8795 - val_loss: 0.3143 - val_accuracy: 0.8804\n",
      "Epoch 1077/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 4.3853 - accuracy: 0.8225 - val_loss: 0.3842 - val_accuracy: 0.8583\n",
      "Epoch 1078/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.9800 - accuracy: 0.8486 - val_loss: 0.3652 - val_accuracy: 0.8649\n",
      "Epoch 1079/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4697 - accuracy: 0.8735 - val_loss: 0.3380 - val_accuracy: 0.8699\n",
      "Epoch 1080/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2463 - accuracy: 0.8811 - val_loss: 0.3376 - val_accuracy: 0.8690\n",
      "Epoch 1081/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1692 - accuracy: 0.8830 - val_loss: 0.3096 - val_accuracy: 0.8805\n",
      "Epoch 1082/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1005 - accuracy: 0.8855 - val_loss: 0.3168 - val_accuracy: 0.8771\n",
      "Epoch 1083/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1014 - accuracy: 0.8848 - val_loss: 0.3041 - val_accuracy: 0.8840\n",
      "Epoch 1084/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0866 - accuracy: 0.8863 - val_loss: 0.3538 - val_accuracy: 0.8570\n",
      "Epoch 1085/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1266 - accuracy: 0.8832 - val_loss: 0.3262 - val_accuracy: 0.8726\n",
      "Epoch 1086/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0517 - accuracy: 0.8872 - val_loss: 0.3082 - val_accuracy: 0.8814\n",
      "Epoch 1087/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0994 - accuracy: 0.8844 - val_loss: 0.3261 - val_accuracy: 0.8742\n",
      "Epoch 1088/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2042 - accuracy: 0.8819 - val_loss: 0.3395 - val_accuracy: 0.8665\n",
      "Epoch 1089/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2628 - accuracy: 0.8778 - val_loss: 0.3190 - val_accuracy: 0.8793\n",
      "Epoch 1090/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1841 - accuracy: 0.8817 - val_loss: 0.3288 - val_accuracy: 0.8745\n",
      "Epoch 1091/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1659 - accuracy: 0.8834 - val_loss: 0.3463 - val_accuracy: 0.8642\n",
      "Epoch 1092/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1261 - accuracy: 0.8836 - val_loss: 0.3253 - val_accuracy: 0.8737\n",
      "Epoch 1093/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1304 - accuracy: 0.8833 - val_loss: 0.3077 - val_accuracy: 0.8828\n",
      "Epoch 1094/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0987 - accuracy: 0.8862 - val_loss: 0.3406 - val_accuracy: 0.8661\n",
      "Epoch 1095/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.2451 - accuracy: 0.8778 - val_loss: 0.3223 - val_accuracy: 0.8768\n",
      "Epoch 1096/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1518 - accuracy: 0.8832 - val_loss: 0.3019 - val_accuracy: 0.8862\n",
      "Epoch 1097/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0662 - accuracy: 0.8874 - val_loss: 0.3037 - val_accuracy: 0.8854\n",
      "Epoch 1098/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1424 - accuracy: 0.8834 - val_loss: 0.2996 - val_accuracy: 0.8868\n",
      "Epoch 1099/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0633 - accuracy: 0.8881 - val_loss: 0.3043 - val_accuracy: 0.8847\n",
      "Epoch 1100/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0970 - accuracy: 0.8850 - val_loss: 0.3252 - val_accuracy: 0.8732\n",
      "Epoch 1101/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0630 - accuracy: 0.8868 - val_loss: 0.2965 - val_accuracy: 0.8883\n",
      "Epoch 1102/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1648 - accuracy: 0.8823 - val_loss: 0.3653 - val_accuracy: 0.8559\n",
      "Epoch 1103/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3249 - accuracy: 0.8753 - val_loss: 0.3457 - val_accuracy: 0.8653\n",
      "Epoch 1104/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7234 - accuracy: 0.8548 - val_loss: 0.3263 - val_accuracy: 0.8773\n",
      "Epoch 1105/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3195 - accuracy: 0.8766 - val_loss: 0.3271 - val_accuracy: 0.8765\n",
      "Epoch 1106/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1559 - accuracy: 0.8837 - val_loss: 0.3335 - val_accuracy: 0.8696\n",
      "Epoch 1107/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0986 - accuracy: 0.8859 - val_loss: 0.3258 - val_accuracy: 0.8725\n",
      "Epoch 1108/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0423 - accuracy: 0.8878 - val_loss: 0.3152 - val_accuracy: 0.8791\n",
      "Epoch 1109/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1022 - accuracy: 0.8847 - val_loss: 0.3253 - val_accuracy: 0.8742\n",
      "Epoch 1110/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1624 - accuracy: 0.8829 - val_loss: 0.3472 - val_accuracy: 0.8649\n",
      "Epoch 1111/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0736 - accuracy: 0.8871 - val_loss: 0.3607 - val_accuracy: 0.8555\n",
      "Epoch 1112/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6875 - accuracy: 0.8554 - val_loss: 0.3413 - val_accuracy: 0.8743\n",
      "Epoch 1113/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.5492 - accuracy: 0.8660 - val_loss: 0.3135 - val_accuracy: 0.8838\n",
      "Epoch 1114/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2014 - accuracy: 0.8834 - val_loss: 0.3168 - val_accuracy: 0.8787\n",
      "Epoch 1115/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1087 - accuracy: 0.8847 - val_loss: 0.3133 - val_accuracy: 0.8792\n",
      "Epoch 1116/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0552 - accuracy: 0.8881 - val_loss: 0.3247 - val_accuracy: 0.8734\n",
      "Epoch 1117/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0543 - accuracy: 0.8866 - val_loss: 0.3441 - val_accuracy: 0.8635\n",
      "Epoch 1118/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0754 - accuracy: 0.8860 - val_loss: 0.3242 - val_accuracy: 0.8748\n",
      "Epoch 1119/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0334 - accuracy: 0.8878 - val_loss: 0.3323 - val_accuracy: 0.8688\n",
      "Epoch 1120/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1333 - accuracy: 0.8825 - val_loss: 0.2968 - val_accuracy: 0.8881\n",
      "Epoch 1121/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1065 - accuracy: 0.8840 - val_loss: 0.2948 - val_accuracy: 0.8898\n",
      "Epoch 1122/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2935 - accuracy: 0.8770 - val_loss: 0.3234 - val_accuracy: 0.8786\n",
      "Epoch 1123/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0900 - accuracy: 0.8863 - val_loss: 0.3308 - val_accuracy: 0.8695\n",
      "Epoch 1124/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0310 - accuracy: 0.8885 - val_loss: 0.3051 - val_accuracy: 0.8836\n",
      "Epoch 1125/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3395 - accuracy: 0.8734 - val_loss: 0.3187 - val_accuracy: 0.8814\n",
      "Epoch 1126/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5063 - accuracy: 0.8676 - val_loss: 0.3011 - val_accuracy: 0.8892\n",
      "Epoch 1127/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4178 - accuracy: 0.8715 - val_loss: 0.3114 - val_accuracy: 0.8836\n",
      "Epoch 1128/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3305 - accuracy: 0.8766 - val_loss: 0.4536 - val_accuracy: 0.8106\n",
      "Epoch 1129/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2854 - accuracy: 0.8771 - val_loss: 0.3455 - val_accuracy: 0.8660\n",
      "Epoch 1130/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2139 - accuracy: 0.8784 - val_loss: 0.3305 - val_accuracy: 0.8717\n",
      "Epoch 1131/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5590 - accuracy: 0.8640 - val_loss: 0.3291 - val_accuracy: 0.8776\n",
      "Epoch 1132/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3205 - accuracy: 0.8772 - val_loss: 0.3045 - val_accuracy: 0.8849\n",
      "Epoch 1133/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1221 - accuracy: 0.8854 - val_loss: 0.3196 - val_accuracy: 0.8770\n",
      "Epoch 1134/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0446 - accuracy: 0.8876 - val_loss: 0.3013 - val_accuracy: 0.8853\n",
      "Epoch 1135/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1938 - accuracy: 0.8791 - val_loss: 0.3017 - val_accuracy: 0.8866\n",
      "Epoch 1136/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1401 - accuracy: 0.8854 - val_loss: 0.3424 - val_accuracy: 0.8665\n",
      "Epoch 1137/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0384 - accuracy: 0.8879 - val_loss: 0.3120 - val_accuracy: 0.8810\n",
      "Epoch 1138/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0278 - accuracy: 0.8875 - val_loss: 0.3083 - val_accuracy: 0.8824\n",
      "Epoch 1139/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2424 - accuracy: 0.8786 - val_loss: 0.3342 - val_accuracy: 0.8696\n",
      "Epoch 1140/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1394 - accuracy: 0.8825 - val_loss: 0.3248 - val_accuracy: 0.8771\n",
      "Epoch 1141/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0226 - accuracy: 0.8889 - val_loss: 0.2980 - val_accuracy: 0.8865\n",
      "Epoch 1142/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9874 - accuracy: 0.8904 - val_loss: 0.3176 - val_accuracy: 0.8759\n",
      "Epoch 1143/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3325 - accuracy: 0.8732 - val_loss: 0.4509 - val_accuracy: 0.8174\n",
      "Epoch 1144/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 4.2130 - accuracy: 0.8322 - val_loss: 0.4100 - val_accuracy: 0.8405\n",
      "Epoch 1145/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8050 - accuracy: 0.8533 - val_loss: 0.3596 - val_accuracy: 0.8625\n",
      "Epoch 1146/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4145 - accuracy: 0.8722 - val_loss: 0.3252 - val_accuracy: 0.8766\n",
      "Epoch 1147/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.1488 - accuracy: 0.8844 - val_loss: 0.3072 - val_accuracy: 0.8829\n",
      "Epoch 1148/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1198 - accuracy: 0.8843 - val_loss: 0.3176 - val_accuracy: 0.8778\n",
      "Epoch 1149/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1233 - accuracy: 0.8824 - val_loss: 0.3310 - val_accuracy: 0.8713\n",
      "Epoch 1150/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6250 - accuracy: 0.8596 - val_loss: 0.3412 - val_accuracy: 0.8731\n",
      "Epoch 1151/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3973 - accuracy: 0.8737 - val_loss: 0.3030 - val_accuracy: 0.8876\n",
      "Epoch 1152/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1530 - accuracy: 0.8848 - val_loss: 0.3100 - val_accuracy: 0.8825\n",
      "Epoch 1153/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3481 - accuracy: 0.8741 - val_loss: 0.3088 - val_accuracy: 0.8843\n",
      "Epoch 1154/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3498 - accuracy: 0.8723 - val_loss: 0.3070 - val_accuracy: 0.8858\n",
      "Epoch 1155/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1636 - accuracy: 0.8837 - val_loss: 0.2967 - val_accuracy: 0.8885\n",
      "Epoch 1156/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1371 - accuracy: 0.8849 - val_loss: 0.3108 - val_accuracy: 0.8801\n",
      "Epoch 1157/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7663 - accuracy: 0.8548 - val_loss: 0.4316 - val_accuracy: 0.8213\n",
      "Epoch 1158/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8613 - accuracy: 0.8452 - val_loss: 0.3580 - val_accuracy: 0.8655\n",
      "Epoch 1159/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4149 - accuracy: 0.8743 - val_loss: 0.3490 - val_accuracy: 0.8647\n",
      "Epoch 1160/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2603 - accuracy: 0.8788 - val_loss: 0.3530 - val_accuracy: 0.8599\n",
      "Epoch 1161/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1362 - accuracy: 0.8818 - val_loss: 0.3135 - val_accuracy: 0.8791\n",
      "Epoch 1162/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0915 - accuracy: 0.8853 - val_loss: 0.2967 - val_accuracy: 0.8876\n",
      "Epoch 1163/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0745 - accuracy: 0.8869 - val_loss: 0.3248 - val_accuracy: 0.8730\n",
      "Epoch 1164/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0337 - accuracy: 0.8875 - val_loss: 0.3094 - val_accuracy: 0.8810\n",
      "Epoch 1165/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0073 - accuracy: 0.8894 - val_loss: 0.3170 - val_accuracy: 0.8760\n",
      "Epoch 1166/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0453 - accuracy: 0.8870 - val_loss: 0.3089 - val_accuracy: 0.8817\n",
      "Epoch 1167/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1539 - accuracy: 0.8826 - val_loss: 0.3343 - val_accuracy: 0.8685\n",
      "Epoch 1168/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1051 - accuracy: 0.8830 - val_loss: 0.2974 - val_accuracy: 0.8887\n",
      "Epoch 1169/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1099 - accuracy: 0.8857 - val_loss: 0.3068 - val_accuracy: 0.8837\n",
      "Epoch 1170/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0182 - accuracy: 0.8897 - val_loss: 0.2986 - val_accuracy: 0.8863\n",
      "Epoch 1171/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0249 - accuracy: 0.8880 - val_loss: 0.3154 - val_accuracy: 0.8777\n",
      "Epoch 1172/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0032 - accuracy: 0.8887 - val_loss: 0.3173 - val_accuracy: 0.8771\n",
      "Epoch 1173/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.1519 - accuracy: 0.8825 - val_loss: 0.3062 - val_accuracy: 0.8835\n",
      "Epoch 1174/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0628 - accuracy: 0.8871 - val_loss: 0.3121 - val_accuracy: 0.8810\n",
      "Epoch 1175/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1138 - accuracy: 0.8832 - val_loss: 0.2999 - val_accuracy: 0.8877\n",
      "Epoch 1176/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4906 - accuracy: 0.8678 - val_loss: 0.3204 - val_accuracy: 0.8809\n",
      "Epoch 1177/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.6062 - accuracy: 0.8609 - val_loss: 0.3237 - val_accuracy: 0.8806\n",
      "Epoch 1178/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2786 - accuracy: 0.8781 - val_loss: 0.2963 - val_accuracy: 0.8890\n",
      "Epoch 1179/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1151 - accuracy: 0.8868 - val_loss: 0.2992 - val_accuracy: 0.8863\n",
      "Epoch 1180/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0193 - accuracy: 0.8894 - val_loss: 0.3000 - val_accuracy: 0.8861\n",
      "Epoch 1181/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0073 - accuracy: 0.8889 - val_loss: 0.2957 - val_accuracy: 0.8874\n",
      "Epoch 1182/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0216 - accuracy: 0.8893 - val_loss: 0.3441 - val_accuracy: 0.8636\n",
      "Epoch 1183/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0675 - accuracy: 0.8860 - val_loss: 0.3522 - val_accuracy: 0.8596\n",
      "Epoch 1184/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0574 - accuracy: 0.8860 - val_loss: 0.3110 - val_accuracy: 0.8810\n",
      "Epoch 1185/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0645 - accuracy: 0.8865 - val_loss: 0.3480 - val_accuracy: 0.8596\n",
      "Epoch 1186/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0623 - accuracy: 0.8862 - val_loss: 0.3080 - val_accuracy: 0.8830\n",
      "Epoch 1187/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0034 - accuracy: 0.8894 - val_loss: 0.2955 - val_accuracy: 0.8879\n",
      "Epoch 1188/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0089 - accuracy: 0.8885 - val_loss: 0.2936 - val_accuracy: 0.8889\n",
      "Epoch 1189/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1260 - accuracy: 0.8841 - val_loss: 0.2942 - val_accuracy: 0.8892\n",
      "Epoch 1190/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1215 - accuracy: 0.8829 - val_loss: 0.3316 - val_accuracy: 0.8712\n",
      "Epoch 1191/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2206 - accuracy: 0.8806 - val_loss: 0.4087 - val_accuracy: 0.8322\n",
      "Epoch 1192/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.7487 - accuracy: 0.8540 - val_loss: 0.4573 - val_accuracy: 0.8149\n",
      "Epoch 1193/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3784 - accuracy: 0.8717 - val_loss: 0.3673 - val_accuracy: 0.8558\n",
      "Epoch 1194/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1326 - accuracy: 0.8834 - val_loss: 0.3028 - val_accuracy: 0.8851\n",
      "Epoch 1195/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1615 - accuracy: 0.8829 - val_loss: 0.3209 - val_accuracy: 0.8759\n",
      "Epoch 1196/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.6380 - accuracy: 0.8577 - val_loss: 0.3334 - val_accuracy: 0.8732\n",
      "Epoch 1197/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.3204 - accuracy: 0.8768 - val_loss: 0.3404 - val_accuracy: 0.8705\n",
      "Epoch 1198/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1035 - accuracy: 0.8845 - val_loss: 0.3042 - val_accuracy: 0.8846\n",
      "Epoch 1199/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0500 - accuracy: 0.8878 - val_loss: 0.3226 - val_accuracy: 0.8730\n",
      "Epoch 1200/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0514 - accuracy: 0.8866 - val_loss: 0.3172 - val_accuracy: 0.8762\n",
      "Epoch 1201/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0060 - accuracy: 0.8883 - val_loss: 0.2904 - val_accuracy: 0.8905\n",
      "Epoch 1202/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1778 - accuracy: 0.8793 - val_loss: 0.3242 - val_accuracy: 0.8755\n",
      "Epoch 1203/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7563 - accuracy: 0.8545 - val_loss: 0.4740 - val_accuracy: 0.8107\n",
      "Epoch 1204/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1102 - accuracy: 0.8377 - val_loss: 0.3664 - val_accuracy: 0.8670\n",
      "Epoch 1205/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4287 - accuracy: 0.8734 - val_loss: 0.3552 - val_accuracy: 0.8606\n",
      "Epoch 1206/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2148 - accuracy: 0.8806 - val_loss: 0.3142 - val_accuracy: 0.8795\n",
      "Epoch 1207/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0701 - accuracy: 0.8868 - val_loss: 0.3141 - val_accuracy: 0.8784\n",
      "Epoch 1208/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0145 - accuracy: 0.8894 - val_loss: 0.3010 - val_accuracy: 0.8849\n",
      "Epoch 1209/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0840 - accuracy: 0.8841 - val_loss: 0.2993 - val_accuracy: 0.8865\n",
      "Epoch 1210/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1529 - accuracy: 0.8834 - val_loss: 0.3137 - val_accuracy: 0.8793\n",
      "Epoch 1211/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1298 - accuracy: 0.8836 - val_loss: 0.4225 - val_accuracy: 0.8232\n",
      "Epoch 1212/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.7019 - accuracy: 0.8570 - val_loss: 0.3982 - val_accuracy: 0.8409\n",
      "Epoch 1213/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3951 - accuracy: 0.8710 - val_loss: 0.3128 - val_accuracy: 0.8833\n",
      "Epoch 1214/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1940 - accuracy: 0.8814 - val_loss: 0.3092 - val_accuracy: 0.8828\n",
      "Epoch 1215/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1613 - accuracy: 0.8818 - val_loss: 0.4173 - val_accuracy: 0.8265\n",
      "Epoch 1216/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.4320 - accuracy: 0.8673 - val_loss: 0.3704 - val_accuracy: 0.8523\n",
      "Epoch 1217/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1873 - accuracy: 0.8821 - val_loss: 0.3465 - val_accuracy: 0.8650\n",
      "Epoch 1218/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1429 - accuracy: 0.8832 - val_loss: 0.3023 - val_accuracy: 0.8866\n",
      "Epoch 1219/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1844 - accuracy: 0.8825 - val_loss: 0.2960 - val_accuracy: 0.8887\n",
      "Epoch 1220/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0447 - accuracy: 0.8882 - val_loss: 0.3448 - val_accuracy: 0.8638\n",
      "Epoch 1221/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0667 - accuracy: 0.8854 - val_loss: 0.3042 - val_accuracy: 0.8847\n",
      "Epoch 1222/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.3823 - accuracy: 0.8711 - val_loss: 0.3106 - val_accuracy: 0.8842\n",
      "Epoch 1223/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2926 - accuracy: 0.8753 - val_loss: 0.3052 - val_accuracy: 0.8851\n",
      "Epoch 1224/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1092 - accuracy: 0.8867 - val_loss: 0.2998 - val_accuracy: 0.8871\n",
      "Epoch 1225/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1759 - accuracy: 0.8824 - val_loss: 0.4259 - val_accuracy: 0.8216\n",
      "Epoch 1226/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3706 - accuracy: 0.8710 - val_loss: 0.4016 - val_accuracy: 0.8375\n",
      "Epoch 1227/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2011 - accuracy: 0.8801 - val_loss: 0.3308 - val_accuracy: 0.8739\n",
      "Epoch 1228/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0203 - accuracy: 0.8898 - val_loss: 0.3025 - val_accuracy: 0.8843\n",
      "Epoch 1229/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9871 - accuracy: 0.8898 - val_loss: 0.2928 - val_accuracy: 0.8886\n",
      "Epoch 1230/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0787 - accuracy: 0.8845 - val_loss: 0.2920 - val_accuracy: 0.8901\n",
      "Epoch 1231/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0306 - accuracy: 0.8886 - val_loss: 0.3123 - val_accuracy: 0.8800\n",
      "Epoch 1232/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9897 - accuracy: 0.8903 - val_loss: 0.3128 - val_accuracy: 0.8792\n",
      "Epoch 1233/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0625 - accuracy: 0.8854 - val_loss: 0.2996 - val_accuracy: 0.8863\n",
      "Epoch 1234/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1291 - accuracy: 0.8829 - val_loss: 0.3732 - val_accuracy: 0.8502\n",
      "Epoch 1235/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.6459 - accuracy: 0.8581 - val_loss: 0.4381 - val_accuracy: 0.8219\n",
      "Epoch 1236/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.4112 - accuracy: 0.8719 - val_loss: 0.3721 - val_accuracy: 0.8530\n",
      "Epoch 1237/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1657 - accuracy: 0.8821 - val_loss: 0.3634 - val_accuracy: 0.8574\n",
      "Epoch 1238/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2401 - accuracy: 0.8770 - val_loss: 0.3058 - val_accuracy: 0.8838\n",
      "Epoch 1239/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2712 - accuracy: 0.8773 - val_loss: 0.3055 - val_accuracy: 0.8855\n",
      "Epoch 1240/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1572 - accuracy: 0.8833 - val_loss: 0.2947 - val_accuracy: 0.8892\n",
      "Epoch 1241/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0242 - accuracy: 0.8889 - val_loss: 0.2947 - val_accuracy: 0.8885\n",
      "Epoch 1242/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1222 - accuracy: 0.8840 - val_loss: 0.3797 - val_accuracy: 0.8458\n",
      "Epoch 1243/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4439 - accuracy: 0.8669 - val_loss: 0.4144 - val_accuracy: 0.8297\n",
      "Epoch 1244/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2295 - accuracy: 0.8796 - val_loss: 0.3623 - val_accuracy: 0.8587\n",
      "Epoch 1245/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0556 - accuracy: 0.8871 - val_loss: 0.3460 - val_accuracy: 0.8645\n",
      "Epoch 1246/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2886 - accuracy: 0.8733 - val_loss: 0.3550 - val_accuracy: 0.8631\n",
      "Epoch 1247/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4804 - accuracy: 0.8702 - val_loss: 0.3718 - val_accuracy: 0.8546\n",
      "Epoch 1248/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1826 - accuracy: 0.8821 - val_loss: 0.3535 - val_accuracy: 0.8637\n",
      "Epoch 1249/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0975 - accuracy: 0.8856 - val_loss: 0.3312 - val_accuracy: 0.8695\n",
      "Epoch 1250/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0257 - accuracy: 0.8871 - val_loss: 0.2917 - val_accuracy: 0.8898\n",
      "Epoch 1251/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9967 - accuracy: 0.8905 - val_loss: 0.3163 - val_accuracy: 0.8769\n",
      "Epoch 1252/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9919 - accuracy: 0.8893 - val_loss: 0.2944 - val_accuracy: 0.8885\n",
      "Epoch 1253/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9779 - accuracy: 0.8895 - val_loss: 0.2949 - val_accuracy: 0.8880\n",
      "Epoch 1254/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9928 - accuracy: 0.8889 - val_loss: 0.2961 - val_accuracy: 0.8872\n",
      "Epoch 1255/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 2.9960 - accuracy: 0.8899 - val_loss: 0.2937 - val_accuracy: 0.8888\n",
      "Epoch 1256/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9676 - accuracy: 0.8914 - val_loss: 0.2974 - val_accuracy: 0.8871\n",
      "Epoch 1257/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 2.9416 - accuracy: 0.8917 - val_loss: 0.3122 - val_accuracy: 0.8793\n",
      "Epoch 1258/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0570 - accuracy: 0.8858 - val_loss: 0.3502 - val_accuracy: 0.8591\n",
      "Epoch 1259/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1857 - accuracy: 0.8792 - val_loss: 0.3233 - val_accuracy: 0.8757\n",
      "Epoch 1260/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5373 - accuracy: 0.8634 - val_loss: 0.3478 - val_accuracy: 0.8668\n",
      "Epoch 1261/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3921 - accuracy: 0.8726 - val_loss: 0.3226 - val_accuracy: 0.8788\n",
      "Epoch 1262/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1077 - accuracy: 0.8851 - val_loss: 0.3122 - val_accuracy: 0.8806\n",
      "Epoch 1263/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0136 - accuracy: 0.8898 - val_loss: 0.3113 - val_accuracy: 0.8794\n",
      "Epoch 1264/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9618 - accuracy: 0.8906 - val_loss: 0.3034 - val_accuracy: 0.8835\n",
      "Epoch 1265/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9529 - accuracy: 0.8908 - val_loss: 0.2966 - val_accuracy: 0.8871\n",
      "Epoch 1266/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9826 - accuracy: 0.8904 - val_loss: 0.3174 - val_accuracy: 0.8763\n",
      "Epoch 1267/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0045 - accuracy: 0.8884 - val_loss: 0.2928 - val_accuracy: 0.8889\n",
      "Epoch 1268/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9516 - accuracy: 0.8914 - val_loss: 0.3009 - val_accuracy: 0.8860\n",
      "Epoch 1269/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0696 - accuracy: 0.8851 - val_loss: 0.3057 - val_accuracy: 0.8830\n",
      "Epoch 1270/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2069 - accuracy: 0.8813 - val_loss: 0.3111 - val_accuracy: 0.8821\n",
      "Epoch 1271/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5000 - accuracy: 0.8648 - val_loss: 0.3461 - val_accuracy: 0.8654\n",
      "Epoch 1272/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1805 - accuracy: 0.8815 - val_loss: 0.3684 - val_accuracy: 0.8543\n",
      "Epoch 1273/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1899 - accuracy: 0.8781 - val_loss: 0.3324 - val_accuracy: 0.8707\n",
      "Epoch 1274/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5381 - accuracy: 0.8637 - val_loss: 0.3036 - val_accuracy: 0.8869\n",
      "Epoch 1275/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.1892 - accuracy: 0.8842 - val_loss: 0.3514 - val_accuracy: 0.8617\n",
      "Epoch 1276/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1896 - accuracy: 0.8797 - val_loss: 0.3027 - val_accuracy: 0.8852\n",
      "Epoch 1277/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0228 - accuracy: 0.8892 - val_loss: 0.2932 - val_accuracy: 0.8889\n",
      "Epoch 1278/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0025 - accuracy: 0.8902 - val_loss: 0.3107 - val_accuracy: 0.8808\n",
      "Epoch 1279/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9379 - accuracy: 0.8915 - val_loss: 0.2957 - val_accuracy: 0.8880\n",
      "Epoch 1280/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9295 - accuracy: 0.8923 - val_loss: 0.3282 - val_accuracy: 0.8701\n",
      "Epoch 1281/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9741 - accuracy: 0.8888 - val_loss: 0.2907 - val_accuracy: 0.8902\n",
      "Epoch 1282/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.0402 - accuracy: 0.8866 - val_loss: 0.3003 - val_accuracy: 0.8857\n",
      "Epoch 1283/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0017 - accuracy: 0.8889 - val_loss: 0.3220 - val_accuracy: 0.8753\n",
      "Epoch 1284/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0082 - accuracy: 0.8878 - val_loss: 0.2941 - val_accuracy: 0.8883\n",
      "Epoch 1285/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0303 - accuracy: 0.8871 - val_loss: 0.2926 - val_accuracy: 0.8901\n",
      "Epoch 1286/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9806 - accuracy: 0.8905 - val_loss: 0.3115 - val_accuracy: 0.8807\n",
      "Epoch 1287/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0327 - accuracy: 0.8874 - val_loss: 0.3003 - val_accuracy: 0.8861\n",
      "Epoch 1288/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9422 - accuracy: 0.8922 - val_loss: 0.2951 - val_accuracy: 0.8878\n",
      "Epoch 1289/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9836 - accuracy: 0.8881 - val_loss: 0.3602 - val_accuracy: 0.8587\n",
      "Epoch 1290/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4831 - accuracy: 0.8684 - val_loss: 0.5403 - val_accuracy: 0.7741\n",
      "Epoch 1291/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7012 - accuracy: 0.8546 - val_loss: 0.3357 - val_accuracy: 0.8770\n",
      "Epoch 1292/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2372 - accuracy: 0.8795 - val_loss: 0.3189 - val_accuracy: 0.8783\n",
      "Epoch 1293/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0357 - accuracy: 0.8881 - val_loss: 0.3097 - val_accuracy: 0.8808\n",
      "Epoch 1294/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9855 - accuracy: 0.8896 - val_loss: 0.2984 - val_accuracy: 0.8860\n",
      "Epoch 1295/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9741 - accuracy: 0.8892 - val_loss: 0.2864 - val_accuracy: 0.8923\n",
      "Epoch 1296/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9746 - accuracy: 0.8915 - val_loss: 0.3027 - val_accuracy: 0.8830\n",
      "Epoch 1297/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9434 - accuracy: 0.8912 - val_loss: 0.2944 - val_accuracy: 0.8876\n",
      "Epoch 1298/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9219 - accuracy: 0.8918 - val_loss: 0.3044 - val_accuracy: 0.8848\n",
      "Epoch 1299/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.7577 - accuracy: 0.8550 - val_loss: 0.4088 - val_accuracy: 0.8328\n",
      "Epoch 1300/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5927 - accuracy: 0.8607 - val_loss: 0.3338 - val_accuracy: 0.8742\n",
      "Epoch 1301/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3330 - accuracy: 0.8736 - val_loss: 0.3670 - val_accuracy: 0.8550\n",
      "Epoch 1302/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0902 - accuracy: 0.8853 - val_loss: 0.3064 - val_accuracy: 0.8832\n",
      "Epoch 1303/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9755 - accuracy: 0.8910 - val_loss: 0.3027 - val_accuracy: 0.8833\n",
      "Epoch 1304/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9633 - accuracy: 0.8912 - val_loss: 0.3250 - val_accuracy: 0.8707\n",
      "Epoch 1305/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9525 - accuracy: 0.8902 - val_loss: 0.2990 - val_accuracy: 0.8856\n",
      "Epoch 1306/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0772 - accuracy: 0.8841 - val_loss: 0.2931 - val_accuracy: 0.8898\n",
      "Epoch 1307/3000\n",
      "10/10 [==============================] - 1s 80ms/step - loss: 3.0526 - accuracy: 0.8867 - val_loss: 0.3123 - val_accuracy: 0.8795\n",
      "Epoch 1308/3000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 3.1372 - accuracy: 0.8824 - val_loss: 0.3213 - val_accuracy: 0.8761\n",
      "Epoch 1309/3000\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 3.0497 - accuracy: 0.8860 - val_loss: 0.2879 - val_accuracy: 0.8922\n",
      "Epoch 1310/3000\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 3.0212 - accuracy: 0.8885 - val_loss: 0.2931 - val_accuracy: 0.8895\n",
      "Epoch 1311/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9587 - accuracy: 0.8921 - val_loss: 0.3088 - val_accuracy: 0.8812\n",
      "Epoch 1312/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9643 - accuracy: 0.8896 - val_loss: 0.3161 - val_accuracy: 0.8776\n",
      "Epoch 1313/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0409 - accuracy: 0.8861 - val_loss: 0.2884 - val_accuracy: 0.8917\n",
      "Epoch 1314/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9989 - accuracy: 0.8904 - val_loss: 0.2909 - val_accuracy: 0.8898\n",
      "Epoch 1315/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0217 - accuracy: 0.8879 - val_loss: 0.2900 - val_accuracy: 0.8915\n",
      "Epoch 1316/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0577 - accuracy: 0.8872 - val_loss: 0.3429 - val_accuracy: 0.8662\n",
      "Epoch 1317/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0827 - accuracy: 0.8850 - val_loss: 0.3086 - val_accuracy: 0.8834\n",
      "Epoch 1318/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9823 - accuracy: 0.8895 - val_loss: 0.3090 - val_accuracy: 0.8820\n",
      "Epoch 1319/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9540 - accuracy: 0.8904 - val_loss: 0.3172 - val_accuracy: 0.8764\n",
      "Epoch 1320/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9652 - accuracy: 0.8893 - val_loss: 0.2872 - val_accuracy: 0.8919\n",
      "Epoch 1321/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9534 - accuracy: 0.8907 - val_loss: 0.2905 - val_accuracy: 0.8902\n",
      "Epoch 1322/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0404 - accuracy: 0.8869 - val_loss: 0.3006 - val_accuracy: 0.8868\n",
      "Epoch 1323/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9860 - accuracy: 0.8903 - val_loss: 0.3007 - val_accuracy: 0.8864\n",
      "Epoch 1324/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1775 - accuracy: 0.8801 - val_loss: 0.2923 - val_accuracy: 0.8901\n",
      "Epoch 1325/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.4853 - accuracy: 0.8650 - val_loss: 0.3156 - val_accuracy: 0.8833\n",
      "Epoch 1326/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3463 - accuracy: 0.8739 - val_loss: 0.3030 - val_accuracy: 0.8872\n",
      "Epoch 1327/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2573 - accuracy: 0.8765 - val_loss: 0.3018 - val_accuracy: 0.8877\n",
      "Epoch 1328/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1225 - accuracy: 0.8840 - val_loss: 0.3248 - val_accuracy: 0.8760\n",
      "Epoch 1329/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0199 - accuracy: 0.8865 - val_loss: 0.3076 - val_accuracy: 0.8828\n",
      "Epoch 1330/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5324 - accuracy: 0.8627 - val_loss: 0.3530 - val_accuracy: 0.8693\n",
      "Epoch 1331/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3973 - accuracy: 0.8710 - val_loss: 0.3106 - val_accuracy: 0.8843\n",
      "Epoch 1332/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0923 - accuracy: 0.8866 - val_loss: 0.3113 - val_accuracy: 0.8810\n",
      "Epoch 1333/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9906 - accuracy: 0.8898 - val_loss: 0.2863 - val_accuracy: 0.8918\n",
      "Epoch 1334/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0559 - accuracy: 0.8843 - val_loss: 0.2903 - val_accuracy: 0.8911\n",
      "Epoch 1335/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9790 - accuracy: 0.8913 - val_loss: 0.2875 - val_accuracy: 0.8920\n",
      "Epoch 1336/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9221 - accuracy: 0.8932 - val_loss: 0.2870 - val_accuracy: 0.8913\n",
      "Epoch 1337/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 2.9159 - accuracy: 0.8931 - val_loss: 0.3014 - val_accuracy: 0.8837\n",
      "Epoch 1338/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1544 - accuracy: 0.8806 - val_loss: 0.2895 - val_accuracy: 0.8913\n",
      "Epoch 1339/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0185 - accuracy: 0.8888 - val_loss: 0.2926 - val_accuracy: 0.8904\n",
      "Epoch 1340/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9192 - accuracy: 0.8936 - val_loss: 0.2909 - val_accuracy: 0.8896\n",
      "Epoch 1341/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9252 - accuracy: 0.8923 - val_loss: 0.3533 - val_accuracy: 0.8578\n",
      "Epoch 1342/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0665 - accuracy: 0.8849 - val_loss: 0.3283 - val_accuracy: 0.8719\n",
      "Epoch 1343/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.0116 - accuracy: 0.8875 - val_loss: 0.3046 - val_accuracy: 0.8839\n",
      "Epoch 1344/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3821 - accuracy: 0.8700 - val_loss: 0.6188 - val_accuracy: 0.7577\n",
      "Epoch 1345/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.1550 - accuracy: 0.8349 - val_loss: 0.3326 - val_accuracy: 0.8797\n",
      "Epoch 1346/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3997 - accuracy: 0.8742 - val_loss: 0.3414 - val_accuracy: 0.8674\n",
      "Epoch 1347/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1212 - accuracy: 0.8867 - val_loss: 0.2997 - val_accuracy: 0.8872\n",
      "Epoch 1348/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1020 - accuracy: 0.8830 - val_loss: 0.3039 - val_accuracy: 0.8846\n",
      "Epoch 1349/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.8088 - accuracy: 0.8497 - val_loss: 0.3313 - val_accuracy: 0.8784\n",
      "Epoch 1350/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5299 - accuracy: 0.8727 - val_loss: 0.4047 - val_accuracy: 0.8364\n",
      "Epoch 1351/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3116 - accuracy: 0.8744 - val_loss: 0.2935 - val_accuracy: 0.8903\n",
      "Epoch 1352/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2259 - accuracy: 0.8789 - val_loss: 0.2969 - val_accuracy: 0.8881\n",
      "Epoch 1353/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0601 - accuracy: 0.8865 - val_loss: 0.3243 - val_accuracy: 0.8733\n",
      "Epoch 1354/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0028 - accuracy: 0.8889 - val_loss: 0.2889 - val_accuracy: 0.8907\n",
      "Epoch 1355/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9976 - accuracy: 0.8890 - val_loss: 0.3000 - val_accuracy: 0.8851\n",
      "Epoch 1356/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9702 - accuracy: 0.8908 - val_loss: 0.3305 - val_accuracy: 0.8705\n",
      "Epoch 1357/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9988 - accuracy: 0.8882 - val_loss: 0.3355 - val_accuracy: 0.8684\n",
      "Epoch 1358/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9684 - accuracy: 0.8896 - val_loss: 0.3151 - val_accuracy: 0.8767\n",
      "Epoch 1359/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0414 - accuracy: 0.8856 - val_loss: 0.3193 - val_accuracy: 0.8760\n",
      "Epoch 1360/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.7091 - accuracy: 0.8551 - val_loss: 0.5195 - val_accuracy: 0.7892\n",
      "Epoch 1361/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7711 - accuracy: 0.8525 - val_loss: 0.3329 - val_accuracy: 0.8767\n",
      "Epoch 1362/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.2979 - accuracy: 0.8767 - val_loss: 0.3013 - val_accuracy: 0.8886\n",
      "Epoch 1363/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1351 - accuracy: 0.8877 - val_loss: 0.3267 - val_accuracy: 0.8720\n",
      "Epoch 1364/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0311 - accuracy: 0.8858 - val_loss: 0.2866 - val_accuracy: 0.8915\n",
      "Epoch 1365/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9827 - accuracy: 0.8900 - val_loss: 0.3162 - val_accuracy: 0.8759\n",
      "Epoch 1366/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0174 - accuracy: 0.8881 - val_loss: 0.3274 - val_accuracy: 0.8706\n",
      "Epoch 1367/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9429 - accuracy: 0.8906 - val_loss: 0.3069 - val_accuracy: 0.8821\n",
      "Epoch 1368/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8979 - accuracy: 0.8933 - val_loss: 0.3036 - val_accuracy: 0.8831\n",
      "Epoch 1369/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9902 - accuracy: 0.8874 - val_loss: 0.2872 - val_accuracy: 0.8913\n",
      "Epoch 1370/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0332 - accuracy: 0.8863 - val_loss: 0.2955 - val_accuracy: 0.8884\n",
      "Epoch 1371/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9955 - accuracy: 0.8898 - val_loss: 0.3076 - val_accuracy: 0.8818\n",
      "Epoch 1372/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2758 - accuracy: 0.8751 - val_loss: 0.2946 - val_accuracy: 0.8908\n",
      "Epoch 1373/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.0362 - accuracy: 0.8369 - val_loss: 0.3307 - val_accuracy: 0.8738\n",
      "Epoch 1374/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4740 - accuracy: 0.8730 - val_loss: 0.4008 - val_accuracy: 0.8388\n",
      "Epoch 1375/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.1768 - accuracy: 0.8811 - val_loss: 0.2962 - val_accuracy: 0.8895\n",
      "Epoch 1376/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.0282 - accuracy: 0.8879 - val_loss: 0.2936 - val_accuracy: 0.8877\n",
      "Epoch 1377/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9824 - accuracy: 0.8895 - val_loss: 0.2902 - val_accuracy: 0.8893\n",
      "Epoch 1378/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9362 - accuracy: 0.8921 - val_loss: 0.2950 - val_accuracy: 0.8870\n",
      "Epoch 1379/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9254 - accuracy: 0.8925 - val_loss: 0.3231 - val_accuracy: 0.8731\n",
      "Epoch 1380/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9998 - accuracy: 0.8879 - val_loss: 0.3168 - val_accuracy: 0.8770\n",
      "Epoch 1381/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9790 - accuracy: 0.8895 - val_loss: 0.3181 - val_accuracy: 0.8763\n",
      "Epoch 1382/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9509 - accuracy: 0.8910 - val_loss: 0.2929 - val_accuracy: 0.8896\n",
      "Epoch 1383/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9194 - accuracy: 0.8930 - val_loss: 0.3125 - val_accuracy: 0.8785\n",
      "Epoch 1384/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8785 - accuracy: 0.8938 - val_loss: 0.2941 - val_accuracy: 0.8881\n",
      "Epoch 1385/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0224 - accuracy: 0.8877 - val_loss: 0.3267 - val_accuracy: 0.8713\n",
      "Epoch 1386/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0124 - accuracy: 0.8873 - val_loss: 0.3310 - val_accuracy: 0.8689\n",
      "Epoch 1387/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1080 - accuracy: 0.8824 - val_loss: 0.3166 - val_accuracy: 0.8796\n",
      "Epoch 1388/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0314 - accuracy: 0.8865 - val_loss: 0.3037 - val_accuracy: 0.8843\n",
      "Epoch 1389/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5734 - accuracy: 0.8626 - val_loss: 0.4152 - val_accuracy: 0.8396\n",
      "Epoch 1390/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.9940 - accuracy: 0.8445 - val_loss: 0.4595 - val_accuracy: 0.8141\n",
      "Epoch 1391/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4492 - accuracy: 0.8657 - val_loss: 0.3046 - val_accuracy: 0.8853\n",
      "Epoch 1392/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1451 - accuracy: 0.8852 - val_loss: 0.3005 - val_accuracy: 0.8858\n",
      "Epoch 1393/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9787 - accuracy: 0.8905 - val_loss: 0.3178 - val_accuracy: 0.8773\n",
      "Epoch 1394/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9646 - accuracy: 0.8892 - val_loss: 0.2876 - val_accuracy: 0.8902\n",
      "Epoch 1395/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9207 - accuracy: 0.8919 - val_loss: 0.2967 - val_accuracy: 0.8868\n",
      "Epoch 1396/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9404 - accuracy: 0.8911 - val_loss: 0.2988 - val_accuracy: 0.8861\n",
      "Epoch 1397/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.0410 - accuracy: 0.8856 - val_loss: 0.2893 - val_accuracy: 0.8906\n",
      "Epoch 1398/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9983 - accuracy: 0.8896 - val_loss: 0.3181 - val_accuracy: 0.8759\n",
      "Epoch 1399/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9381 - accuracy: 0.8911 - val_loss: 0.2872 - val_accuracy: 0.8914\n",
      "Epoch 1400/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8929 - accuracy: 0.8941 - val_loss: 0.3526 - val_accuracy: 0.8592\n",
      "Epoch 1401/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1956 - accuracy: 0.8784 - val_loss: 0.3115 - val_accuracy: 0.8809\n",
      "Epoch 1402/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.7429 - accuracy: 0.8508 - val_loss: 0.3490 - val_accuracy: 0.8712\n",
      "Epoch 1403/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.4681 - accuracy: 0.8690 - val_loss: 0.3357 - val_accuracy: 0.8735\n",
      "Epoch 1404/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.1488 - accuracy: 0.8846 - val_loss: 0.3364 - val_accuracy: 0.8689\n",
      "Epoch 1405/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0635 - accuracy: 0.8861 - val_loss: 0.3205 - val_accuracy: 0.8753\n",
      "Epoch 1406/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6109 - accuracy: 0.8575 - val_loss: 0.3648 - val_accuracy: 0.8635\n",
      "Epoch 1407/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4521 - accuracy: 0.8709 - val_loss: 0.3298 - val_accuracy: 0.8750\n",
      "Epoch 1408/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0755 - accuracy: 0.8878 - val_loss: 0.3043 - val_accuracy: 0.8829\n",
      "Epoch 1409/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9580 - accuracy: 0.8904 - val_loss: 0.2847 - val_accuracy: 0.8924\n",
      "Epoch 1410/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9279 - accuracy: 0.8914 - val_loss: 0.2868 - val_accuracy: 0.8908\n",
      "Epoch 1411/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9702 - accuracy: 0.8897 - val_loss: 0.2911 - val_accuracy: 0.8888\n",
      "Epoch 1412/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.8915 - accuracy: 0.8937 - val_loss: 0.2899 - val_accuracy: 0.8895\n",
      "Epoch 1413/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9097 - accuracy: 0.8920 - val_loss: 0.2905 - val_accuracy: 0.8898\n",
      "Epoch 1414/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0041 - accuracy: 0.8880 - val_loss: 0.2942 - val_accuracy: 0.8878\n",
      "Epoch 1415/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9389 - accuracy: 0.8915 - val_loss: 0.3263 - val_accuracy: 0.8721\n",
      "Epoch 1416/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1196 - accuracy: 0.8826 - val_loss: 0.2994 - val_accuracy: 0.8862\n",
      "Epoch 1417/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 4.0831 - accuracy: 0.8332 - val_loss: 0.3715 - val_accuracy: 0.8556\n",
      "Epoch 1418/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.4517 - accuracy: 0.8725 - val_loss: 0.3343 - val_accuracy: 0.8718\n",
      "Epoch 1419/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1349 - accuracy: 0.8841 - val_loss: 0.2909 - val_accuracy: 0.8919\n",
      "Epoch 1420/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0106 - accuracy: 0.8904 - val_loss: 0.2965 - val_accuracy: 0.8862\n",
      "Epoch 1421/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0099 - accuracy: 0.8874 - val_loss: 0.3027 - val_accuracy: 0.8825\n",
      "Epoch 1422/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9205 - accuracy: 0.8925 - val_loss: 0.2997 - val_accuracy: 0.8848\n",
      "Epoch 1423/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9389 - accuracy: 0.8912 - val_loss: 0.3150 - val_accuracy: 0.8763\n",
      "Epoch 1424/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8982 - accuracy: 0.8923 - val_loss: 0.2879 - val_accuracy: 0.8906\n",
      "Epoch 1425/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9244 - accuracy: 0.8914 - val_loss: 0.2849 - val_accuracy: 0.8921\n",
      "Epoch 1426/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2283 - accuracy: 0.8755 - val_loss: 0.3518 - val_accuracy: 0.8629\n",
      "Epoch 1427/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.4398 - accuracy: 0.8699 - val_loss: 0.3035 - val_accuracy: 0.8864\n",
      "Epoch 1428/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0810 - accuracy: 0.8864 - val_loss: 0.2914 - val_accuracy: 0.8906\n",
      "Epoch 1429/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9874 - accuracy: 0.8911 - val_loss: 0.2972 - val_accuracy: 0.8865\n",
      "Epoch 1430/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4992 - accuracy: 0.8652 - val_loss: 0.4695 - val_accuracy: 0.8070\n",
      "Epoch 1431/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5188 - accuracy: 0.8626 - val_loss: 0.3535 - val_accuracy: 0.8638\n",
      "Epoch 1432/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.1789 - accuracy: 0.8807 - val_loss: 0.2952 - val_accuracy: 0.8903\n",
      "Epoch 1433/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0508 - accuracy: 0.8885 - val_loss: 0.3166 - val_accuracy: 0.8761\n",
      "Epoch 1434/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9850 - accuracy: 0.8884 - val_loss: 0.2973 - val_accuracy: 0.8854\n",
      "Epoch 1435/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.9265 - accuracy: 0.8920 - val_loss: 0.3168 - val_accuracy: 0.8762\n",
      "Epoch 1436/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9476 - accuracy: 0.8901 - val_loss: 0.3063 - val_accuracy: 0.8808\n",
      "Epoch 1437/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.8949 - accuracy: 0.8926 - val_loss: 0.2932 - val_accuracy: 0.8891\n",
      "Epoch 1438/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.8583 - accuracy: 0.8943 - val_loss: 0.2831 - val_accuracy: 0.8929\n",
      "Epoch 1439/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9448 - accuracy: 0.8906 - val_loss: 0.2875 - val_accuracy: 0.8919\n",
      "Epoch 1440/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8868 - accuracy: 0.8932 - val_loss: 0.3089 - val_accuracy: 0.8800\n",
      "Epoch 1441/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9087 - accuracy: 0.8920 - val_loss: 0.3372 - val_accuracy: 0.8665\n",
      "Epoch 1442/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9232 - accuracy: 0.8905 - val_loss: 0.2811 - val_accuracy: 0.8942\n",
      "Epoch 1443/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0247 - accuracy: 0.8868 - val_loss: 0.2869 - val_accuracy: 0.8922\n",
      "Epoch 1444/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.9702 - accuracy: 0.8903 - val_loss: 0.2907 - val_accuracy: 0.8901\n",
      "Epoch 1445/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0053 - accuracy: 0.8885 - val_loss: 0.4002 - val_accuracy: 0.8358\n",
      "Epoch 1446/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 4.2414 - accuracy: 0.8285 - val_loss: 0.3563 - val_accuracy: 0.8660\n",
      "Epoch 1447/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5337 - accuracy: 0.8686 - val_loss: 0.3221 - val_accuracy: 0.8814\n",
      "Epoch 1448/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1648 - accuracy: 0.8838 - val_loss: 0.3099 - val_accuracy: 0.8832\n",
      "Epoch 1449/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0651 - accuracy: 0.8890 - val_loss: 0.3206 - val_accuracy: 0.8743\n",
      "Epoch 1450/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9846 - accuracy: 0.8890 - val_loss: 0.3255 - val_accuracy: 0.8705\n",
      "Epoch 1451/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9376 - accuracy: 0.8908 - val_loss: 0.2933 - val_accuracy: 0.8877\n",
      "Epoch 1452/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9096 - accuracy: 0.8929 - val_loss: 0.3120 - val_accuracy: 0.8777\n",
      "Epoch 1453/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8766 - accuracy: 0.8934 - val_loss: 0.2943 - val_accuracy: 0.8865\n",
      "Epoch 1454/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8915 - accuracy: 0.8930 - val_loss: 0.2830 - val_accuracy: 0.8931\n",
      "Epoch 1455/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9957 - accuracy: 0.8878 - val_loss: 0.2954 - val_accuracy: 0.8872\n",
      "Epoch 1456/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9198 - accuracy: 0.8917 - val_loss: 0.2842 - val_accuracy: 0.8927\n",
      "Epoch 1457/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.8917 - accuracy: 0.8937 - val_loss: 0.2953 - val_accuracy: 0.8878\n",
      "Epoch 1458/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.8562 - accuracy: 0.8944 - val_loss: 0.2912 - val_accuracy: 0.8884\n",
      "Epoch 1459/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0329 - accuracy: 0.8836 - val_loss: 0.3535 - val_accuracy: 0.8620\n",
      "Epoch 1460/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 4.3384 - accuracy: 0.8253 - val_loss: 0.3751 - val_accuracy: 0.8550\n",
      "Epoch 1461/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.5300 - accuracy: 0.8715 - val_loss: 0.3278 - val_accuracy: 0.8764\n",
      "Epoch 1462/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1641 - accuracy: 0.8819 - val_loss: 0.2905 - val_accuracy: 0.8920\n",
      "Epoch 1463/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0176 - accuracy: 0.8905 - val_loss: 0.3231 - val_accuracy: 0.8737\n",
      "Epoch 1464/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0202 - accuracy: 0.8865 - val_loss: 0.2879 - val_accuracy: 0.8908\n",
      "Epoch 1465/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0177 - accuracy: 0.8890 - val_loss: 0.3197 - val_accuracy: 0.8756\n",
      "Epoch 1466/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9199 - accuracy: 0.8913 - val_loss: 0.2845 - val_accuracy: 0.8929\n",
      "Epoch 1467/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8860 - accuracy: 0.8939 - val_loss: 0.2886 - val_accuracy: 0.8899\n",
      "Epoch 1468/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.8709 - accuracy: 0.8938 - val_loss: 0.2859 - val_accuracy: 0.8908\n",
      "Epoch 1469/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9736 - accuracy: 0.8891 - val_loss: 0.3279 - val_accuracy: 0.8704\n",
      "Epoch 1470/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6200 - accuracy: 0.8570 - val_loss: 0.4849 - val_accuracy: 0.8072\n",
      "Epoch 1471/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7490 - accuracy: 0.8560 - val_loss: 0.3527 - val_accuracy: 0.8642\n",
      "Epoch 1472/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2655 - accuracy: 0.8773 - val_loss: 0.3346 - val_accuracy: 0.8729\n",
      "Epoch 1473/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0362 - accuracy: 0.8898 - val_loss: 0.2981 - val_accuracy: 0.8867\n",
      "Epoch 1474/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9905 - accuracy: 0.8888 - val_loss: 0.2845 - val_accuracy: 0.8918\n",
      "Epoch 1475/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9862 - accuracy: 0.8895 - val_loss: 0.3192 - val_accuracy: 0.8742\n",
      "Epoch 1476/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1893 - accuracy: 0.8764 - val_loss: 0.3756 - val_accuracy: 0.8505\n",
      "Epoch 1477/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.7507 - accuracy: 0.8588 - val_loss: 0.4191 - val_accuracy: 0.8298\n",
      "Epoch 1478/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.2388 - accuracy: 0.8776 - val_loss: 0.2977 - val_accuracy: 0.8881\n",
      "Epoch 1479/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.0315 - accuracy: 0.8882 - val_loss: 0.2993 - val_accuracy: 0.8861\n",
      "Epoch 1480/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9146 - accuracy: 0.8932 - val_loss: 0.3108 - val_accuracy: 0.8783\n",
      "Epoch 1481/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9713 - accuracy: 0.8891 - val_loss: 0.3379 - val_accuracy: 0.8666\n",
      "Epoch 1482/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 3.0134 - accuracy: 0.8859 - val_loss: 0.2879 - val_accuracy: 0.8913\n",
      "Epoch 1483/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2363 - accuracy: 0.8766 - val_loss: 0.2951 - val_accuracy: 0.8894\n",
      "Epoch 1484/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5603 - accuracy: 0.8621 - val_loss: 0.3272 - val_accuracy: 0.8780\n",
      "Epoch 1485/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3140 - accuracy: 0.8772 - val_loss: 0.3854 - val_accuracy: 0.8492\n",
      "Epoch 1486/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1078 - accuracy: 0.8842 - val_loss: 0.3600 - val_accuracy: 0.8561\n",
      "Epoch 1487/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.0043 - accuracy: 0.8873 - val_loss: 0.2860 - val_accuracy: 0.8920\n",
      "Epoch 1488/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.2844 - accuracy: 0.8737 - val_loss: 0.3412 - val_accuracy: 0.8680\n",
      "Epoch 1489/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5055 - accuracy: 0.8644 - val_loss: 0.2997 - val_accuracy: 0.8900\n",
      "Epoch 1490/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0887 - accuracy: 0.8869 - val_loss: 0.3199 - val_accuracy: 0.8779\n",
      "Epoch 1491/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.9394 - accuracy: 0.8923 - val_loss: 0.2893 - val_accuracy: 0.8898\n",
      "Epoch 1492/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9061 - accuracy: 0.8926 - val_loss: 0.2977 - val_accuracy: 0.8865\n",
      "Epoch 1493/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0621 - accuracy: 0.8840 - val_loss: 0.2868 - val_accuracy: 0.8916\n",
      "Epoch 1494/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6220 - accuracy: 0.8555 - val_loss: 0.3199 - val_accuracy: 0.8794\n",
      "Epoch 1495/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2510 - accuracy: 0.8813 - val_loss: 0.3122 - val_accuracy: 0.8821\n",
      "Epoch 1496/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0159 - accuracy: 0.8875 - val_loss: 0.2872 - val_accuracy: 0.8913\n",
      "Epoch 1497/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4019 - accuracy: 0.8684 - val_loss: 0.3427 - val_accuracy: 0.8681\n",
      "Epoch 1498/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4581 - accuracy: 0.8679 - val_loss: 0.4547 - val_accuracy: 0.8150\n",
      "Epoch 1499/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.3505 - accuracy: 0.8703 - val_loss: 0.3075 - val_accuracy: 0.8836\n",
      "Epoch 1500/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1656 - accuracy: 0.8817 - val_loss: 0.3075 - val_accuracy: 0.8823\n",
      "Epoch 1501/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9963 - accuracy: 0.8894 - val_loss: 0.2876 - val_accuracy: 0.8913\n",
      "Epoch 1502/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.9257 - accuracy: 0.8912 - val_loss: 0.2944 - val_accuracy: 0.8873\n",
      "Epoch 1503/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8666 - accuracy: 0.8940 - val_loss: 0.3064 - val_accuracy: 0.8805\n",
      "Epoch 1504/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.8667 - accuracy: 0.8938 - val_loss: 0.3009 - val_accuracy: 0.8835\n",
      "Epoch 1505/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8526 - accuracy: 0.8941 - val_loss: 0.3031 - val_accuracy: 0.8827\n",
      "Epoch 1506/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8376 - accuracy: 0.8943 - val_loss: 0.2856 - val_accuracy: 0.8914\n",
      "Epoch 1507/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.8823 - accuracy: 0.8935 - val_loss: 0.3200 - val_accuracy: 0.8732\n",
      "Epoch 1508/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.9006 - accuracy: 0.8911 - val_loss: 0.3008 - val_accuracy: 0.8841\n",
      "Epoch 1509/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3949 - accuracy: 0.8696 - val_loss: 0.4544 - val_accuracy: 0.8140\n",
      "Epoch 1510/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5425 - accuracy: 0.8612 - val_loss: 0.3568 - val_accuracy: 0.8631\n",
      "Epoch 1511/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3646 - accuracy: 0.8713 - val_loss: 0.3196 - val_accuracy: 0.8810\n",
      "Epoch 1512/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0565 - accuracy: 0.8884 - val_loss: 0.3108 - val_accuracy: 0.8800\n",
      "Epoch 1513/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9203 - accuracy: 0.8922 - val_loss: 0.2822 - val_accuracy: 0.8938\n",
      "Epoch 1514/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9157 - accuracy: 0.8920 - val_loss: 0.2970 - val_accuracy: 0.8856\n",
      "Epoch 1515/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8488 - accuracy: 0.8957 - val_loss: 0.3201 - val_accuracy: 0.8727\n",
      "Epoch 1516/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0321 - accuracy: 0.8861 - val_loss: 0.3023 - val_accuracy: 0.8827\n",
      "Epoch 1517/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8269 - accuracy: 0.8456 - val_loss: 0.3437 - val_accuracy: 0.8704\n",
      "Epoch 1518/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.4116 - accuracy: 0.8726 - val_loss: 0.3088 - val_accuracy: 0.8843\n",
      "Epoch 1519/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.1841 - accuracy: 0.8802 - val_loss: 0.2866 - val_accuracy: 0.8936\n",
      "Epoch 1520/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9667 - accuracy: 0.8929 - val_loss: 0.3037 - val_accuracy: 0.8817\n",
      "Epoch 1521/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8823 - accuracy: 0.8927 - val_loss: 0.2869 - val_accuracy: 0.8909\n",
      "Epoch 1522/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.8721 - accuracy: 0.8935 - val_loss: 0.2842 - val_accuracy: 0.8918\n",
      "Epoch 1523/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8940 - accuracy: 0.8917 - val_loss: 0.2846 - val_accuracy: 0.8919\n",
      "Epoch 1524/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9565 - accuracy: 0.8904 - val_loss: 0.3054 - val_accuracy: 0.8818\n",
      "Epoch 1525/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9249 - accuracy: 0.8902 - val_loss: 0.2810 - val_accuracy: 0.8941\n",
      "Epoch 1526/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8410 - accuracy: 0.8953 - val_loss: 0.3001 - val_accuracy: 0.8845\n",
      "Epoch 1527/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.8273 - accuracy: 0.8958 - val_loss: 0.3081 - val_accuracy: 0.8796\n",
      "Epoch 1528/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.3168 - accuracy: 0.8708 - val_loss: 0.3265 - val_accuracy: 0.8782\n",
      "Epoch 1529/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.4092 - accuracy: 0.8694 - val_loss: 0.3102 - val_accuracy: 0.8828\n",
      "Epoch 1530/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9703 - accuracy: 0.8908 - val_loss: 0.3073 - val_accuracy: 0.8830\n",
      "Epoch 1531/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8868 - accuracy: 0.8949 - val_loss: 0.2948 - val_accuracy: 0.8867\n",
      "Epoch 1532/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8842 - accuracy: 0.8914 - val_loss: 0.2942 - val_accuracy: 0.8874\n",
      "Epoch 1533/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6335 - accuracy: 0.8553 - val_loss: 0.3916 - val_accuracy: 0.8574\n",
      "Epoch 1534/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.5646 - accuracy: 0.8652 - val_loss: 0.3290 - val_accuracy: 0.8770\n",
      "Epoch 1535/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1158 - accuracy: 0.8863 - val_loss: 0.3185 - val_accuracy: 0.8792\n",
      "Epoch 1536/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0167 - accuracy: 0.8872 - val_loss: 0.2956 - val_accuracy: 0.8880\n",
      "Epoch 1537/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9735 - accuracy: 0.8907 - val_loss: 0.3178 - val_accuracy: 0.8758\n",
      "Epoch 1538/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3504 - accuracy: 0.8685 - val_loss: 0.3564 - val_accuracy: 0.8604\n",
      "Epoch 1539/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.8031 - accuracy: 0.8537 - val_loss: 0.3213 - val_accuracy: 0.8817\n",
      "Epoch 1540/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.2195 - accuracy: 0.8825 - val_loss: 0.3062 - val_accuracy: 0.8854\n",
      "Epoch 1541/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0138 - accuracy: 0.8890 - val_loss: 0.2995 - val_accuracy: 0.8867\n",
      "Epoch 1542/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9119 - accuracy: 0.8941 - val_loss: 0.3014 - val_accuracy: 0.8832\n",
      "Epoch 1543/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.8743 - accuracy: 0.8936 - val_loss: 0.2899 - val_accuracy: 0.8888\n",
      "Epoch 1544/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.9132 - accuracy: 0.8923 - val_loss: 0.3262 - val_accuracy: 0.8693\n",
      "Epoch 1545/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9633 - accuracy: 0.8880 - val_loss: 0.2911 - val_accuracy: 0.8897\n",
      "Epoch 1546/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.9511 - accuracy: 0.8903 - val_loss: 0.3194 - val_accuracy: 0.8752\n",
      "Epoch 1547/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1310 - accuracy: 0.8788 - val_loss: 0.3744 - val_accuracy: 0.8512\n",
      "Epoch 1548/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.5884 - accuracy: 0.8653 - val_loss: 0.4502 - val_accuracy: 0.8189\n",
      "Epoch 1549/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3569 - accuracy: 0.8708 - val_loss: 0.3126 - val_accuracy: 0.8824\n",
      "Epoch 1550/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 3.0909 - accuracy: 0.8855 - val_loss: 0.2884 - val_accuracy: 0.8918\n",
      "Epoch 1551/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9510 - accuracy: 0.8912 - val_loss: 0.2948 - val_accuracy: 0.8876\n",
      "Epoch 1552/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.0991 - accuracy: 0.8837 - val_loss: 0.4574 - val_accuracy: 0.8080\n",
      "Epoch 1553/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.3181 - accuracy: 0.8710 - val_loss: 0.2915 - val_accuracy: 0.8914\n",
      "Epoch 1554/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0139 - accuracy: 0.8878 - val_loss: 0.2969 - val_accuracy: 0.8869\n",
      "Epoch 1555/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.0278 - accuracy: 0.8865 - val_loss: 0.3787 - val_accuracy: 0.8467\n",
      "Epoch 1556/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0573 - accuracy: 0.8833 - val_loss: 0.2944 - val_accuracy: 0.8891\n",
      "Epoch 1557/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.8812 - accuracy: 0.8941 - val_loss: 0.2821 - val_accuracy: 0.8936\n",
      "Epoch 1558/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9060 - accuracy: 0.8931 - val_loss: 0.3577 - val_accuracy: 0.8542\n",
      "Epoch 1559/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.5345 - accuracy: 0.8614 - val_loss: 0.4098 - val_accuracy: 0.8296\n",
      "Epoch 1560/3000\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 3.2728 - accuracy: 0.8755 - val_loss: 0.2963 - val_accuracy: 0.8907\n",
      "Epoch 1561/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 3.0268 - accuracy: 0.8881 - val_loss: 0.3255 - val_accuracy: 0.8740\n",
      "Epoch 1562/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.8996 - accuracy: 0.8936 - val_loss: 0.2842 - val_accuracy: 0.8932\n",
      "Epoch 1563/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.8579 - accuracy: 0.8944 - val_loss: 0.3122 - val_accuracy: 0.8778\n",
      "Epoch 1564/3000\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 2.9064 - accuracy: 0.8913 - val_loss: 0.3094 - val_accuracy: 0.8792\n",
      "Epoch 1565/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.8912 - accuracy: 0.8931 - val_loss: 0.3022 - val_accuracy: 0.8823\n",
      "Epoch 1566/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.1289 - accuracy: 0.8813 - val_loss: 0.5265 - val_accuracy: 0.7814\n",
      "Epoch 1567/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.6682 - accuracy: 0.8532 - val_loss: 0.3463 - val_accuracy: 0.8663\n",
      "Epoch 1568/3000\n",
      " 3/10 [========>.....................] - ETA: 0s - loss: 3.5835 - accuracy: 0.8591Epoch 2486/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.6085 - accuracy: 0.9030 - val_loss: 0.2935 - val_accuracy: 0.8872\n",
      "Epoch 2487/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.5871 - accuracy: 0.9038 - val_loss: 0.2977 - val_accuracy: 0.8852\n",
      "Epoch 2488/3000\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 2.5993 - accuracy: 0.9027 - val_loss: 0.2791 - val_accuracy: 0.8952\n",
      "Epoch 2489/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.5925 - accuracy: 0.9041 - val_loss: 0.3163 - val_accuracy: 0.8756\n",
      "Epoch 2490/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.7435 - accuracy: 0.8941 - val_loss: 0.3591 - val_accuracy: 0.8633\n",
      "Epoch 2491/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 3.2346 - accuracy: 0.8753 - val_loss: 0.3081 - val_accuracy: 0.8878\n",
      "Epoch 2492/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.8992 - accuracy: 0.8907 - val_loss: 0.2883 - val_accuracy: 0.8932\n",
      "Epoch 2493/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.7557 - accuracy: 0.8980 - val_loss: 0.2800 - val_accuracy: 0.8945\n",
      "Epoch 2494/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 2.6838 - accuracy: 0.9005 - val_loss: 0.3562 - val_accuracy: 0.8562\n",
      "Epoch 2495/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 3.6215 - accuracy: 0.8555 - val_loss: 0.3222 - val_accuracy: 0.8818\n",
      "Epoch 2496/3000\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 3.3605 - accuracy: 0.8699 - val_loss: 0.3650 - val_accuracy: 0.8593\n",
      "Epoch 2497/3000\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 2.9877 - accuracy: 0.8877 - val_loss: 0.2842 - val_accuracy: 0.8942\n",
      "Epoch 2498/3000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 2.7376 - accuracy: 0.8983 - val_loss: 0.2899 - val_accuracy: 0.8890\n",
      "Epoch 2499/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.6432 - accuracy: 0.9025 - val_loss: 0.2759 - val_accuracy: 0.8965\n",
      "Epoch 2500/3000\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 2.6188 - accuracy: 0.9026 - val_loss: 0.2758 - val_accuracy: 0.8976\n",
      "Epoch 2501/3000\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 2.6314 - accuracy: 0.9022 - val_loss: 0.2924 - val_accuracy: 0.8877\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape = trainFeature.shape[1]))\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(8, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(3, activation = \"softmax\"))\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate = 0.0005)\n",
    "\n",
    "model.compile(optimizer = Adam, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "class_weight = {0 : 7.,\n",
    "                1 : 18.,\n",
    "                2 : 8.}\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = \"val_loss\", min_delta = 0.00001, patience = 300, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(trainFeature, trainTarget, epochs = 3000, validation_split = 0.3, shuffle = True,\n",
    "                    verbose = 1, batch_size = 15000, class_weight = class_weight, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(testFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8967436735314234"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.argmax(result, axis = 1) == test[\"class\"]) / len(test[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv(\"./RawData/test.csv\")\n",
    "submit = pd.read_csv(\"./RawData/sample_submission.csv\")\n",
    "result = model.predict(pred.drop(\"id\", axis = \"columns\"))\n",
    "submit[\"class\"] = np.argmax(result, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>399995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>399996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>399997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>399998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>399999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  class\n",
       "0      320000      0\n",
       "1      320001      0\n",
       "2      320002      0\n",
       "3      320003      0\n",
       "4      320004      0\n",
       "...       ...    ...\n",
       "79995  399995      0\n",
       "79996  399996      0\n",
       "79997  399997      0\n",
       "79998  399998      0\n",
       "79999  399999      0\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"C:/Users/Family/Desktop/submit.csv\", index = False, encoding = \"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./RawData/train.csv\")\n",
    "train = train.drop([\"id\"], axis = \"columns\")\n",
    "\n",
    "clf = IsolationForest(n_estimators = 100)\n",
    "clf.fit(train)\n",
    "pred = clf.predict(train)\n",
    "train[\"anomaly\"] = pred\n",
    "train = train.loc[train[\"anomaly\"] != -1]\n",
    "train = train.drop(\"anomaly\", axis = \"columns\")\n",
    "\n",
    "train, test = train_test_split(train, test_size = .2)\n",
    "\n",
    "train, valid = train_test_split(train, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeature = train.drop(\"class\", axis = \"columns\")\n",
    "trainTarget = train[\"class\"]\n",
    "\n",
    "validFeature = valid.drop(\"class\", axis = \"columns\")\n",
    "validTarget = valid[\"class\"]\n",
    "\n",
    "testFeature = test.drop(\"class\", axis = \"columns\")\n",
    "testTarget = test[\"class\"]\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "res = scale.fit(trainFeature)\n",
    "res = scale.transform(trainFeature)\n",
    "trainFeature = np.array(res)\n",
    "\n",
    "res = scale.transform(validFeature)\n",
    "validFeature = np.array(res)\n",
    "\n",
    "res = scale.transform(testFeature)\n",
    "testFeature = np.array(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.10232\n",
      "[1]\tvalidation_0-merror:0.09575\n",
      "[2]\tvalidation_0-merror:0.09150\n",
      "[3]\tvalidation_0-merror:0.09078\n",
      "[4]\tvalidation_0-merror:0.09029\n",
      "[5]\tvalidation_0-merror:0.08953\n",
      "[6]\tvalidation_0-merror:0.08879\n",
      "[7]\tvalidation_0-merror:0.08819\n",
      "[8]\tvalidation_0-merror:0.08736\n",
      "[9]\tvalidation_0-merror:0.08603\n",
      "[10]\tvalidation_0-merror:0.08543\n",
      "[11]\tvalidation_0-merror:0.08478\n",
      "[12]\tvalidation_0-merror:0.08408\n",
      "[13]\tvalidation_0-merror:0.08334\n",
      "[14]\tvalidation_0-merror:0.08328\n",
      "[15]\tvalidation_0-merror:0.08282\n",
      "[16]\tvalidation_0-merror:0.08249\n",
      "[17]\tvalidation_0-merror:0.08215\n",
      "[18]\tvalidation_0-merror:0.08228\n",
      "[19]\tvalidation_0-merror:0.08181\n",
      "[20]\tvalidation_0-merror:0.08154\n",
      "[21]\tvalidation_0-merror:0.08114\n",
      "[22]\tvalidation_0-merror:0.08079\n",
      "[23]\tvalidation_0-merror:0.08071\n",
      "[24]\tvalidation_0-merror:0.08081\n",
      "[25]\tvalidation_0-merror:0.08019\n",
      "[26]\tvalidation_0-merror:0.07967\n",
      "[27]\tvalidation_0-merror:0.07962\n",
      "[28]\tvalidation_0-merror:0.07956\n",
      "[29]\tvalidation_0-merror:0.07954\n",
      "[30]\tvalidation_0-merror:0.07959\n",
      "[31]\tvalidation_0-merror:0.07921\n",
      "[32]\tvalidation_0-merror:0.07908\n",
      "[33]\tvalidation_0-merror:0.07896\n",
      "[34]\tvalidation_0-merror:0.07877\n",
      "[35]\tvalidation_0-merror:0.07861\n",
      "[36]\tvalidation_0-merror:0.07835\n",
      "[37]\tvalidation_0-merror:0.07813\n",
      "[38]\tvalidation_0-merror:0.07782\n",
      "[39]\tvalidation_0-merror:0.07756\n",
      "[40]\tvalidation_0-merror:0.07739\n",
      "[41]\tvalidation_0-merror:0.07718\n",
      "[42]\tvalidation_0-merror:0.07707\n",
      "[43]\tvalidation_0-merror:0.07653\n",
      "[44]\tvalidation_0-merror:0.07639\n",
      "[45]\tvalidation_0-merror:0.07599\n",
      "[46]\tvalidation_0-merror:0.07585\n",
      "[47]\tvalidation_0-merror:0.07580\n",
      "[48]\tvalidation_0-merror:0.07577\n",
      "[49]\tvalidation_0-merror:0.07568\n",
      "[50]\tvalidation_0-merror:0.07565\n",
      "[51]\tvalidation_0-merror:0.07557\n",
      "[52]\tvalidation_0-merror:0.07552\n",
      "[53]\tvalidation_0-merror:0.07546\n",
      "[54]\tvalidation_0-merror:0.07543\n",
      "[55]\tvalidation_0-merror:0.07519\n",
      "[56]\tvalidation_0-merror:0.07511\n",
      "[57]\tvalidation_0-merror:0.07506\n",
      "[58]\tvalidation_0-merror:0.07493\n",
      "[59]\tvalidation_0-merror:0.07492\n",
      "[60]\tvalidation_0-merror:0.07493\n",
      "[61]\tvalidation_0-merror:0.07492\n",
      "[62]\tvalidation_0-merror:0.07489\n",
      "[63]\tvalidation_0-merror:0.07482\n",
      "[64]\tvalidation_0-merror:0.07465\n",
      "[65]\tvalidation_0-merror:0.07474\n",
      "[66]\tvalidation_0-merror:0.07466\n",
      "[67]\tvalidation_0-merror:0.07478\n",
      "[68]\tvalidation_0-merror:0.07474\n",
      "[69]\tvalidation_0-merror:0.07465\n",
      "[70]\tvalidation_0-merror:0.07460\n",
      "[71]\tvalidation_0-merror:0.07462\n",
      "[72]\tvalidation_0-merror:0.07457\n",
      "[73]\tvalidation_0-merror:0.07452\n",
      "[74]\tvalidation_0-merror:0.07446\n",
      "[75]\tvalidation_0-merror:0.07440\n",
      "[76]\tvalidation_0-merror:0.07441\n",
      "[77]\tvalidation_0-merror:0.07447\n",
      "[78]\tvalidation_0-merror:0.07451\n",
      "[79]\tvalidation_0-merror:0.07440\n",
      "[80]\tvalidation_0-merror:0.07430\n",
      "[81]\tvalidation_0-merror:0.07414\n",
      "[82]\tvalidation_0-merror:0.07408\n",
      "[83]\tvalidation_0-merror:0.07413\n",
      "[84]\tvalidation_0-merror:0.07413\n",
      "[85]\tvalidation_0-merror:0.07414\n",
      "[86]\tvalidation_0-merror:0.07408\n",
      "[87]\tvalidation_0-merror:0.07386\n",
      "[88]\tvalidation_0-merror:0.07383\n",
      "[89]\tvalidation_0-merror:0.07390\n",
      "[90]\tvalidation_0-merror:0.07378\n",
      "[91]\tvalidation_0-merror:0.07373\n",
      "[92]\tvalidation_0-merror:0.07356\n",
      "[93]\tvalidation_0-merror:0.07343\n",
      "[94]\tvalidation_0-merror:0.07340\n",
      "[95]\tvalidation_0-merror:0.07346\n",
      "[96]\tvalidation_0-merror:0.07340\n",
      "[97]\tvalidation_0-merror:0.07337\n",
      "[98]\tvalidation_0-merror:0.07333\n",
      "[99]\tvalidation_0-merror:0.07321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = xgboost.XGBClassifier(objective = \"softprob\")\n",
    "tree.fit(trainFeature, trainTarget, eval_set = [(validFeature, validTarget)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = {\n",
    "    \"subsample\" : [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"max_depth\" : [2, 3, 4, 5, 6, 7],\n",
    "    \"n_estimators\" : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    \"gamma\" : [0.5, 1, 1.5, 2, 2.5],\n",
    "    \"learning_rate\" : [0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(tree, param_grid = xgb_param, scoring = \"accuracy\", cv = 5)\n",
    "grid_xgb.fit(trainFeature, trainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9239099458535195"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tree.predict(testFeature)\n",
    "sum(result == testTarget.reset_index(drop = True)) / len(testTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv(\"./RawData/test.csv\")\n",
    "submit = pd.read_csv(\"./RawData/sample_submission.csv\")\n",
    "result = tree.predict(np.array(pred.drop(\"id\", axis = \"columns\")))\n",
    "submit[\"class\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"C:/Users/Family/Desktop/submit.csv\", index = False, encoding = \"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-215-c7026e1070eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainFeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    832\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1159\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
